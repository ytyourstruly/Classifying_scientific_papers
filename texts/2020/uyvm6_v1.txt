Angry men and happy women – A pre-registered replication using psychophysics
Sebastian Korb1,2
Claudia Massaccesi3
1 Department of Psychology, University of Essex, Colchester, UK
2 Department of Cognition, Emotion, and Methods in Psychology, University of Vienna,
Austria
3 Department of Clinical and Health Psychology, University of Vienna, Austria
Correspondence: Sebastian Korb, Department of Psychology, University of Essex, Wivenhoe
Park, CO4 3SQ Colchester, UK. Tel.: +44 (0) 1206 873712. Email:
sebastian.korb@essex.ac.uk
Data availability statement:
The data that support the findings of this study are openly available in Open Science
Abstract
Judgments about the emotional expression of a face are influenced by its sexual
features, and vice versa. The cause of this interaction remains unclear. Most previous research
has used standard analyses of categorisation responses to full-blown emotional expressions. A
better understanding of the phenomenon may however require the adoption of nuanced stimuli
and sophisticated analyses methods. For example, Harris et al. (2016), used psychophysics
methods to compare responses to faces displaying emotions at several intensity levels. The
point of subjective equality (PSE), at which happy and angry categories are equally likely, was
found to be closer to the happiness pole for male compared to female faces. Because these
methods seem promising for the quest of advancing the field to a better understanding of how
emotional and social judgments of faces are formed, we attempted a replication of Harris et
large sample (N = 108) from a comparable population was tested with the same stimuli and
task as in the original publication. We successfully replicated the main and some secondary
findings, which we discuss in the context of the literature, and we indicate promising avenues
of research in this domain.
Keywords
Face processing; social judgments; categorisation; emotion; sex
Acknowledgements
We thank our students for contributing to task programming and data acquisition.
Thanks to Nace Mikus and Matteo Lisi for help with extracting the psychophysical parameters.
We especially thank Vivian Ciaramitaro for sharing the stimuli and providing information
about the original study.
1 Introduction
2 Human faces reveal many things, such as a person’s age, sex, focus of attention, and
3 emotional state, which perceivers extract and categorise automatically at first sight (Willis &
4 Todorov, 2006). Face perception also relies heavily on top-down effects of categorisation, such
5 as situational context and perceiver biases (Wieser & Brosch, 2012). Importantly, the sight of
6 a face can elicits the activation of multiple competing, and possibly interacting, social
7 categories in the mind (and brain) of the perceiver (Freeman & Johnson, 2016). In line with
8 this, previous work has suggested that a face’s biological sex influences perceptual judgments
9 of its emotional expression, and vice-versa. In general, maleness is associated with anger or
10 aggression, while femaleness is associated with happiness, fear, or sadness. For example,
11 emotionally ambiguous infant faces are rated as angry when the infant is labelled as a boy, and
12 as fearful when it is labelled as a girl (Condry & Condry, 1976). Emotionally and sexually
13 ambiguous adult faces are rated as angry if shown with typically male clothing and hairstyle,
14 and as sad when shown with typically female clothing and hair (Plant et al., 2004).
15 The mechanisms underlying the reported mutual effects of emotional expression and
16 sex during face perception remain debated. They may include top-down effects of gender
17 evaluation and gender stereotyping (Amodio & Devine, 2006; Plant et al., 2000), and objective
18 morphological similarities between certain sexual and emotional features (Said et al., 2009;
19 Zebrowitz et al., 2010). Because of this complexity, the field is best advised to start adopting
20 rigorous research methods, such as the use of standardized tasks, fine-grained and controlled
21 facial stimuli, advanced data analysis, and registered replications.
22 The perhaps most common method to experimentally investigate the mutual influence
23 of facial emotion and sex cues, is the categorisation of male and female faces that display a
24 strong and therefore clear emotional expression. Using this method, several studies have found
25 that the categorisation of both the emotional expression and the sex of faces is faster and more
26 accurate for angry male and happy female faces, compared to happy male and angry female
27 faces (Becker et al., 2007; Hess et al., 2009).
28 A recent categorisation study however stands out for having used male and female faces
29 that gradually change between happiness and anger. Harris et al. (2016) fitted psychophysics
30 curves to happy/angry categorisation choices in response to nine emotion levels (including
31 neutral), and established that the point of subjective equality (PSE), at which happy and angry
32 categories are equally likely to be selected, was further towards the happiness pole for male
33 than for female faces. The effect size was small to medium (Cohen’s d = 0.28). This approach,
34 which focuses on ambiguous rather than full-blown expressions, appears promising for a more
35 in-depth exploration of the phenomenon of emotion-sex interaction effect on face processing.
37 replication attempt of the main finding of Harris et al. (2016), by testing 108 participants with
38 the same task and identical face stimuli.
39 Methods
Participants
41 Participants were 108 psychology students (75 females, age range 18 to 33 years, mean
42 age = 21.51, SD = 2.9) who received study credits for their participation. To determine sample
43 size we estimated the original effect size based on the means and standard errors of the mean
45 average PSEs (SEM) were 4.3 (1) for male and 1.2 (1) for female faces. From that, we estimated
46 a standard deviation (SD) of 12 for both groups, by multiplying the SEM by the square root of
47 the sample (126). Using these values, and assuming a 0.6 correlation between groups, Cohen’s
48 d was estimated to be 0.28 with the program G*Power (Faul et al., 2007). A total sample size
49 of 103 participants was estimated to be necessary to replicate the finding with a power of 0.8,
50 with alpha set at 0.05. We aimed to test up to 110 participants, but stopped at N = 108 du to
51 organizational reasons. The study was approved by the ethics committee of the University of
52 Vienna.
Stimuli
54 The identical stimulus set was used as in the original publication (Harris et al., 2016).
55 It included 72 pictures of faces selected from the NimStim database (Tottenham et al., 2009),
56 displaying a neutral face, as well as morphs with 10, 20, 40, and 80% of both happiness and
57 anger, for eight facial identities (four male, four female).
Procedure
59 The task was programmed with PsychoPy3 (Peirce et al., 2019) and consisted in
60 categorising each face as either happy or angry, by pushing, with the index and middle/ring
61 fingers of the right hand, the right or left arrow button on a computer keyboard (assignment of
62 buttons to emotions was counterbalanced across participants). In each trial, a fixation cross was
63 shown for one second, followed by a face for one second, and a question mark for 1.5 seconds.
64 Participants were instructed to indicate their categorisation choice when the question mark was
65 on the screen. The task was preceded by four practice trials, in which emojis were shown
66 instead of faces. Up to 10 participants were tested simultaneously, each sitting in front of a
67 computer screen and separated by cubicles.
69 was followed by other categorisation tasks with different stimuli (not reported here), and by a
70 series of questionnaires. We focus here on the PANAS questionnaire (Watson et al., 1988), as
71 it was also reported in Harris et al (2016).
Analyses
74 removal of trials without response (2.4% of all trials), participants’ categorisation choices were
75 analysed in a generalized linear mixed-effects binomial model (GLMM), using the glmer
76 function of the lme4 package in R1. A probit (cumulative gaussian) function was specified, as
77 in Harris et al. (2016). By including random effects, GLMMs reduce Type-I errors and allow
78 for better generalization of findings (Judd et al., 2017). Categorisation choice (happy/angry)
79 was the dependent variable, stimulus emotion (nine levels, cantered) and stimulus sex (two
80 levels, dummy-coded) were the fixed effects, and by-subject random intercepts and random
81 slopes for stimulus’ emotion and sex and their interaction were included. Based on the fitted
82 GLMM, the PSE and the slope of the model fits were calculated for each subject and sex. To
83 compare the PSEs for male and female faces (main finding in Harris et al., 2016), we used
84 linear regression implemented with the function lm in R. Type III ANOVA output was obtained
85 with the Anova function of the car package. Similarly, model slopes and percentages of
86 categorisation choices for the standard neutral faces (those labelled as neutral in the original
87 face database) were regressed on the predictor stimulus’ sex. Participants’ sex and scores on
88 the positive and negative PANAS scales were added as covariates, to control for individual
89 differences. PSEs were also compared against zero using two-tailed t-tests.
Results
91 The analysis of categorisation choices resulted in significant main effects of Emotion
92 (b = .48, SE = .02, z = 30.32, p < .001) and Sex (b = -.84, SE = .09, z = -9.59, p < .001), as well
93 as a significant Emotion X Sex interaction (b = .13, SE = .03, z = 3.70, p < .001). The main
94 effect of Emotion reflects that happier faces were categorised more often as happy, and thus
1 glmer(choice ~ emotion * sex + (emotion * sex | sub) , family=binomial (link=”probit”))
95 that participants followed instructions and could recognize the facial expressions. The main
96 effect of Sex confirms the hypothesis that female faces are perceived as happier than male
97 faces. Finally, the interaction is explained by a greater difference between female and male
98 faces at the centre of the emotion continuum (where expressions are more ambiguous),
101 Fig1: (A) Lines represent the average (SD) percentage of trials categorised as happy, by emotional expression and
102 sex. Raw data (jittered to improve visibility) is shown with blue triangles (male faces) and red circles (female
103 faces). (B) Marginal means and confidence intervals of the GLMM fitted to the data, with indicated points of
104 subjective equality (PSE, for which there is a 50% chance to be categorised as happy or angry). Stimuli at the PSE
105 for male faces contained significantly more happiness than stimuli at the PSE for female faces.
106 As expected, the PSE contained more happiness in male than female faces. On average,
107 male faces required 17.5% of happiness, to be categorised as happy 50% of the time, while
109 shown by linear regression (F(1, 214) = 75.75, p < . 001), and stayed significant when
110 controlling for participants’ sex, and mood (positive and negative subscales of the PANAS, see
112 8.7 for male, and 10.2 for female faces, correlation of 0.76 between conditions). Thus, although
113 the difference between male and female PSEs in the current replication (1.34 in units of
114 morphs) was less than half of that (3.1) found by Harris et al., the corresponding effect size
115 was more than seven-fold bigger, thanks to smaller SDs. The PSEs were also significantly
116 different from zero for both male faces (t(107) = 16.64, p < . 001) and female faces (t(107) =
117 2.15, p = . 04).
118 Furthermore, we carried out the other analyses reported in the original study. The slope
119 of the fitted statistical model was steeper (F(1, 214) = 33.10 p < . 001) for male faces (b = .59)
120 than for female faces (b = .48), suggesting that emotion was perceived more categorically for
121 male than female faces. Standard neutral faces (those at the centre of the continuum, which
122 were labelled as neutral in the original database), were categorised significantly (F(1,214) =
123 71.99, p < . 001) more often as happy if they were female (45.14%), than male (14.51%),
124 confirming that neutral male faces are perceived as angrier compared to neutral female faces.
126 Reaction times for faces with 80% intensity were neither predicted by the emotion (happy,
127 angry), nor by the gender (male, female) of the face, nor by their interaction (all F < .5, all p
128 > .5).
130 Fig2: Top row: scatterplots between PSE and (A) positive mood, (B) negative mood. Bottom row: scatterplots
131 between the percentage of happy categorisations at the standard neutral faces and (C) positive mood, and (D)
132 negative mood. None of the correlations was statistically significant (all p > .5).
Discussion
134 Harris et al.’s (2016) finding, that stimuli at the PSE for male faces contain significantly
135 more happiness compared to the stimuli at the PSE for female faces, was successfully
136 replicated. The corresponding standardized effect size (d = 2.0) was about seven times larger
137 than in the original study (d = .28). We also replicated the finding that male neutral faces were
138 judged angrier than female neutral faces. Our results confirm that male faces are perceived as
139 angrier (less happy) than female faces, and are in line with the literature (Becker et al., 2007;
140 Hess et al., 2009).
141 Other results differed from those reported by Harris et al. (2016). First, the fitted probit
142 function had a steeper slope for male compared to female faces, suggesting more categorical
143 emotion perception for male faces. In contrast, Harris et al. found no difference in slopes.
144 Second, we did not replicate the correlations between PSEs and participants’ positive affect,
145 nor between categorisation of standard neutral faces and positive affect. Third, we did not
146 replicate the finding of faster responses to female than male faces with 80% anger. These
147 effects were however not the focus of the replication, and their replication may have required
148 a larger sample size.
149 Successful replication of the difference in PSEs for male and female faces may partly
150 be attributable to the fact that comparable groups of participants were tested in both studies (all
151 students, similar average age and gender ratio). However, focusing on student populations
152 bears its problems (Henrich et al., 2010), and it therefore should be tested if the results hold
153 also in other groups.
154 Neither the results by Harris et al. (2016), nor this replication, can by themselves clarify
155 what causes men to be perceived as angrier, and women as happier. Several factors have been
156 proposed to underlie these effects, ranging from low-level visual similarities between male
157 faces and angry faces, to top-down modulation by higher-order cognition like stereotypes
158 (Plant et al., 2004; Said et al., 2009; Zebrowitz et al., 2010). Clearly, laboratory experiments
159 using controlled stimuli with gradual emotion changes, and psychophysical analyses of
160 participants’ responses seem an appropriate first step to better understand the phenomenon at
161 hand. Registered replication efforts provide the important validation of reported findings.
162 The phenomenon should however also be investigated from different angles, e.g. by
163 investigating if the sex-induced emotion bias can be erased through priming, which would
164 suggest that it is easily modifiable and thus unlikely to be hardwired (Kurzban et al., 2001), or
165 by investigating if it occurs when face awareness is suppressed by binocular rivalry (Korb et
166 al., 2017). In addition, it might be worthwhile to explore the bidirectionality of the emotion by
167 sex interaction, and to compare the strength of these effects at the explicit and implicit level.
168 To that purpose, we have recently developed a new stimulus set comprising avatar faces with
169 11 levels of emotion and sex, and found that ratings and categorisations of faces are influenced
170 equally by the face’s emotion and sex, when these dimensions are attended to, but that the
171 effects of emotion prevail over the effects of sex, when these stimulus dimensions are
172 processed implicitly (in preparation).