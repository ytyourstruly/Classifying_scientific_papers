The German Job Search Panel
†,‡,* ± ‡
Clemens Hetschko Julia Schmidtke Michael Eid
‡ ‡,* ±,⁜
Mario Lawes Ronnie Schöb Gesine Stephan
This version: 30 December 2022
Abstract
This report introduces the German Job Search Panel, a monthly survey that follows people who
registered as job seeking over the course of up to two years. The focus of the survey is on the
well-being and health of jobseekers, with special emphasis on workers affected by mass layoffs.
The use of an innovative survey app allows for frequent measurement every month and for
conducting the experience sampling method to measure affective well-being. The collected data
may be linked to administrative records of the Federal Employment Agency subject to
participant consent. For a subsample of surveyed jobseekers hair cortisol levels are available as
a biomarker for chronic stress. In this report, we describe the sampling procedure, adjustments
over the recruitment period and the collected data. We moreover examine selective participation
in the panel. It turns out that high-skilled workers, young individuals and women were more
likely to sign up. Age increases the probability to take part in the hair sampling. People working
in East Germany are more likely to consent to the linkage of survey data and administrative
records. However, the aggregated bias resulting from selective participation is small.
† University of Leeds
* CESifo, Munich
‡ Freie Universität Berlin
± Institute for Employment Research (IAB), Nuremberg
⁜ Friedrich-Alexanders-Universität Erlangen-Nuremberg
Corresponding author. Clemens Hetschko, Leeds University Business School, Economics Division, Maurice
Keyworth Building, Leeds, LS2 9JT.
Acknowledgements. The authors are indebted to the IAB-DIM unit, in particular Stephan Grießemer who carried
out the sampling, and thank Benjamin Küfner for valuable research assistance. Financial support by the German
Science Foundation (DFG) through projects EI 379/11-1, EI 379/11-2, SCHO 1270/5-1, SCHO 1270/5-2, STE
1424/4-1 and STE 1424/4-2 as well as by the Institute for Employment Research (IAB) through projects 3111,
3874, 3877 and 3905 is gratefully acknowledged.
1. Introduction
In recent years, well-being indicators have become an important tool for the analysis of the
individual impact of unemployment (e.g., Hetschko & Schöb, 2017; Paul & Moser, 2009;
Wanberg, 2012). However, previous research has mainly focused on one measure of subjective
well-being, overall life satisfaction (e.g., Luhmann et al., 2012, 2014; Luhmann & Eid, 2009),
for exceptions, see Knabe et al. (2010)). The German Job Search Panel (GJSP) intends to
broaden this perspective. It is a collection of monthly panel data of jobseekers, which allows
researchers examining the impact of unemployment on three different dimensions of well-being
at the same time – subjective, eudaimonic and physical well-being. In the process, multiple
indicators are available for each construct. For instance, subjective well-being can be elicited
via different measures of cognitive well-being as well as measures of affective well-being. As
a result, the GJSP enables researchers to analyze if the changes in well-being following
unemployment vary between well-being constructs. These differences may be mapped over
time, with relatively short time lags of one month between the points of measurement.
This data report describes the GJSP. A first focus is on the data generating process. It is
based on the notification process of jobseekers with the German Federal Employment Agency
(Bundesagentur für Arbeit, BA) and identifies people who consider likely that their
employment relationship ends in the course of the following months to invite them to participate
in a panel survey about job search. The sampling places special emphasis on mass layoffs as
reason for the termination of a job. Participants are then surveyed once a month over a period
of up to two years. These comprehensive panel data are collected using an innovative generic
smartphone app. The survey data may be linked to high-quality register-based data of the
Institute for Employment Research (IAB) and to people’s objectively measured chronic stress
levels, ascertained by hair cortisol. These two features are further novelties in the research on
unemployment and well-being.
During the recruitment of participants, we had to deal with low sign-up rates initially. This
issue was aggravated further by the fact that less than half of the persons that signed up could
actually be considered for the final sample for methodological reasons. We therefore adjusted
the way we contacted participants in several ways over the recruitment period. This included
extending the sample to non-mass-layoff-related jobseeker registrations. Thus, a second focus
of this data report is to give an account of these adjustments and the evolution of the sign-up
rate. Moreover, we describe the scheme used to incentivize repeated participation over time and
give an overview of the collected data.
Unavoidably, sign-up to a smartphone-based survey is non-random. A third focus of this data
report is therefore on sample selectivity. This concerns initial participation, survival in the panel
over time, consent to linking administrative records to the survey data as well as the willingness
to provide sensitive health data through hair cortisol. Our sampling process allows us to
investigate selectivity in depth, as we are able to link participation data (‘paradata’) to the
register data available at IAB. While the average non-response bias is only 3.7% across
characteristics, it turns out that females and relatively educated people are significantly more
likely to sign up for the study and to continuously participate over many months than males and
less educated people. Younger age groups are more likely to participate in general whereas
older participants are more willing to provide hair samples for cortisol measurement.
2. Sampling
For our data collection, the Data and IT Management (DIM) unit of IAB identified workers
who had registered as jobseekers in the German unemployment insurance system prior to
entering unemployment. In Germany, to be eligible for insurance-based unemployment benefits
(Arbeitslosengeld), employees are obliged to register as job seeking with the employment
agency at the latest three months before they expect (having) to terminate their job. If they learn
about the termination of their employment later, they will have to register as a jobseeker within
three days. Otherwise, a cut-off period for the receipt of unemployment benefits may apply. By
contacting them early on when they had just registered as jobseekers, we ensured that our survey
would include one measurement wave before workers potentially enter unemployment.
Many people who register as jobseekers, however, do not enter unemployment later on. For
instance, if employers announce mass layoffs, it is often unclear for some time who actually
loses work and who is able to stay with the firm. Fixed-term contracts are also often prolonged
shortly before the expiration date which means that people register as jobseekers pro forma.
Hence, many workers who have registered as jobseekers three months before possibly
terminating their jobs eventually stay employed at the same firm. Stephan (2016) shows that
only slightly more than half of the people that register as job seeking actually become
unemployed within the following three months. A relatively high share of registered jobseekers
stays employed with the same firm or immediately takes up a new job. The GJSP exploits this
institutional background to provide a comparison group of employed workers for individuals
entering unemployment. Both groups are surveyed after the registration of jobseekers, whether
or not they actually become unemployed later on. The fact that both groups start the panel as
registered jobseekers ensures some principle similarity.
IAB-DIM obtains the address data of recently registered jobseekers through the data
warehouse of the Federal Employment Agency, with a delay of about two to eight weeks after
registration. For the period from November 2017 to May 2019, they identified jobseekers that
th th
registered between the 15 day of the second-last month to the 14 day of the last month as
potential participants of the GJSP. This means we sampled jobseekers during a period of low
overall unemployment in Germany, varying between 3% and 4% over our sampling phase
(OECD, 2022). People were contacted if they met the following conditions1: German
nationality (as our surveys were conducted in German language only), age between 18 and 60
years, the current employment relationship is subject to social insurance contributions
(sozialversicherungspflichtige Beschäftigung) and has lasted for at least 150 days (i.e.,
probation is most likely over). Moreover, their registration as jobseeker had not been directly
preceded by a previous registration. Partly due to these restrictions, we primarily sampled
jobseekers that were eligible for unemployment benefits in case of job loss.2
Due to our particular interest in the effects of involuntary unemployment, we started off
drawing samples of registered jobseekers who were likely affected by a mass layoff only (over
the whole recruitment period, N = 79,092 invites were sent out to this group).3 However, we
decided to draw an additional sample from August 2018 onwards as our mass layoff sample
had filled up only slowly over time. Therefore, we additionally identified an equally sized
random sample of recently registered jobseekers out of the group of people who did not fulfill
the requirements of a mass layoff (from August 2018 to May 2019, N = 48,109). While a focus
on mass layoffs limits the extent of unobservable heterogeneity, comparing multiple reasons
for job search with respect to their impact on well-being is of interest for researchers in itself
(Chadi & Hetschko, 2018).
IAB-DIM initiated the dispatch of invitation letters and emails through the postal office of the Federal
Employment Agency. This procedure also ensured that we did not have access to the address data.
Provided that the unemployed person has been employed for 12 months in the last 30 months, unemployment
benefits replace 60% (people without children) / 67% (people with children) of the previous net salary. The receipt
usually expires after 12 months. The duration is shorter for people who were employed for less than two years
before entering unemployment and longer for workers who are at least 50 years old and were employed for at least
30 months before entering unemployment. Afterwards, people are eligible for means-tested welfare benefits
(Arbeitslosengeld II).
We apply the thresholds for a notifiable mass layoff according to §17(1) of the German employment protection
act (Kündigungsschutzgesetz): > 5 layoffs in plants with 21 to 59 employees, 10% in plants with 60 to 250
employees, > 25 layoffs in plants with 251 to 499 employees, ≥ 30 layoffs in plants with 500 or more employees.
In addition, we assume a mass layoff in a plant of ≤ 20 employees if the staff reduced by more than five people.
As it takes some time to learn about newly registered jobseekers through the data warehouse of
the BA, many people had already stopped working when they received the invitation to the
study. We therefore used the first couple of questions of the app-based survey (‘entry survey’)
to carry out further exclusions. Most importantly, people who reported to have become
unemployed already at the time of the entry survey were not considered further for the study
(N = 1,424).4 Again, this was to ensure the availability of a pre-event measure of well-being.
215 subjects were excluded because they were still in their probation period. Of the remaining
group, every third person was randomly excluded to run an experiment on the effect of
participating in the study on future labor market outcomes (N = 940). Moreover, 246 individuals
did not submit their entry survey. While 4,698 persons signed up for the study initially, only
1,873 (40%) people were kept in the final sample.5
The survey was conducted by an independent research institute, the Happiness Research
Organization (HRO). The HRO developed a generic app specifically for this purpose, the
Happiness Analyzer (Ludwigs & Erdtmann, 2019). The app was adjusted and used for
commercial use such as employee surveys and for research (for previous applications, see, e.g.,
Hendriks et al., 2016; Ludwigs et al., 2020).6 Note that people did not need to be online when
participating. Questionnaires and the gathered data were locally stored and only transmitted
once people had Wi-Fi access.
3. Contact modes and adjustments over time
recruitment period.7 Note that the number of people that were invited would be half as high
from August 2018 onwards had we not extended invitations to a second sample of non-mass-
layoff jobseekers. The number of contacted jobseekers peaked in November 2018. This might
reflect a high number of people terminating seasonal jobs or having contracts that expire at the
end of the year, thus noticing the employment agency in fall.
45 individuals claimed to be employed and were included in the final sample even though they were already no
longer employed at the time of their jobseeker registration according to later updates of the administrative data.
The numbers presented here might slightly differ from substantive analyses based on the GJSP due to specific
strategies of dealing with a small number of people who were invited more than once or who potentially falsely
claimed to be still employed at sign-up. These cases can be identified via variables in the dataset.
During our recruitment period, over 95% of smartphones used in Germany relied on Android or iOS as operating
systems (Statista, 2022). The Happiness Analyzer runs on both, circumventing selective participation dependent
on system software.
in November 2017 and December 2017 (1,430 invitees combined).
People were initially contacted via a physical letter sent to their home addresses (Appendix B,
Material B1). The letter highlighted the study purposes and informed about the institutions
involved. It also provided extensive information on data privacy (Appendix B, Material B2)
and included a personal token needed to register for the study. The initial sign-up rate in January
people installed the app and inserted their token successfully. Accordingly, the number of
people actually recruited (final sample) was tiny. We therefore decided to augment the letter by
an elaborate and professionally designed flyer (see Appendix B, Material B3). Apart from other
nicely presented information about the study, it henceforth contained QR codes directing
subjects to the Google PlayStore or Apple Appstore to download the survey app, which were
formerly part of the letter.
The sign-up rate soared significantly after the flyer was included in the envelope, providing
descriptive support for its effectiveness in recruiting people for the study. We kept providing
flyers with the physical letters until the end of the recruitment period. Still, the final sample
filled up slowly. As mentioned before, we therefore decided to randomly draw an equally sized
second sample of non-mass-layoff jobseekers from the eligible group of individuals, doubling
the number of potential participants (‘dual sampling’).
Moreover, if an email address was available to the BA, people were invited via email instead
of a physical letter from August 2018 onwards (see Appendix B, Material B4). Emails
conveniently enable participants to use a link to download the app on their smartphone. Links
can lead to informative websites. However, email invitations may be misinterpreted as spam
and fail to convey the legitimacy of the study. It is therefore a priori unclear whether this step
increases participation. At least, contacting people by email helps to save postage costs.
August 2018 to October 2018. It turns out that many more people who were contacted by email
installed the app and registered for the survey. This does not need to be an effect of the contact
mode though. People who provide an email address might differ also in other respects from
those who do not, for instance, when it comes to age, openness to using digital tools, concerns
about data privacy and thus be more likely to participate in an app-based study than the latter.
To explore these possibilities and to exploit the potential of the GJSP for methodological
research, we ran an experiment on the mode of contact from November 2018 until the end of
the recruitment period. We randomly assigned three contact modes to equally sized subgroups
of those people who provided an email address (see Lawes et al., 2022a): physical letter, email
and a physical pre-announcement letter followed by an email (Appendix B, Material B5).
Source. Paradata on GJSP participation.
physical letters nor emails yield higher participation rates. People that provide an email address
are simply also more likely to participate in this kind of study. Sending a pre-announcement
letter notifying people that they will receive an email inviting them to the GJSP leads to a
significantly higher sign-up rate than the other conditions. It seems to combine the advantages
of both modes, conveying the legitimacy of the study (physical pre-announcement letter) and
convenience when it comes to downloading the app (follow-up email).
As a final adjustment toward the end of the recruitment period, we focused on individuals
who received the letter because they had not provided an email address to the Federal
Employment Agency. In particular, we tried to formulate the invitation in a simpler and more
appealing way. In addition, we experimented with goal framing, placing stronger emphasis on
either the monetary incentives provided by the study or the normative goal of making a
contribution to society by participating in a research project (Lindenberg & Steg, 2007). Against
the background of a limited budget and improving sign-up rates, we terminated recruiting
further participants in May 2019.
Despite the positive trend in sign-up to the GJSP over time, the participation rate seems
relatively low, overall. People might have hesitated to sign up for an obviously burdensome
study that requires them to indicate plenty of information over a long time every month. Others
may have anticipated that they are not part of the target group anymore as they had already lost
their jobs. Moreover, people could contact the research team for queries and to provide feedback
via telephone and email after they received the invitation. Based on their many calls and
messages, we suspect that the extensive public discussion in the run-up to the introduction of
the EU’s General Data Protection Regulation (GDPR) in spring 2018 did not help in recruiting
participants, despite the fact that our study complied with all rules of that directive from the
beginning. Other major concerns were of a technical nature, such as uncertainty about one’s
eligibility for the study, disabled tokens and switching smartphones during participation.8
Participation in app-based surveys is generally higher if subjects are recruited from a
population of active survey participants, which are obviously prone to take part in studies. Even
in these cases the sign-up rate is often below 20%, sometimes only 5%.9 There is a lack of
evidence on sign-up rates to app-based panel surveys for samples of people who were not
previous survey participants, as in our case. We suspect that people’s concerns about data
protection with respect to smartphone usage generally limit participation in app-based surveys.
Note. Panel A depicts sign-up rates of people who received a physical letter, as they had not provided
an email address and people for which an email address was available. Panel B depicts sign-up
rates for people who provided an email address and were randomly assigned to one of the three
contact modes. It is based on Lawes et al. (2022a). Whiskers denote 95% confidence intervals.
Source. Paradata on GJSP participation.
Once used, tokens needed to be reactivated to avoid multiple participation of the same person.
Kreuter et al. (2019) invited active participants of the German PASS panel to take part in a mobile data collection.
Further examples include Scherpenzeel (2017) and Jäckle et al. (2019) based on British UKHLS data. Keusch et
al. (2019) invited previously interviewed refugees to provide passive data through an app.
4. Incentives and smartphone provision
Continued participation is key to any panel survey. We thus rewarded people who had steadily
of a money transfer or an Amazon voucher for each month they completed at least 80% of all
items in the first year. Continued participation was rewarded further by a loyalty bonus of 40
euros after the sixth and the twelfth month.10 People who did not reach the threshold of 80% in
two months lost eligibility for the loyalty bonus. Those who sent in hair bundles for the
measurement of cortisol got another incentive of 10 euros per hair sample. Self-administered
hair sampling entailed extracting a hair bundle and sending it to us in a readymade envelop.
Subjects could get feedback on their cortisol values if they completed all five measurements.
Regular incentives were no longer paid during the second year of participation, as the first
year was most important for our study purposes. However, people could get lottery tickets in
year two. After two years, we drew lots for cash prices worth 5,000 euros in total. Subjects who
still participated after April 2020 received a cash incentive of 10 euros per month again because
we wanted to ensure that they continued to participate in order to map their well-being around
waves of Covid-19. We also continued hair sampling for this group.
An obvious concern about an app-based study is the participation of people who lack access
to smartphones. Using apps as survey mode favors the participation of young and educated
people as well as people living in areas with widespread broadband internet access. To
encourage participation of jobseekers who did not possess a smartphone to participate in the
study, we allowed them to complete the entry survey online by using any computer with internet
access and to request a smartphone provided through the HRO. Once they received the
smartphone, they had to use the app to continue participating. As we will describe in more detail
in the next section, the most important reason for us to require smartphones as survey mode is
the collection of data on affective well-being via experience sampling. The 179 individuals who
borrowed a smartphone did not receive any payments or Amazon vouchers. They could keep
the smartphone as a gift after repeatedly participating in the panel study upon the condition that
they had completed at least 80% of all questionnaires in year one. This created an incentive to
continue participation over time also for this group of people. The monetary value of the
smartphone resembled the money obtained through incentives when participating continuously
using one’s own device.
Initially we paid 15 euros every other month of the first year, ten euros every other month of the second year
and no loyalty bonus. The incentive scheme changed for current and new participants.
5. Collected data
Once people had successfully installed the survey app, completed the entry survey and were
included in the final sample, the app notified them about new questionnaires on up to eight
consecutive days each month over a period of two years. This allowed us to balance the burden
of participation over several days during a month. The time needed to complete a daily survey
was roughly five minutes. As some questions were asked only every three months or six
months, participation in months 1, 4, 7, 10, 13, 16, 19, 22 and 25 was more time consuming.
response to the Covid-19 pandemic, we added items in relation to the event, such as experience
with a Covid-19 infection and taking part in the German job retention scheme (‘Kurzarbeit, i.e.
‘short-time work’) as well as a few other items (highlighted bold). The wording of all questions
can be found in the GJSP Codebook (2023) or on the Open Science Framework’s (OSF)
legally restricted. The collection of well-being data followed guidelines by the OECD and the
US National Academy of Sciences (National Research Council, 2013; OECD, 2013). Cognitive
well-being (module C) was assessed by the Satisfaction With Life Scale (Diener et al., 1985),
Cantril’s (1965) ladder and life domain-specific satisfaction indicators.
For measuring affective well-being (module A), we used the experience sampling method
(ESM; Hektner et al., 2007; Larson & Csikszentmihalyi, 1983), among others. Measuring
affective well-being is ideally based on real-time information, since retrospective measurement
is prone to errors (OECD, 2013). Before the smartphone era, researchers had to equip subjects
with pagers that needed to be carried at all times. Now, participants only need to install the app
on their smartphone and wait for the ESM notifications, as most of them carry their smartphone
anyway. This renders collecting ESM data much less expensive and burdensome for
participants than before, allowing for large sample sizes and repeated measurement (Bryson &
MacKerron, 2017).
In our study, people were requested to complete an ESM for their current activity on six
randomly chosen time points over the course of one day per month. Those who completed less
than three episodes were asked to repeat the ESM module at the end of the monthly
questionnaire cycle. The mood states elicited were based on the Multidimensional Mood State
Questionnaire (Multidimensionaler Befindlichkeitsfragebogen, see Steyer et al. (1997)).
Specifically, panelists were asked about their momentary happiness/unhappiness,
awakeness/sleepiness and calmness/restlessness.
We also employed the day reconstruction method (DRM; Kahneman et al., 2004) to assess
affective well-being. The DRM requires people to complete a diary of the previous day with all
activities, for which they are then to indicate their emotional state. We ascertained the emotions
happy, nervous, sad, worried, enthusiastic, bored, lonely and stressed. Later on, we also
included a summary affective well-being measure concerning the previous day. In addition,
people completed a German short version of the Center of Epidemiological Studies Depression
Scale (CES-D / Allgemeine Depressionsskala, see, e.g., Hautzinger et al. (2012) over the
previous week which can be seen as a measure of mental health as well as affective well-being.
Eudaimonic well-being (module E) was measured in three ways. First, by using an adapted
24-item short version of the Ryff (1989) Scale of Psychological Well-Being which was obtained
from applying confirmatory factor analysis in combination with an ant algorithm (Schultze,
2017). Four items each assessed the six facets self-acceptance, positive relations, autonomy,
environmental mastery, personal growth and purpose in life. Second, by asking individuals
during each ESM episode whether their current activity is perceived as meaningful. Third,
respondents were asked in the DRM if they had perceived the activity as meaningful.
Further main psychological variables (module P) included a 21-item version of the five
facets proactive coping, reflective coping, strategic planning, instrumental support seeking and
avoidance coping of the Proactive Coping Inventory (Greenglass et al., 1999). It was reduced
to 21 items by a principal component analysis. We also included selected dimensions of the
AVEM (Arbeitsbezogenes Verhaltens- und Erlebensmuster, work-related behavior and
experience patterns, see Schaarschmidt & Fischer (2008), a mood regulation inventory
(Lischetzke et al., 2001) and the subscale ‘perceived available support’ of the Berlin Social
Support Scales (Schulz & Schwarzer, 2003). Finally, we augmented our version of the CES-D
with similarly worded questions on perceived stress and loneliness.
For the measurement of physical health (module H), we closely followed the German
Ageing Survey (DEAS; Engstler et al., 2013) and asked people, inter alia, about their current
health status, diagnosed diseases and health expectations. As mentioned before, we also
measured hair cortisol as a biomarker for chronic stress (Stalder & Kirschbaum, 2012). Chronic
stress increases the risk for cardiovascular diseases (Dimsdale, 2008), type 2 diabetes (Pouwer
et al., 2010), ulcerative colitis (Mawdsley et al., 2006) and decreases fertility (Ebbesen et al.,
2009). We further asked subjects to indicate which hair styling products they use, how long
they are exposed to the sunlight and whether they use any cortisol-based medication
(Dettenborn et al., 2012). The Dresden Lab Service determined the chronic stress level over the
past three months in 3 cm hair segments
Module Frequency
C C0 Satisfaction With Life Scale Monthly
C1 Cantril’s ladder Quarterly
C2 Satisfaction with various life domains Monthly
A A0 Day reconstruction method (feelings) Quarterly
A1 Yesterday’s mood (new) Monthly
A2 Experience sampling: Multidimensional Mood State Questionnaire Monthly
A3 Center for Epidemiologic Studies Depression Scale Monthly
E E0 Ryff Scale of Psychological Well-Being Monthly
E1 Experienced meaningfulness (as part of A0 / A1) Monthly / quarterly
P P0 Proactive Coping Inventory Monthly
P1 Perceived stress (as part of A0 and add-on to A3) Monthly
P2 Loneliness (as part of A0 and later also added to A3 Monthly
P3 Work-related Behavior and Experience Patterns (selected dimensions) Entry survey
P4 Tendency to resign and problem coping Monthly
P5 Mood regulation questionnaire Monthly
P6 Berlin Social Support Scale, Perceived support Monthly (adjusted)
H H0 Self-assessed health Monthly
H1 Changes in health (last five years) Entry survey
H2 Expected changes in health (next three years) Entry survey
H3 Weight Monthly
H4 Disability Biyearly
H5 Diseases Monthly
H6 Doctoral visits (last three months) Quarterly
H7 Overnight stays in hospital (last three months) Quarterly
H8 Height Entry survey
H9 Hair cortisol concentration as a biomarker of chronic stress Quarterly
H10 Worries about health and beyond (new) Monthly
H11 Covid-19 infection (new) Monthly
H12 Covid-19 contact (new) Monthly
H13 Covid-19 quarantine (new) Monthly
0 00 Consent to record linkage Month 1, 2 or 3
01 Employment is still the same Entry survey
02 Start date of employment Entry survey
03 Reason for job seeker registration Entry survey
04 Working hours Entry survey
05 Long hours (adjusted) Entry survey
06 Earnings Entry survey
07 Job characteristics Entry survey
08 Employment-related expecation Entry survey
09 Smartphone awareness Entry survey
1 10 Marital status Biyearly
11 Partnership Biyearly
12 Employment status of partner Biyearly
13 Place of residence in 1989 Entry survey
14 Education / training Biyearly
15 Number of children Biyearly
16 Household income Monthly
17.1 Prejudice toward the unemployed (new) Monthly
17.2 Big five personality traits, risk aversion Quarterly
17.3 Patience (new) Monthly
18 Fairness, locus of control Quarterly
19 Religion Biyearly
2 20 Labour market status Monthly
21 Termination of employment relationship (adjusted) Monthly
22 Working hours Quarterly
23 Long hours Quarterly
24 Earnings Quarterly
25 Job characteristics Quarterly
26 Employment-related expecations Monthly (adjusted)
27 Kurzarbeit scheme (short-time work, new) Monthly
28 Key worker (new) Monthly
29 Working from home (new) Monthly
3 30 Reemployment planning Monthly
31 New job part-time or fulltime Monthly
32 Employability Monthly
33 Reservation wage Monthly
34 Re-employment expectations Monthly
35 Job search Monthly
36 Employment-related expectations Monthly
37 Unemployment benefits (Arbeitslosengeld) Monthly
38 Unemployment benefits II (Arbeitslosengeld II) Monthly
39 Re-employment intentions (new) Monthly
Note. Bold items were added/adjusted in April/July 2020. For all details on the items see the GJSP
What is more, we gathered data on multiple individual characteristics (modules numbered 0-3).
These were mostly based on the German Socio-Economic Panel (SOEP, see Wagner et al.,
2007), on the DEAS and on the survey ‘The Value of Work’ (Knabe et al., 2010). Subjects were
required to indicate their employment status, as we wanted to know when individuals had
entered unemployment or found a new job. We also asked them about their job search (if
unemployed), job characteristics (if employed), personality traits, family background and so
forth. For people who consented to linking the process data of the Federal Employment Agency,
information on previous times of employment, unemployment, benefit receipt, participation in
labor market policy schemes, among others, can be merged with the survey data.
6. Selectivity analysis
Participation
The final GJSP sample is not representative of the invited group of jobseekers, as we required
people to use a smartphone and as the response rate to our study invitation was low. In general,
the degree of non-representativeness (i.e., non-response bias) might be the higher the lower the
sign-up rate of particular sub-groups (Groves & Peytcheva, 2008). To document the degree of
non-response bias and identify patterns of selective participation, we merge paradata on study
participation with the Integrated Employment Biographies (IEB) of the IAB (v16). These
register-based data combine individual-level information on periods of dependent employment
(not as a public servant though), unemployment/welfare benefit receipt, job seeking and
participation in active labor market programs (see Jacobebbinghaus & Seth, 2007 for more
details on the IEB). A small number of individuals was accidentally contacted more than once
(636 individuals). In this report, each individual is included with their first jobseeker
registration only. Note that paradata on study participation can be linked to the IEB for all
contacted persons through an anonymized person identifier. On the contrary, linking survey
data with the IEB requires the explicit consent of participants.
All variables are measured at the time of registering as a jobseeker, i.e., shortly before
people received the study invitation. We exclude people who, according to the data, earn
unrealistically low wages (≤ 5 euros per day) or wages above the ceiling for social insurance
contributions (230 euros per day in 2020 for unemployment insurance in Western German
federal states), which are prone to measurement error. In addition to the IEB variables, we
include the recruitment month and a variable indicating belonging to the mass layoff sample.
people who signed up and the final sample of people who fulfilled the inclusion criteria.
Differences between people who signed up and people who were finally included may be driven
by the inclusion criteria. We treat people who did not sign-up as a reference group to test for
statistically significant differences between participants and non-participants. It turns out that
participants are significantly younger, more likely female, better educated and earn higher
wages than non-participants. They also have less work experience over the past ten years. The
federal state where people live as well as the recruitment month are also significantly correlated
with the probability of signing up. The sign-up rate in the mass-layoff sample was lower
compared to the non-mass-layoff samples, but the inclusion criteria seem to have corrected for
this bias by chance. What is more, the differences in characteristics between participants and
non-participants are highly similar to the whole sample in the group of jobseekers who were
contacted as part of the mass layoff sample (cf. Tables 2 and A2 in the Appendix).
Average non-response bias
One may also calculate the average absolute non-response bias (Y ) separately for both
absolute
definitions of participation (people who signed up initially and people who were finally
included). In line with the literature (e.g., Sakshaug et al., 2019), we compute proportions (Y )
of persons who participate (S) and compare them to the group of contacted jobseekers (JS)
across a wide range of categories (k = 1, …, K) of variables. The average absolute non-response
bias is the sum of all absolute differences between the two samples and the contacted
individuals (|Y − Y , |) for all categories, divided by the total number of categories:
k,S k JS
Y − Y
k,S k,JS
Average Absolute Bias = k=1
For binary variables only one category is considered (e.g., female). Ratio variables need to be
categorized to obtain proportions that can be compared between people who signed up / belong
to final sample and the eligible jobseekers. If their distribution is highly skewed (e.g., periods
of welfare benefit receipt over the past ten years), we collapse them into a binary variable (any
indication / no indication). Other ratio variables (e.g., age) are categorized into quartiles of the
The absolute non-response bias amounts to 3.0% in the group of people who signed up and to
3.7% in the final sample. Non-response biases are thus rather low. This is also true for
jobseekers who were invited to participate in the study after experiencing a mass layoff. The
average bias is 3.5% for group who signed up and 4.2% for final sample, respectively.
(1) Invited sample (2) Did not sign up (3) Signed up (4) Final sample
Mean (std. dv.) N Mean (std. dv.) N Mean (std. dv.) N Mean (std. dv.) N
Age (17 - 60) 41.25 (11.23) 127,201 41.35 (11.24) 122,503 38.50*** (10.57) 4,698 38.62*** (10.26) 1,873
Tenure (.41 - 22.1) 3.51 (4.81) 123,095 3.51 (4.83) 118,551 3.39 (4.24) 4,544 3.47 (4.23) 1,826
Employment history over past 10 years (measured in years)
Regular employment (.21 - 10) 7.27 (2.56) 127,196 7.29 (2.55) 122,498 6.81*** (2.67) 4,698 6.79*** (2.65) 1,873
Unemployment benefit receipt (0 - 5.33) 0.48 (0.69) 127,196 0.49 (0.69) 122,498 0.34*** (0.56) 4,698 0.33*** (0.55) 1,873
Welfare benefit receipt (0 - 10) 0.71 (1.71) 127,196 0.71 (1.72) 122,498 0.54*** (1.46) 4,698 0.47*** (1.34) 1,873
Registered as jobseeker (0 - 10) 1.66 (2.06) 127,196 1.67 (2.07) 122,498 1.34*** (1.84) 4,698 1.30*** (1.75) 1,873
Participation in policy schemes (0 - 10) 0.28 (0.67) 127,196 0.28 (0.68) 122,498 0.23*** (0.61) 4,698 0.19*** (0.54) 1,873
Female (shares) 0.40 (0.49) 127,198 0.40 (0.49) 122,500 0.50††† (0.50) 4,698 0.51††† (0.50) 1,873
Highest level of qualification (shares)
Missing 0.00 (0.00) 127,201 0.00 (0.00) 122,503 0.00††† (0.00) 4,698 0.00††† (0.00) 1,873
None 0.05 (0.21) 127,201 0.05 (0.22) 122,503 0.02††† (0.15) 4,698 0.02††† (0.12) 1,873
Vocational training 0.61 (0.49) 127,201 0.62 (0.49) 122,503 0.35††† (0.48) 4,698 0.30††† (0.46) 1,873
A-levels 0.01 (0.11) 127,201 0.01 (0.11) 122,503 0.02††† (0.14) 4,698 0.01††† (0.12) 1,873
A-levels and vocational training 0.14 (0.34) 127,201 0.13 (0.34) 122,503 0.19††† (0.39) 4,698 0.19††† (0.39) 1,873
Tertiary degree 0.19 (0.39) 127,201 0.18 (0.39) 122,503 0.42††† (0.49) 4,698 0.48††† (0.50) 1,873
Federal state (shares)
Schleswig-Holstein 0.03 (0.18) 127,148 0.03 (0.18) 122,450 0.03††† (0.17) 4,698 0.03††† (0.16) 1,873
Hamburg 0.02 (0.14) 127,148 0.02 (0.14) 122,450 0.03††† (0.18) 4,698 0.03††† (0.18) 1,873
Lower Saxony 0.11 (0.31) 127,148 0.11 (0.31) 122,450 0.09††† (0.29) 4,698 0.10††† (0.31) 1,873
Bremen 0.01 (0.10) 127,148 0.01 (0.10) 122,450 0.01††† (0.10) 4,698 0.01††† (0.11) 1,873
North Rhine Westphalia 0.19 (0.39) 127,148 0.19 (0.39) 122,450 0.19††† (0.39) 4,698 0.18††† (0.39) 1,873
Hesse 0.06 (0.24) 127,148 0.06 (0.24) 122,450 0.05††† (0.22) 4,698 0.06††† (0.23) 1,873
Rhineland Palatinate 0.05 (0.21) 127,148 0.05 (0.21) 122,450 0.04††† (0.19) 4,698 0.03††† (0.18) 1,873
Baden Württemberg 0.09 (0.29) 127,148 0.09 (0.29) 122,450 0.10††† (0.31) 4,698 0.11††† (0.31) 1,873
Bavaria 0.18 (0.38) 127,148 0.18 (0.38) 122,450 0.16††† (0.37) 4,698 0.14††† (0.35) 1,873
Saarland 0.01 (0.12) 127,148 0.01 (0.12) 122,450 0.01††† (0.11) 4,698 0.01††† (0.11) 1,873
Berlin 0.05 (0.21) 127,148 0.05 (0.21) 122,450 0.09††† (0.29) 4,698 0.09††† (0.29) 1,873
Brandenburg 0.04 (0.19) 127,148 0.04 (0.19) 122,450 0.04††† (0.18) 4,698 0.04††† (0.20) 1,873
Mecklenburg Western Pomerania 0.02 (0.15) 127,148 0.02 (0.15) 122,450 0.02††† (0.15) 4,698 0.02††† (0.15) 1,873
Saxony 0.06 (0.24) 127,148 0.06 (0.24) 122,450 0.06††† (0.24) 4,698 0.06††† (0.24) 1,873
Saxony Anhalt 0.04 (0.20) 127,148 0.04 (0.21) 122,450 0.03††† (0.18) 4,698 0.03††† (0.18) 1,873
Thuringia 0.04 (0.20) 127,148 0.04 (0.20) 122,450 0.03††† (0.18) 4,698 0.04††† (0.18) 1,873
Abroad 0.00 (0.02) 127,148 0.00 (0.02) 122,450 0.00††† (0.00) 4,698 0.00††† (0.00) 1,873
Mass layoff sample (share) 0.62 (0.48) 127,201 0.62 (0.48) 122,503 0.56††† (0.50) 4,698 0.63 (0.48) 1,873
Invited sample Did not sign up Signed up Final sample
Mean (std. dv.) N Mean (std. dv.) N Mean (std. dv.) N Mean (std. dv.) N
Recruitment month (shares)
Pre-test (November, December 2017) 0.01 (0.11) 127,201 0.01 (0.11) 122,503 0.00††† (0.07) 4,698 0.00††† (0.05) 1,873
January 2018 0.06 (0.24) 127,201 0.06 (0.24) 122,503 0.02††† (0.14) 4,698 0.02††† (0.14) 1,873
February 2018 0.04 (0.20) 127,201 0.04 (0.20) 122,503 0.02††† (0.14) 4,698 0.02††† (0.15) 1,873
March 2018 0.03 (0.16) 127,201 0.03 (0.16) 122,503 0.03††† (0.16) 4,698 0.04††† (0.19) 1,873
April 2018 0.02 (0.14) 127,201 0.02 (0.14) 122,503 0.01††† (0.11) 4,698 0.01††† (0.09) 1,873
May 2018 0.03 (0.17) 127,201 0.03 (0.17) 122,503 0.03††† (0.16) 4,698 0.03††† (0.18) 1,873
June 2018 0.03 (0.18) 127,201 0.03 (0.18) 122,503 0.03††† (0.18) 4,698 0.04††† (0.19) 1,873
July 2018 0.03 (0.16) 127,201 0.03 (0.16) 122,503 0.02††† (0.14) 4,698 0.02††† (0.15) 1,873
August 2018 0.06 (0.25) 127,201 0.06 (0.25) 122,503 0.07††† (0.26) 4,698 0.07††† (0.26) 1,873
September 2018 0.05 (0.21) 127,201 0.05 (0.21) 122,503 0.05††† (0.22) 4,698 0.05††† (0.23) 1,873
October 2018 0.04 (0.21) 127,201 0.05 (0.21) 122,503 0.04††† (0.20) 4,698 0.03††† (0.18) 1,873
November 2018 0.15 (0.36) 127,201 0.15 (0.36) 122,503 0.19††† (0.39) 4,698 0.22††† (0.42) 1,873
December 2018 0.08 (0.27) 127,201 0.08 (0.27) 122,503 0.08††† (0.27) 4,698 0.05††† (0.22) 1,873
January 2019 0.09 (0.28) 127,201 0.09 (0.28) 122,503 0.08††† (0.27) 4,698 0.06††† (0.24) 1,873
February 2019 0.07 (0.26) 127,201 0.07 (0.26) 122,503 0.07††† (0.25) 4,698 0.05††† (0.22) 1,873
March 2019 0.06 (0.24) 127,201 0.06 (0.24) 122,503 0.06††† (0.24) 4,698 0.06††† (0.24) 1,873
April 2019 0.05 (0.23) 127,201 0.05 (0.23) 122,503 0.06††† (0.24) 4,698 0.06††† (0.24) 1,873
May 2019 0.09 (0.29) 127,201 0.09 (0.29) 122,503 0.13††† (0.33) 4,698 0.15††† (0.35) 1,873
Employment status (shares)
Employed, contributing to social insurance 0.97 (0.18) 127,201 0.97 (0.18) 122,503 0.97 (0.18) 4,698 0.97 (0.16) 1,873
Marginally employed 0.00 (0.04) 127,201 0.00 (0.04) 122,503 0.00 (0.04) 4,698 0.00 (0.03) 1,873
Other (i.e. apprenticeship) 0.03 (0.17) 127,201 0.03 (0.17) 122,503 0.03 (0.17) 4,698 0.02 (0.15) 1,873
Part-time job (share) 0.24 (0.43) 123,095 0.23 (0.42) 118,551 0.29††† (0.46) 4,544 0.33††† (0.47) 1,826
Daily wage (5.02 - 229.35) 93.02 (42.22) 120,288 92.59 (41.94) 115,876 104.33*** (47.73) 4,412 108.09*** (47.72) 1,795
Individuals 127,201 122,503 4,698 1,873
Note. Asterisks denote significant differences between the samples of people who signed up / the final sample and the sample of people who did not sign-up: ***p<0.001, **p<0.01,
*p<0.05. We performed Chi2 tests for categorial and dummy variables: †,††, ††† denote significance at least at 5%, 1% and 0.1% level respectively.
Source. Paradata on GJSP participation and IEB version v16.
Multivariate analyses
Next, we run separate multivariate analyses on the probabilities of signing up and of belonging
to the final sample to identify drivers of selective participation. For instance, the finding that
people with less work experience in employment subject to social insurance contributions over
Likewise, the fact that both educational attainment and wages increase the probability to
corresponding logit estimates and the marginal effects in percentage points of the probability
to belong to the respective sample. Still, young individuals, females and part-time workers were
relatively likely to sign up and be part of the final sample, despite potential overlap between
these groups, which is now controlled for.11 A lower daily wage and longer previous spells of
receiving unemployment benefits decrease the likelihood of signing up and final sample
inclusion. People in the mass layoff sample were less likely to sign up, but more likely to be
findings on significant predictors of participation emerge likewise within the mass layoff
sample.
Most strikingly, education has a strong effect on the probability to participate in the GJSP.
For example, people with a tertiary degree are about 3.9 percentage points more likely to sign
up than people with no degree when all other covariates are at their mean (mass layoff sample:
3.6 p.p.). This stark difference reduces to 1.7 percentage points (mass layoff sample: 1.5 p.p.)
when it comes to the probability of belonging to the final sample. Generally, the marginal
effects (and, hence, the conditional variable-specific non-response biases) appear smaller for
the final sample than for sign up.12
According to Lawes et al. (2022a), the gender difference in sign-up would not exist had we been able to invite
everyone by a pre-announcement letter and a subsequent email. Males are almost as likely to sign up as females
in the corresponding treatment condition of their experiment.
Note that this observation is not based on tests for statistically significant differences.
Probability of signing up Probability of belonging to final
sample
Logit (Standard Marginal Logit (Standard Marginal
estimates errors) effects estimates errors) effects
Age in years / 10 -0.181*** (0.018) -0.507*** -0.187*** (0.028) -0.194***
Tenure in years / 10 0.031 (0.044) 0.086 0.058 (0.068) 0.060
Employment history (over past 10 years)
Regular employment (.21 - 10) -0.011 (0.008) -0.030 -0.022 (0.012) -0.023
Unemployment benefit receipt (0 - 5.33) -0.146*** (0.041) -0.408*** -0.208*** (0.063) -0.216***
Welfare benefit receipt (0 - 10) -0.060* (0.024) -0.167* -0.165*** (0.035) -0.171***
Registered as jobseeker (0 - 10) 0.046* (0.022) 0.130* 0.139*** (0.031) 0.144***
Participation in policy schemes (0 - 10) 0.056 (0.029) 0.156 -0.009 (0.050) -0.009
Female (shares) 0.249*** (0.034) 0.697*** 0.282*** (0.053) 0.293***
Level of qualification (ref. no degree)
Vocational training 0.339** (0.107) 0.952** 0.479* (0.193) 0.497*
A-levels 1.083*** (0.151) 3.037*** 1.021*** (0.271) 1.059***
A-levels and vocational training 1.068*** (0.110) 2.994*** 1.316*** (0.196) 1.366***
Tertiary degree 1.397*** (0.109) 3.917*** 1.666*** (0.194) 1.729***
Federal state (ref. Schleswig Holstein)
Hamburg 0.228 (0.126) 0.640 0.368 (0.201) 0.381
Lower Saxony -0.024 (0.104) -0.068 0.234 (0.170) 0.243
Bremen -0.043 (0.184) -0.120 0.289 (0.266) 0.300
North Rhine Westphalia 0.017 (0.098) 0.047 0.135 (0.163) 0.140
Hesse -0.217 (0.114) -0.607 -0.001 (0.183) -0.001
Rhineland Palatinate -0.019 (0.121) -0.053 0.089 (0.199) 0.092
Baden Württemberg 0.062 (0.103) 0.175 0.215 (0.170) 0.223
Bavaria 0.049 (0.099) 0.137 0.079 (0.166) 0.082
Saarland -0.004 (0.169) -0.011 0.097 (0.273) 0.101
Berlin 0.359*** (0.106) 1.006*** 0.416* (0.174) 0.432*
Brandenburg 0.168 (0.123) 0.471 0.519** (0.193) 0.538**
Mecklenburg Western Pomerania 0.154 (0.141) 0.431 0.455* (0.219) 0.472*
Saxony 0.116 (0.110) 0.325 0.216 (0.181) 0.224
Saxony Anhalt 0.089 (0.125) 0.249 0.295 (0.202) 0.306
Thuringia 0.093 (0.125) 0.261 0.344 (0.199) 0.357
Mass layoff sample -0.114** (0.035) -0.321** 0.123* (0.055) 0.128*
Recruitment month (ref. November 2018)
Pre-test (November, December 2017) -0.637** (0.220) -1.787** -1.397** (0.453) -1.450**
January 2018 -0.607*** (0.113) -1.703*** -0.790*** (0.180) -0.820***
February 2018 -0.297** (0.113) -0.832** -0.368* (0.169) -0.382*
March 2018 0.030 (0.101) 0.084 0.020 (0.142) 0.021
April 2018 -0.336* (0.144) -0.943* -0.786** (0.251) -0.816**
May 2018 -0.314** (0.103) -0.879** -0.347* (0.143) -0.360*
June 2018 -0.026 (0.092) -0.074 -0.130 (0.133) -0.135
July 2018 -0.277* (0.116) -0.777* -0.422* (0.172) -0.437*
August 2018 -0.060 (0.068) -0.168 -0.203* (0.103) -0.210*
September 2018 -0.003 (0.079) -0.009 -0.029 (0.117) -0.030
October 2018 -0.057 (0.085) -0.159 -0.364* (0.143) -0.378*
December 2018 -0.016 (0.067) -0.046 -0.508*** (0.119) -0.527***
January 2019 0.001 (0.066) 0.003 -0.334** (0.110) -0.347**
February 2019 -0.087 (0.069) -0.245 -0.403*** (0.114) -0.418***
March 2019 0.018 (0.072) 0.049 -0.046 (0.108) -0.047
April 2019 -0.029 (0.074) -0.081 -0.106 (0.113) -0.110
May 2019 0.171** (0.056) 0.480** 0.162* (0.081) 0.168*
Part-time job (share) 0.187*** (0.040) 0.525*** 0.399*** (0.061) 0.414***
Daily wage in euros / 10 0.043*** (0.004) 0.120*** 0.063*** (0.007) 0.065***
Individuals 120,209 120,209 117,592 117,592
probability to sign up / belong to the final sample of the GJSP survey. The number of individuals is lower
included in the estimation. ***p<0.001, **p<0.01, *p<0.05.
Source. Paradata on GJSP participation and IEB version v16.
Compliance with record linkage and hair sampling
All analyses considering hair cortisol or linking survey data to administrative data would be
subject to further sample selection unless the willingness to provide hair samples or to give
the final sample differs from the groups who expressed this willingness. It also provides figures
on another relevant comparison group, the subsample of people that were asked to send hair
samples / consent to record linkage which is not the same as the final sample. Differences in
this respect may originate from attrition up to the points where we inquired if people were
prepared to comply with our requests (cortisol: end of the first week of questions, record
approve of linking their administrative records to their survey data resemble the final sample
largely. Hence, in this respect the non-response bias is small.
The high number of compliers (cortisol: 81.8%, linkage consent: 90.7% and 81.4% and
90.4% for the mass layoff sample, respectively) may cover important reasons for belonging to
the exceptional group of people that does not give their consent to the record linkage / is
unwilling to submit hair samples. We therefore run a multivariate analysis, separately
estimating the propensities of consent to record linkage and indicated willingness to participate
in the cortisol study based on the respective samples of people who were asked to comply. The
We find a couple of substantial marginal effects. The effects of only three individual
characteristics, however, are statistically significant: age increases the probability of
participating in the cortisol study. While we can only speculate about the reason for this finding,
it seems plausible that older people are more interested in health-related studies. This is also
daily wage attracts a statistically significantly negative effect. A much more detailed analysis
of participation in the hair sampling can be obtained from Lawes et al. (2022b). In the process,
further obstacles to participation after indicating a principal willingness are analyzed and
discussed. For instance, not all willing individuals could actually participate in the hair-
sampling as their hair was too short. What is more, not all eligible subjects stuck to completing
the whole process which includes retrieving and sending a sample of their hair by postal letter.
People working in East Germany have a higher propensity to consent to the linkage of their
administrative records in both the full sample as well as the mass layoff subsample. Time spent
regularly employed (i.e., employed subject to social security contributions) increases the
propensity to indicate a willingness to partake in the cortisol study, too. This result is not
statistically significant in the mass layoff sample, where, however, part-time work attracts a
significantly positive effect.
Probability of Linkage consent Probability of willingness to
participate in the hair sampling
Logit (Standard Marginal Logit (Standard Marginal
estimates errors) effects estimates errors) effects
Age in years / 10 0.233 (0.128) 1.688 0.276** (0.090) 3.923**
Tenure in years / 10 -0.494 (0.287) -3.576 -0.182 (0.206) -2.596
Employment history (over past 10 years)
Regular employment (.21 - 10) 0.111* (0.052) 0.803* 0.023 (0.036) 0.326
Unemployment benefit receipt (0 - 5.33) -0.524 (0.287) -3.792 0.009 (0.208) 0.129
Welfare benefit receipt (0 - 10) -0.110 (0.158) -0.794 0.102 (0.116) 1.452
Registered as jobseeker (0 - 10) 0.033 (0.144) 0.239 -0.136 (0.101) -1.934
Participation in policy schemes (0 - 10) 0.413 (0.273) 2.993 0.095 (0.176) 1.356
Female (shares) -0.354 (0.217) -2.562 0.121 (0.153) 1.728
Mass layoff sample -0.247 (0.234) -1.786 -0.082 (0.165) -1.168
Academic degree 0.307 (0.249) 2.224 0.064 (0.175) 0.909
East Germany 0.972** (0.340) 7.036** 0.257 (0.198) 3.656
Recruitment month (ref. November 2018)
Pre-test (November, December 2017) 0.000 (.) 0.000 0.000 (.) 0.000
January 2018 -0.601 (0.706) -4.352 0.403 (0.653) 5.740
February 2018 0.728 (1.085) 5.273 0.049 (0.658) 0.700
March 2018 0.987 (1.061) 7.145 -0.205 (0.496) -2.924
April 2018 0.000 (.) 0.000 0.955 (1.056) 13.598
May 2018 -0.307 (0.510) -2.223 -0.111 (0.411) -1.582
June 2018 0.634 (0.574) 4.589 0.058 (0.404) 0.831
July 2018 0.577 (0.782) 4.179 -1.007* (0.435) -14.332*
August 2018 -0.018 (0.411) -0.128 -0.132 (0.306) -1.884
September 2018 0.724 (0.637) 5.245 -0.380 (0.356) -5.416
October 2018 1.196 (1.047) 8.663 -0.063 (0.481) -0.896
December 2018 0.096 (0.484) 0.693 -0.740* (0.319) -10.529*
January 2019 0.254 (0.484) 1.840 -0.503 (0.318) -7.156
February 2019 -0.014 (0.430) -0.102 0.468 (0.389) 6.667
March 2019 0.322 (0.452) 2.329 0.188 (0.342) 2.672
April 2019 0.387 (0.520) 2.803 0.155 (0.369) 2.201
May 2019 -0.032 (0.317) -0.234 -0.426 (0.232) -6.061
Part-time job (share) 0.399 (0.276) 2.892 0.252 (0.196) 3.581
Daily wage in euros / 10 -0.008 (0.031) -0.055 -0.035 (0.022) -0.491
Individuals 1,194 1,194 1,341 1,341
two outcomes (linkage consent, cortisol participation), conditional on being asked to comply with
the respective outcome. ***p<0.001, **p<0.01, *p<0.05.
Source. Paradata on GJSP participation and IEB version v16.
Panel stability
study. Both the number of people missing the 80% threshold as well as the number of people
failing to respond to any item in a given months are displayed. Panel attrition seems to slow
down over time. In particular, the 80% threshold was reached by a stable number of participants
from the second month onwards. One might speculate whether the first month was used by
many participants as a trial.
number of people that answered at least one item. It turns out that panel attrition was high at
the beginning of the study. The recruitment waves in the first quarter of 2018 are associated
with the worst retention. This might be due to technical difficulties with the app-based survey
during this time, which could explain why about 30% of participants successfully recruited in
the first quarter of 2018 failed to answer at least a single item in the first month. As depicted in
that the underlying problem was solved.
To further analyze panel stability over time, we estimate the probabilities to participate in
the survey after 6 months (wave 7, M7) and one year (wave 13, M13), respectively, conditional
what extent the participants in M7 and M13 differ from the final sample. We find only a small
number of significant results. Females are more likely to still participate in wave 7 of the survey
than males. In the subsample of mass layoffs this result is still statistically significant at M13
mass layoff sample) and A-level education (but no higher degree) are more likely to continue
participation at least until month 13. Again, the first monthly recruitment waves are associated
with much larger attrition than later waves. Overall, this means that the sample did not become
substantially more selective over time.
Source. Paradata on GJSP participation.
responding to at least one (80 %) of the questions each month. The lower panel depicts the share
of participants included in the final sample responding to at least one item per month for each
quarterly period of recruitment.
Probability of participating in M7 Probability of participating in M13
Logit (Standard Marginal Logit (Standard Marginal
estimates errors) effects estimates errors) effects
Age in years / 10 0.028 (0.058) 0.696 0.087 (0.059) 2.149
Tenure in years / 10 0.259 (0.145) 6.479 0.296* (0.147) 7.339*
Employment history (over past 10 years)
Regular employment (0.21 - 10) 0.013 (0.025) 0.323 0.002 (0.025) 0.059
Unemployment benefit receipt (0 - 5.33) -0.135 (0.139) -3.382 -0.129 (0.142) -3.209
Welfare benefit receipt (0 - 10) -0.088 (0.077) -2.194 -0.146 (0.079) -3.623
Registered as jobseeker (0 - 10) 0.077 (0.069) 1.927 0.090 (0.070) 2.237
Participation in policy schemes (0 - 10) -0.115 (0.110) -2.869 -0.055 (0.114) -1.369
Female (shares) 0.205 (0.106) 5.115 0.140 (0.107) 3.469
Level of qualification (ref. no degree)
Vocational training 0.185 (0.434) 4.631 0.422 (0.484) 10.473
A-levels 0.840 (0.583) 20.985 1.266* (0.628) 31.431*
A-levels and vocational training 0.500 (0.440) 12.503 0.675 (0.488) 16.756
Tertiary degree 0.562 (0.436) 14.029 0.743 (0.485) 18.443
Federal state (ref. Schleswig Holstein)
Hamburg -0.681 (0.418) -17.017 -0.581 (0.423) -14.425
Lower Saxony -0.239 (0.358) -5.963 -0.041 (0.359) -1.008
Bremen -0.699 (0.561) -17.454 -0.568 (0.591) -14.092
North Rhine Westphalia -0.528 (0.344) -13.201 -0.318 (0.345) -7.898
Hesse -0.379 (0.385) -9.467 -0.213 (0.385) -5.294
Rhineland Palatinate -0.302 (0.416) -7.537 -0.180 (0.418) -4.457
Baden Württemberg -0.510 (0.358) -12.744 -0.294 (0.358) -7.300
Bavaria -0.711* (0.349) -17.774* -0.482 (0.351) -11.965
Saarland 0.364 (0.585) 9.102 -0.196 (0.576) -4.877
Berlin -0.511 (0.364) -12.757 -0.255 (0.365) -6.322
Brandenburg -0.149 (0.405) -3.728 0.020 (0.407) 0.487
Mecklenburg Western Pomerania 0.075 (0.466) 1.870 0.071 (0.472) 1.767
Saxony -0.387 (0.382) -9.676 -0.230 (0.383) -5.716
Saxony Anhalt -0.624 (0.426) -15.592 -0.489 (0.436) -12.151
Thuringia -0.459 (0.416) -11.455 -0.316 (0.418) -7.834
Mass layoff sample 0.090 (0.112) 2.242 0.125 (0.111) 3.098
Recruitment month (ref. November 2018)
Pre-test (November, December 2017) 0.000 (.) 0.000 0.000 (.) 0.000
January 2018 -1.604*** (0.477) -40.074*** 0.000 (.) 0.000
February 2018 -1.366*** (0.403) -34.119*** 0.000 (.) 0.000
March 2018 -1.384*** (0.327) -34.565*** -1.412*** (0.348) -35.063***
April 2018 -0.590 (0.514) -14.751 -0.568 (0.527) -14.101
May 2018 -0.242 (0.290) -6.045 -0.198 (0.291) -4.904
June 2018 -0.311 (0.268) -7.764 -0.328 (0.271) -8.152
July 2018 -0.014 (0.348) -0.350 -0.020 (0.349) -0.489
August 2018 -0.121 (0.208) -3.021 -0.343 (0.211) -8.519
September 2018 -0.048 (0.238) -1.197 -0.143 (0.240) -3.558
October 2018 -0.088 (0.289) -2.195 -0.294 (0.294) -7.293
December 2018 0.033 (0.241) 0.821 -0.049 (0.242) -1.209
January 2019 -0.100 (0.222) -2.495 -0.002 (0.222) -0.046
February 2019 0.661** (0.243) 16.520** 0.478* (0.233) 11.868*
March 2019 0.228 (0.220) 5.692 0.113 (0.217) 2.815
April 2019 0.022 (0.228) 0.538 -0.049 (0.229) -1.225
May 2019 0.070 (0.165) 1.737 0.057 (0.164) 1.409
Part-time job (share) 0.113 (0.129) 2.813 0.047 (0.130) 1.156
Daily wage in euros / 10 -0.003 (0.015) -0.081 -0.005 (0.015) -0.113
Individuals 1,790 1,790 1,713 1,713
participation after six months and after one year, respectively (conditional on belonging to the final
individuals without any missing values on the relevant variables are included in the estimations.
**p<0.001, **p<0.01, *p<0.05.
Source. Paradata on GJSP participation and IEB version v16.
7. Conclusions
The GJSP is a new source of panel data with a focus on well-being and health. Jobseekers are
surveyed on a monthly basis using a smartphone app. The data collection is innovative along
several dimensions: It allows for collecting longitudinal data on various well-being facets and
chronic stress using state-of-the-art methods (e.g., experience sampling and hair cortisol) before
and after a job loss. Further, the survey data may be linked to rich administrative records
covering participants full employment history with a few exceptions (e.g. periods as public
servant). The sampling allows for comparing unemployed jobseekers to a highly comparable
group of continuously employed individuals. These merits, however, come at some cost, first,
low participation, and, second, selective participation.
The low sign-up proved to be an issue, bearing the risk of large non-response bias.
Reassuringly, the aggregate bias turned out to be quite low. Nevertheless, the question arises as
to why people hesitate to sign up for an app-based survey. The act of downloading, registering,
and actively engaging with an app for frequent measurement may still be burdensome.
Moreover, people might be concerned about the protection of their data in particular if
smartphones are used as survey mode. Not surprisingly, an app-based survey on well-being and
health attracts a non-random group of participants. Although aggregate bias is low, there are
patterns of self-selection into the sample, most importantly of women, highly educated people
and young workers.
On a more general note, when choosing a survey mode, low sign-up and selective
participation need to be considered and weighed against the advantages of using smartphone
apps over traditional web surveys or face-to-face and telephone surveys. These advantages
include convenient high-frequency assessment, increased flexibility for participants, push
notifications, reminders and interventions. The case of the GJSP highlights one of these
advantages. Data such as experience sampling would be difficult or almost impossible to gather
by other means than via a smartphone app.