OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
Perception of visual homogeneity as a precursor to the generalization
of threat across racial outgroup individuals
Niclas Willscheid * & Florian Bublatzky *
Central Institute of Mental Health, Medical Faculty Mannheim, Heidelberg University,
Germany
* Correspondence to Niclas Willscheid and Florian Bublatzky
niclas.willscheid@zi-mannheim.de florian.bublatzky@zi-mannheim.de
J5, 68159 Mannheim J5, 68159 Mannheim
+49621 1703-4461 +49621 1703-4461
Author Contributions: The authors contributed equally to this work.
Competing Interest Statement: The authors declare no conflict of interest.
This PDF file includes:
Manuscript
Figures 1 to 2
Supplementary material
Figures S1 to S5
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
Abstract
People who look different from oneself are often categorized as homogeneous members
of another racial group. We examined whether the relationship between such
categorization and the tendency to generalize over outgroup individuals is explained by
perceived visual similarity, leading to an all-look-alike misperception. To address this
question, White participants perceived sequences of White and Black faces while event-
related electrocortical activity was recorded. Prior to each face sequence, one specific
ingroup or outgroup face was instructed as a cue for receiving unpleasant electric shocks.
The faces were presented in adaptor-target pairs, consisting of two ingroup faces or two
outgroup faces, which could either depict the same or different identities. Results show
less discrimination of outgroup compared to ingroup faces in early visual processing, i.e.,
N170 repetition suppression was sensitive only to ingroup face identities. Temporally
following stimulus (mis)identification, threat generalized stronger over outgroup compared
to ingroup faces, as indicated by Late Positive Potentials (LPP) for both threat and safety
faces. These findings suggest that the misperception of outgroup homogeneity may be an
early precursor to the tendency to generalize threat associations across outgroup
individuals. The proposed link emphasizes the importance of visual minority
representation to enhance perceptual learning with outgroup faces.
Keywords: social learning, race, neural adaptation, threat generalization, outgroup
homogeneity perception
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
Introduction
Unknown people are often judged based on what has been previously learned about
others who are perceived as similar. Such learning and generalization processes tend to
rely on limited information, and it is well-known that visual characteristics, such as skin
color or facial features, lead to superficial categorizations. Individuals are categorized by
race, here referred to as visual groups (Fischer & Krause, 2023), and are judged based
on these perceived group memberships. Importantly, attributions of visual groups are
particularly directed towards individuals who look different from oneself. Striking visual
differences that indicate an outgroup are more consciously perceived (outgroup
classification advantage; Caldara et al., 2004; Feng et al., 2011), and outgroup individuals
are often mistakenly perceived as looking more alike (outgroup homogeneity effect;
Ostrom & Sedikides, 1992). This indicates a contrast between outgroup categorization
and ingroup individuation in person perception (Hugenberg et al., 2010; Liu et al., 2015).
Similarly, generalizations such as prejudices and stereotypes tend to be directed towards
outgroups rather than the ingroup, and social threat learning, in particular, seems
susceptible to intergroup biases (Amodio & Cikara, 2021; Olsson et al., 2005). In this
study, we examine at the neural level whether the categorization of individuals, who are
visually perceived as similar, is a precursor to outgroup generalizations of threat
association.
Using a visual adaptation paradigm, previous research has demonstrated that the
perceived similarity between visual outgroup faces is reflected in the similarity between
neural representations of those faces. After adapting to the first stimulus (adaptor) of two
consecutively perceived stimuli, the processing activity elicited by the second stimulus
(target) is suppressed to a greater extent when the neural representations of these two
stimuli are more similar. This is called repetition suppression (RS; Barron et al., 2016;
Grill-Spector et al., 2016; Kovács & Schweinberger, 2016). Thus, perceiving two faces
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
successively leads to suppressed face-selective neural processing (categorical RS; Eimer
et al., 2010; Kovács et al., 2006), and the suppression is stronger when the same face is
repeated compared to two different faces (identity-sensitive RS; Caharel et al., 2014;
Ewbank et al., 2008) due to the representational differences between individual faces. The
sensitivity of RS to facial identity has been demonstrated to be present for ingroup faces
but absent when perceiving outgroup faces (Hughes et al., 2019; Reggev et al., 2020;
Vizioli et al., 2010). This suggests that the neural representations of two different outgroup
faces are similar and indicates a neural correlate of outgroup homogeneity perception.
Importantly, measurements of face-selective neural processing, such as fusiform face
area activity or associated modulations of event-related potentials (ERPs) such as the
electrocortical N170 component (Gao et al., 2019; Rossion, 2014), are well-suited to
provide insight into individualized face representations. Object-level face representations
are a product of higher-level processing and encompass the structural information of a
“face” as well as unique facial features and configurations (Liu et al., 2010; Rossion et al.,
2023).
Humans are experts at recognizing individuals by their faces. Despite this basic
ability to process faces, individuation and identity recognition requires perceptual learning
experiences. Thus, identity recognition works best when viewing images of familiar
people, whereas recognition performance is surprisingly poor for unfamiliar people
(Johnston & Edmonds, 2009; Kovács, 2020). Similarly, in the absence of learning
experiences with faces of visual outgroups (in a natural environment dominated by the
ingroup), categorical face expertise gradually develops for ingroup but not outgroup faces.
This bias is thought to explain the misperception of outgroup homogeneity and lower
recognition performance for outgroup faces, commonly referred to as other-race effect
(Correll et al., 2017; Singh et al., 2022; Tüttenberg & Wiese, 2023).
Person recognition also plays a crucial role in associative learning, especially
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
concerning threatening or safe individuals. Much research has shown that threat
associations can be acquired through personal experience (e.g., Pavlovian conditioning;
Lonsdorf et al., 2017). However, learning about outgroup individuals, with whom face-to-
face contact is generally less frequent, often occurs through social learning in the form of
verbal ingroup communication (Golkar et al., 2015; Olsson et al., 2020). In the instructed
threat paradigm (threat-of-shock; Grillon et al., 1991), a laboratory approach to examine
social threat learning, participants are verbally informed that a specific cue (e.g., Person
A) indicates the threat of receiving an electric shock, while other stimuli (e.g., Person B)
signal the absence of shocks and, therefore, safety. Instructions reliably induce selective
threat cue processing, which has been shown to be surprisingly stable over time even in
the complete absence of expected aversive events (Bublatzky et al., 2014; Bublatzky et
al., 2020; Bublatzky & Schupp, 2012). These findings resemble verbal communication
about unfamiliar others in real life, such as gossip or media coverage, which can lead to
persistent opinions even without corroborating personal experiences. On the neural level,
the selective processing of an instructed threat cue can be observed through the activity
of a distributed fear network, for example including the amygdala, anterior cingulate
cortex, and dorsomedial prefrontal cortex (Mechias et al., 2010; Olsson & Phelps, 2007).
The Late Positive Potential (LPP) serves as an electrocortical correlate of this network
activity and reflects the interplay between limbic and extrastriate visual processing (de
Rover et al., 2012; Liu et al., 2012).
Once it is learned that a person is threatening, this initially identity-specific
association is susceptible to being transferred to other individuals who are perceived as
similar. Perceived visual similarity can play a significant role in such categorization and
generalization processes. Previous research has shown that the more similar the threat
and safety cues are (e.g., shapes of different sizes), the more threat processing
generalizes to actual safety cues (Greenberg et al., 2013; Stegmann et al., 2019; Webler
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
et al., 2021). Here, we hypothesized that threat would be generalized more strongly for
visual outgroup faces that are misperceived as more similar compared to ingroup faces.
shared) addressed the potential link between outgroup homogeneity perception and threat
generalization at the neural level. To achieve this, we established a combined face
and Black people's faces to 40 White participants while recording event-related
electrocortical activity. The face pictures were presented as sequences of strung-together
adaptor-target pairs. To examine group differences in identity-sensitive repetition
suppression, the adaptor-target trials included two faces from either the visual ingroup or
outgroup, depicting either the same or two different facial identities. Importantly, before
each sequence, one specific in- or outgroup face was verbally instructed as a threat-of-
shock cue. This group-specific threat instruction allowed us to investigate the
generalization of threat processing from the instructed threat faces to safety faces of the
same visual group.
We had two main hypotheses: (i) Identity-sensitive N170 repetition suppression
would be present for ingroup faces but not for outgroup faces (Vizioli et al., 2010). Due to
lower processing expertise, the neural representations of individual outgroup faces are
less distinct, leading to reduced modulation of the N170 component by the facial identity
of target faces (i.e., same vs. different). Additionally, (ii) we predicted pronounced LPP
amplitudes for instructed threat faces (Bublatzky et al., 2020; Bublatzky & Schupp, 2012),
and that this threat effect would generalize to other safety faces of the same visual group.
Importantly, we anticipated that this generalization would be stronger across outgroup
faces. Thus, we hypothesized that outgroup faces would show lower visual individuation
(N170 repetition suppression) and higher threat generalization (LPP). Further analyses
explored the interaction between identity distinction and threat generalization, the
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
temporal dynamics of identity-sensitive repetition suppression (P1, N170, P200, N250;
Schweinberger & Neumann, 2016), and LPP modulation (early vs. late modulation), as
well as differential processing of ingroup and outgroup faces independent of adaptation
effects.
Materials and Methods
Participants. Forty healthy White participants (26 female) between the ages of 19 and 32
years old (M = 22.58, SD = 3.02) participated. Participants did not report psychological or
medical diseases and were within the normal ranges of trait anxiety (STAI-T, Laux et al.,
1981; M = 35.73, SD = 9.07), state anxiety (STAI-S; M = 34.51, SD = 8.71), social anxiety
(SPIN, Stangier & Steffens, 2002; M = 9.77, SD = 7.63), and intolerance of uncertainty
(UI-18, Gerlach et al., 2008; M = 33.35, SD = 11.64). To ensure that participants had
established ingroup face expertise, only individuals who were born and raised in Germany
were recruited. All participants provided informed consent; the ethics committee of the
University of Heidelberg approved the study protocol.
Materials. Front-view face pictures of shaved males with neutral facial expressions were
taken from the Chicago Face Database (CFD; Ma et al., 2015). Based on CFD norm
ratings, pictures were classified as more than 75% White or Black in terms of racial
categorization. For each participant, 60 Black and 60 White faces were randomly included
in the experiment. Face images were converted to grayscale, cropped to an oval mask
(840 px height, 665 px width), and scalp hair was edited out if reaching into the oval mask.
Importantly, pictures were normalized regarding luminosity with the SHINE toolbox
(Willenbockel et al., 2010) for MATLAB (MathWorks). This was done to equalize skin tone
between grayscale faces, resulting in the exclusion of skin color as a differentiating factor
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
between Black and White faces. Stimulus selection, preparation, and presentation were
adapted from Reggev et al. (2020) to replicate the absence of identity-sensitive repetition
suppression for visual outgroup faces with the same stimuli and a comparable procedure.
Procedure. The experiment consisted of 12 blocks, and within each block, a sequence of
face pictures of five White and five Black persons was presented. Faces were repeated 8
times, leading to 80 face presentations per block. Each block had a different set of faces.
To combine the threat-of-shock and adaptation paradigm, the sequence and timing of
faces within a block were comprised of strung together adaptation trials (i.e., two faces
face from the sequence was verbally instructed as a threat-of-shock cue (Bublatzky et al.,
2020).
Adaptation trials consisted of two faces, an adaptor face and a target face, that
were each presented for 600 ms with an interstimulus interval of 500 ms and an intertrial
interval of 1700 ms. These adaptor-target pairs depicted either two White or two Black
faces, and the target displayed either the same or a different facial identity as the adaptor
face. The assignment of faces was pseudorandomized in a way that the same face could
not be repeated as target and adaptor in two consecutive trials to avoid sequence effects.
For the threat-of-shock learning paradigm, a specific face was instructed as a
signal to receive aversive electric shocks (i.e., a verbal instruction followed by 3500 ms
threat face presentation), and all other faces served as safety cues (i.e., no shocks will be
administered). In each block, either an ingroup or an outgroup face served as a threat cue;
otherwise, the experiment blocks were the same in terms of procedure. Thus, the face
stimuli were presented either in a sequence with a threat cue from the same visual group
(matched condition; e.g., Black safety faces during a sequence with a Black threat face)
or in a sequence with a threat face from the other visual group (unmatched condition; e.g.,
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
Black safety faces during a sequence with a White threat face).
Shock electrodes were placed on the left inner forearm before the experiment.
Participants were told that up to three shocks will be applied throughout the experiment
and that these shocks are unpleased but not yet painful. To focus on the effects of aversive
expectations but not personal experiences in a social context, participants did not receive
electrical shocks during the experiment.
Participants were seated at a distance of 1.25 meters between their eyes and the
center of a 43-inch monitor with a resolution of 1080 × 1920 px. Faces were presented in
the middle of the screen with a small random horizontal offset (5, 10, 15, or 20 px to left
or right) to counteract retinotopic adaptation. The experiment was programmed using
Python and controlled by OpenSesame software (Mathôt et al., 2012).
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
paradigm. Each experiment block began with the presentation of one specific face (either
ingroup or outgroup) that served as an instructed cue for receiving unpleasant electric
shocks. Participants then viewed sequences of 40 adaptor-target face pairs displaying
either two outgroup faces (A and B) or two ingroup faces (C and D). Additionally, to
analyze face individuation, face pairs depicted either the same face (B and D) or two
different faces (A and C). Note that ingroup and outgroup safety faces within a block could
be from the same visual group as the threat face (matched condition; e.g., viewing Black
safety faces during blocks with a Black threat face) or from the other visual group
(unmatched condition). This was the basis of the analysis of group generalization of threat
from the instructed threat face to safety faces.
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
EEG recording and preprocessing. Electrocortical activity was recorded using 65
Ag/AgCl active electrodes (BrainProducts, Munich, Germany) mounted into elastic caps
with sensor positions according to the 10-10 system (Falk Minow Services, Herrsching,
Germany). Sensor impedance was kept below 20 kΩ. EEG data was recorded at a 500
Hz sampling rate with FCz as the reference electrode using BrainAmp DC amplifiers and
BrainVision Recorder software (BrainProducts). Offline data preprocessing included
conversion to an average reference, downsampling to 250 Hz, and low-pass filtering at 35
Hz using BrainVision Analyzer (Version 2.1). Eye movements were screened and
interpolated using the build-in automated independent component analysis for ocular
correction using FP1 and F7 sensors. An automated artifact rejection procedure led to the
removal of, on average, 17.33 out of 960 trials, based on several artifact criteria (i.e.,
voltage steps above 50 microvolt (μV)/ms; amplitudes above or below ± 100 μV; and
voltage differences within 200 ms intervals above 200 μV). Baseline correction was
applied (100 ms prior to stimulus onset), and stimulus-synchronized epochs were
extracted, lasting from 100 ms before stimulus onset to stimulus offset at 600 ms. Finally,
separate average waveforms were calculated for each condition, sensor, and participant.
Data analysis. As preregistered, differences between ingroup and outgroup faces were
examined regarding early facial identity processing (N170) and threat generalization
(LPP), complemented by additional research questions and ERP components.
ERP components were scored based on prior research, visual waveform
inspection, as well as cluster permutation tests with the MNE-Python toolbox (Gramfort et
al., 2013; for details see the supplementary material). For the categorical N170 repetition
suppression, a cluster was defined and treated as the topographical localization of face-
selective neural activity. This cluster included bilateral parieto-occipital sensors (P5/P6,
P7/P8, PO3/PO4, PO7/PO8, PO9/PO10) and was assigned to all ERP components linked
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
to face-selective processing. To score mean amplitudes, selected time windows were
ranging from 150 to 190 ms (N170), 200 to 250 ms (P200), and 250 to 600 ms (N250).
Regarding threat processing, the LPP showed differential processing of threat and safety
faces within a time window ranging from 300-600 ms over centro-partial sensor sites (P1,
Pz, P2, P4). For the P100 component (90-110 ms), a separate analysis for the categorical
P100 repetition suppression indicated a central parieto-occipital cluster (P1, Pz, POz, Oz).
Repeated measures analyses of variance (ANOVA) were performed using SPSS
version 29, including the factors of interest as well as methodological factors (see below).
Note that for all models (except for threat vs. safety processing differences), only the safety
faces were analyzed. For the N170 adaptation analysis, (i) identity-sensitive N170
repetition suppression was examined, including the factors Identity (same vs. different),
Group (ingroup vs. outgroup), and Generalization (matched vs. unmatched; i.e., safety
faces were from the same or different visual group than the instructed threat face). Only
target faces were analyzed for this model. (ii) To examine categorical repetition
suppression, the model included the factors Adaptation (adaptor vs. target), Group
(ingroup vs. outgroup), and Generalization (matched vs. unmatched). The factor
Generalization was added to account for interactions between face processing and threat
generalization. For the analysis of the P100, P200, and N250 components, the same
statistical models (i and ii) were tested.
Regarding the analyses of threat processing based on the LPP component, (iii) the
generalization of threat-selective processing patterns to actual safety faces was tested
with the factors Group (ingroup vs. outgroup) and Generalization (matched vs.
unmatched). (iv) Processing differences between actual threat faces and safety faces
were examined with the factors Instruction (threat vs. safety) and Group (ingroup vs.
outgroup).
(v) Differential processing between ingroup and outgroup faces was analyzed
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
including the factors Group (ingroup vs. outgroup) and Generalization (matched vs.
unmatched). For these analyses, only adaptor faces were used to test group effects
independent of adaptation effects.
As methodological factors, all statistical models included the factor Electrode
(selected sensors for components) and for ERP components that emerged bilaterally
(N170, P200, and N250), the factor Laterality (left vs. right) was included. Moreover, for
ERP components that showed sustained effects, the N250 and LPP components, an
additional factor Time served to examine temporal changes. For the N250, the
conventional waveform peak (250-290 ms) and a following sustained potential (290-600
ms) were differentiated (peak vs. sustained), and for the LPP component, early modulation
(300-450 ms) and later modulation near stimulus offset (450-600 ms) were compared
(early vs. late).
If necessary, Greenhouse-Geisser corrected p-values were reported, and partial
eta squared (η 2) served as a measure of effect size.
Results
Identity-sensitive repetition suppression. Neural adaptation processes were sensitive
to the identity of the adaptor and target faces, suggesting a distinct neural representation
of individual faces. This was indicated by a stronger suppression of target processing (i.e.,
less pronounced ERP amplitudes) when the target and adaptor showed the same face
compared to different faces. Of particular interest was the comparison between in- and
outgroup faces and the interaction between face individuation and threat generalization.
Results confirmed the preregistered hypothesis of identity-sensitive N170
repetition suppression for ingroup faces, but not outgroup faces, in early visual processing
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
ingroup faces served as the threat-of-shock cue. Interestingly, for outgroup faces, identity
sensitivity emerged later in the time frame of the N250 component to the same extent as
for ingroup faces. The results for all ERPs throughout the visual processing stream (P100,
N170, P200, and N250) are reported in the supplementary material.
Differences between ingroup and outgroup in identity-sensitive repetition
suppression emerged for the N170 component (150–190 ms) and varied as a joint function
of Identity × Group × Generalization, F(1,39) = 5.96, p = .019, η 2 = .13. Note that the factor
Generalization distinguishes between safety faces during experiment blocks with a threat
face of the same visual group (matched; generalization condition) and during blocks with
a threat face of the other visual group (unmatched; control condition). Matched faces
showed identity distinction only for ingroup faces, Identity × Group F(1,39) = 6.35, p =
.016, η 2 = .14, with identity sensitivity for ingroup, Identity F(1,39) = 5.11, p = .029, η 2 =
p p
.12, but not outgroup faces, Identity F(1,39) = 2.52, p = .120, η 2 = .06. Unmatched faces
did not show identity sensitivity, Identity F(1,39) = 1.20, p = .280, η 2 = .03, or a group
effect, Identity × Group F(1,39) = .28, p = .600, η 2 = .01. The results for the P200
component align with the N170 results and are described in the supplementary material.
This means that in early face processing, identity sensitivity was found only for ingroup
but not outgroup faces, and the individuation of ingroup faces was facilitated if an ingroup
face was threat-of-shock instructed to better distinguish them from ingroup safety faces.
Starting at the later N250 component (250–600 ms), identity-sensitive face
processing was observed for both visual groups, Identity F(1,39) = 41.47, p < .001, η 2 =
.52, without an ingroup bias, Identity × Group F(1,39) = .46, p = .831, η 2 < .01, and face
distinction did not interact with the threat generalization, Identity × Generalization F(1,39)
= 1.33, p = .256, η 2 = .03. The effect was more pronounced over the right hemisphere,
Identity × Laterality F(1,39) = 10.70, p = .002, η 2 = .22. The separate analyses for N250
peak (250–290 ms) and N250 sustained waveform (290–600 ms), which showed the same
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
results, are reported in the supplementary material. Individuation of ingroup faces was
observed at an early stage of face processing (N170), whereas outgroup faces were
individuated to the same extent only at later, increasingly elaborated processing stages
(N250).
Categorical repetition suppression. Repeated perception of two stimuli of the same
category leads to suppressed neural processing (e.g., faces as adaptor and target; Eimer
et al., 2010; Kovács et al., 2006). Such categorical repetition suppression effects have
been found for the N170 component, Adaptation F(1,39) = 54.79, p < .001, η 2 = .58, and
were stronger over the right hemisphere, Adaptation × Laterality F(1,39) = 4.87, p = .033,
η 2 = .11. Similarly, repetition suppression effects emerged for the N250, Adaptation
F(1,39) = 34.31, p < .001, η 2 = .47, and were also stronger over the right hemisphere,
S1 in the supplementary material.
Group generalization of instructed threat association. The threat processing of
instructed threat faces (i.e., pronounced LPP amplitudes) spilled over to safety faces of
to safety faces after a face of the same visual group was threat-of-shock instructed
(matched condition) compared to the instruction of a face of the respective other visual
group (unmatched condition). For instance, we compared Black safety faces during a
Black threat face (matched) with Black safety faces during a White threat face
(unmatched). The analyses of group differences confirmed the preregistered hypothesis
of stronger threat generalization for outgroup faces. Early LPP modulations showed an
exclusive effect for outgroup faces, and later modulations showed an effect for both visual
groups.
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
Within an early LPP time window (300–450 ms), threat generalization occurred
only for outgroup faces, Generalization × Group F(1,39) = 4.11, p = .049, η 2 = .10, with
generalization present for outgroup faces, F(1,39) = 10.36, p = .003, η 2 = .21, but not for
ingroup faces, F(1,39) = .21, p = .647, η 2 = .01. Within a later time window (450–600 ms),
generalization was indicated for both groups, Generalization F(1,39) = 36.17, p < .001, η 2
= .48. Results for the interaction of time (early vs. late) with group differences in threat
generalization suggested variance between electrodes within the central parietal cluster,
Generalization × Group × Time × Electrode F(3,117) = 3.57, p = .049, η 2 = .08, with sensor
P4 showing a significant outgroup bias independent of the time window, Generalization ×
Group F(1,39) = 4.38, p = .043, η 2 = .10. Especially for outgroup faces, instructed threat
faces and safety faces showed the same LPP modulation, indicating group generalization
of threat processing rather than only selective processing of threat cues.
Differential processing of threat vs. safety faces. Preceding each experiment block,
one specific face was instructed as the cue for receiving unpleasant electric shocks.
Viewing these threat faces within the blocks led to enhanced LPP amplitudes compared
previous research (Bublatzky et al., 2020; Bublatzky & Schupp, 2012). Visual group did
not modulate this general instruction effect, Instruction × Group F(1,39) = .51, p = .478,
η 2 = .01, meaning that, in contrast to outgroup-biased generalization processes, selective
processing of instructed threat faces was not more pronounced for outgroup compared to
ingroup faces.
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
Identity-sensitive repetition suppression is indicated by more positive N170 and N250
amplitudes elicited by same-identity compared to different-identity target faces. Due to the
further interaction with threat generalization, the results for matched safety faces are
illustrated. (B) Group generalization of threat processing is indicated by pronounced early
and late LPP amplitudes elicited by safety faces during a block with a threat face from the
same visual group vs. a different visual group (i.e., matched vs. unmatched). Depicted are
waveforms of exemplary sensors (P6 and P4), bar plots illustrating cluster means
(whiskers indicate SEM), and topographical difference maps (Same – Different and
Matched – Unmatched). Main and interaction effects are marked with an asterisk if
significant, * p < .05 / ** p < .01 / *** p < .001.
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
Differential processing of ingroup vs. outgroup faces. As a complementary analysis,
we examined ERP differences between ingroup and outgroup faces independent of
pronounced P100 amplitudes (90–110 ms) for ingroup relative to outgroup faces, Group
F(1,39) = 13.94, p < .001, η 2 = .26. In contrast, outgroup faces showed more pronounced
amplitudes for subsequent face-sensitive ERP components. This was observed for the
N170 (150–190 ms), Group F(1,39) = 4.14, p = .049, η 2 = .10, for the P200 (200–250 ms),
Group F(1,39) = 4.55, p = .039, η 2 = .10, and for the N250 component, Group F(1,39) =
7.91, p = .008, η 2 = .17. The P200 component showed a right-lateralized effect, Group ×
Laterality F(1,39) = 5.50, p = .024, η 2 = .12. Group differences in adaptor face processing
did not show any interaction with threat generalization in any of the ERP components,
Fs(1,30) < .26, ps > .614, η 2 < .01. Thus, differential processing of faces from visual
ingroup and outgroup was observed already early in the visual processing stream (at the
level of the P100 component) and continued for the N170 and N250 components
regardless of adaptation processes or threat instructions.
Discussion
This study examined whether the all-look-alike misperception between visual outgroup
individuals might be linked to a generalized stereotypic threat perception of outgroup
members. We used a combined adaptation and threat-of-shock paradigm with White
(ingroup) and Black (outgroup) faces while recording event-related electrocortical activity.
This allowed us to measure group differences in the representational similarity between
individual faces (identity-sensitive repetition suppression) and spillover of threat
processing from instructed threat faces to safety faces of the same visual group.
Confirming our hypotheses, ERP results showed less distinction between outgroup faces
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
in early visual processing (N170) and, temporally after stimulus (mis)identification, greater
generalization of threat processing across outgroup faces (LPP). This link between initial
misidentification and later generalization of threat across members of a visual outgroup
may be an important neural mechanism involved in perceptual intergroup biases and
stereotyping.
Early facial identity processing is better for ingroup faces. To examine the
misperceived similarity between outgroup faces, we analyzed whether neural
representations of different outgroup faces are more similar than representations of
ingroup faces. Using an adaptation paradigm with two successively perceived faces
S1), distinct representations for individual faces were indicated by stronger repetition
suppression when the same face was repeated than when two different faces were
perceived (Caharel et al., 2011; Ewbank et al., 2008). Fundamentally replicating previous
research (Hughes et al., 2019; Reggev et al., 2020; Vizioli et al., 2010), we found identity-
sensitive repetition suppression of the N170 component only for ingroup but not for
unique outgroup faces and therefore a lack of visual individuation in early face processing.
Different accounts of categorical face expertise are thought to explain ingroup-biased face
individuation: Because one's social environment is often dominated by ingroup individuals,
learning experiences with outgroup faces are lacking. Accordingly, an expertise for
detailed visual differences that define unique facial identities is built only for faces of the
ingroup but not for the outgroup (Correll et al., 2017; Singh et al., 2022; Tüttenberg &
Wiese, 2023).
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
Threat generalization is more pronounced for outgroup faces. Using an instructed
threat paradigm, we show that the association of threat with a particular person, learned
exclusively through verbal communication, can be generalized to others who are visually
perceived as belonging to the same group of people. While previous studies examined
threat generalization based on actual visual similarity between a learned threat cue and
novel safety cues (Greenberg et al., 2013; Stegmann et al., 2019; Webler et al., 2021), we
asked if misperceived similarity between outgroup faces relative to ingroup faces may be
linked to outgroup-biased threat generalization. Generalization was indicated by a
spillover of threat-enhanced LPP amplitudes to actual safety faces that were of the same
visual group as an instructed threat face. Temporally after stimulus (mis)identification,
reflected in the face-selective N170 component, the initial LPP modulation showed threat
modulation mirrors LPP amplitudes elicited by threat faces (Bublatzky et al., 2020), leading
to direct alignment between threat and outgroup safety cues in terms of topography and
of threat processing also emerged for ingroup safety faces. Thus, even without personal
experience with an allegedly threatening person, the recognition of threat can spread to
new persons who are superficially perceived as similar. Visual outgroup individuals appear
to be particularly susceptible to such generalization tendencies, which may be partly due
to categorization processes in visual person perception.
Face identity processing throughout the visual processing stream. The analyses of
adaptation effects in later face-selective processing (P200 and N250) showed facial
identity distinction also for outgroup faces. The P200 still showed a stronger effect of
identity for ingroup faces (see the supplementary material), however, starting at the N250
component, a sustained potential showed identity-sensitive repetition suppression without
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
processing (N170 and P200) and an unbiased pattern in later processing (N250) can be
explained by an initial primarily structural processing of the stimulus category “face”
followed by gradually more configural processing for familiarized individual faces (Ambrus
et al., 2021; Kaufmann et al., 2009; Schweinberger & Neumann, 2016; Tanaka & Pierce,
2009). Lower categorical face expertise may make the initial perception of unfamiliar
outgroup faces vulnerable to misperceived homogeneity but does not prevent
individuation through face familiarization. The preceding P100 component showed no
modulation by identity, which was expected due to its link with initial visual processing
prior to more complex facial identity representations (Liu et al., 2002; Reggev et al., 2020;
Rossion & Caharel, 2011; see the supplementary material).
Differential processing of ingroup vs. outgroup faces. Independent of adaptation
effects, electrocortical activity differentiates between ingroup and outgroup faces (Bagnis
(Cunningham et al., 2012; Serafini & Pesciarelli, 2023), the visual group of a face already
modulated the P100 component, with more pronounced amplitudes for ingroup faces. The
finding that outgroup faces tended to be processed immediately at the group level (P100),
but only later at the individual face level to the same extent as ingroup faces (N250),
suggests that the initial processing of outgroup faces is biased towards category rather
than identity information. The face-selective N170, P200, and N250 components were all
more pronounced for outgroup faces. Taken together, in the context of the threat face
recognition task, these results may indicate more laborious identity processing for
outgroup faces (Herzmann, 2016; Senholzi & Ito, 2013; Tüttenberg & Wiese, 2023; Yang
et al., 2022).
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
Interaction between threat generalization and identity processing. When an ingroup
face was instructed as a threat cue (in comparison to an outgroup face), participants
showed stronger individuation of ingroup faces in early visual processing. Thus, when the
distinction between ingroup faces was particularly important for recognizing the specific
threat face, identity processing was enhanced. This was evidenced by stronger identity-
sensitive N170 and P200 repetition suppression. Interestingly, this interaction was absent
for outgroup faces which did not show early identity processing regardless of the visual
group of the threat face. On the one hand, for faces of one's own group, the effect may
reflect increased early facial identity processing due to the implicit task demand of face
discrimination (Kim et al., 2019; Senholzi & Ito, 2013; Yang et al., 2022). On the other
hand, the effect could be attributed to group-selective attention, which led to an interplay
between amplified stimulus processing and stronger adaptation (Rhodes et al., 2011;
Stegmann et al., 2021).
Group-selective attention resulting from the group-specific threat instruction may
also be relevant to the present threat generalization results. Later ERP components linked
to more elaborated processing are attention-sensitive (e.g., the LPP; Schindler &
Bublatzky, 2020; Schindler et al., 2022), so it is important to disentangle modulation by
actual threat processing and allocated attentional resources. The temporally early
potentiation of the LPP only for outgroup safety faces and the later modulation also for
ingroup faces can be explained by a simultaneous effect of outgroup-biased generalization
of threat processing and group-selective attention to the same extent for both visual
groups.
Conclusions and future directions. The present results provide initial evidence that
misperceived visual homogeneity could be an early precursor of threat generalization
across a visual outgroup. For example, superficial visual characteristics (e.g., skin color)
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
can lead to preconceptions and generalized threat associations, as in the context of racial
profiling of local visual minorities (Payne & Correll, 2020; Ross, 2015). In addition to such
intergroup biases, dysfunctional social threat learning may contribute to the development
and maintenance of psychopathological fear and anxiety. The influence of anxiety on
threat generalization (Cooper et al., 2022; Dunsmoor & Paz, 2015) may be particularly
relevant for understanding dysfunctional intergroup processes. Another interesting follow-
up question concerns the reciprocity of outgroup categorization and threat generalization
in intercultural settings with different visual groups (Vizioli et al., 2010). A lack of perceptual
learning experiences with outgroup faces is thought to lead to the misperception of
outgroup homogeneity, and our results indicate that such visual categorization may
facilitate outgroup generalizations (Lebrecht et al., 2009; Rösler & Amodio, 2022). A shift
from prejudices against unfamiliar outgroups to learning about an individual (regardless of
group) can be promoted not only by positive personal contact (contact hypothesis; Allport,
1954), but potentially also by perceptual learning with people who look different from
oneself. These considerations illustrate the importance of representing visual minorities,
for example through portrayal in popular media, in order to increase and normalize visual
diversity in person perception.
OUTGROUP GENERALIZATION AND VISUAL CATEGORIZATION
Acknowledgments
This research was supported in part by the German Research Foundation (DFG) grant to
F. Bublatzky (BU 3255/1-1 and -2).
Data availability
The data and code underlying this article are available in the Open Science Framework