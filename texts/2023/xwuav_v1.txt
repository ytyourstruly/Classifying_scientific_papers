Title Page (with Author Details)
Using Whiteboards as Active Responding to Make Higher Education More Inclusive
Arturo Clavijo-Álvarez, Cristian Urbano, Juan Pablo Molano, Laura Suárez
and Julian Zanguña
Universidad Nacional de Colombia, Colombia
Address : Cra. 30 # 45-03, Edificio 212, of. 218, Bogotá, Colombia.
Suggested running head: Active Responding and Inclusion
Corresponding author: Arturo Clavijo, Departamento de Psicologia, Universidad Nacional
de Colombia, Cra. 30 # 45-03, Edificio 212, of. 218, Bogotá, Colombia, Phone: +57 1
3165000, Email: aaclavijoa@unal.edu.co
Author Note: A grant by the Universidad Nacional de Colombia to Arturo Clavijo
supported this research. There is no conflict of interest to declare by any of the authors of
this paper.
Funding: This study was supported by the Grants for Research on Educational Innovation
Headquarters Bogotá - National University of Colombia
Manuscript (without Author Details) Click here to view linked References
Running head: Active Responding and Inclusion
Abstract
Active responding strategies improve learning and increase students' engagement. This study
evaluated the effect of whiteboards, an effective and low-cost active responding strategy, on the
students' perception of inclusion and frequency of their participation in class. Fifty-four
undergraduate students enrolled in a course on motivation went through the two conditions that
comprised this study. In one section of each class, the students actively responded to their
professor's questions by writing on whiteboards; during the other section, they didn’t use boards
but voluntarily raised their hands. Students reported a higher perception of inclusion during
sections with whiteboards than in the sections without them. Their voluntary response frequency
was higher during the sections without whiteboards than during the section with whiteboards.
Keywords: inclusive education, active responding strategy, response whiteboards. university
students.
Running head: Active Responding and Inclusion
Resumen
Las estrategias de respuesta activa mejoran el aprendizaje y aumentan el compromiso de los
estudiantes. Este estudio evaluó el efecto de tableros, una estrategia de respuesta activa efectiva y
de bajo costo, sobre la percepción de inclusión y la frecuencia de la participación en clase de un
grupo de estudiantes. Cincuenta y cuatro estudiantes universitarios matriculados en un curso
sobre motivación pasaron por las dos condiciones que conformaban este estudio. En una sección
de cada clase, los estudiantes respondieron activamente a las preguntas de sus profesores
escribiendo en tableros; durante la otra sección, no usaron tableros, sino que voluntariamente
levantaron la mano. Los estudiantes reportaron una mayor percepción de inclusión durante las
secciones con tableros que en las secciones sin ellos. La frecuencia de participaciones voluntarias
fue mayor en las secciones sin tableros.
Palabras clave: educación inclusiva, estrategia de respuesta activa, tableros de respuesta,
estudiantes universitarios
Running head: Active Responding and Inclusion
This paper reports the results of a study that evaluated how higher education lecturers and
professors might make their classes more inclusive by using active responding strategies.
According to UNESCO (2009), “Inclusive education [IE] is a process of strengthening the
capacity of the education system to reach out to all learners [emphasis added] and can thus be
understood as a key strategy to achieve Education For All (p. 8).” According to Gore (2010),
educators, parents, and even policy makers often forget the reaching-out-to-all-learners
component of the definition due to the strong association they make between IE and the
Education of Individuals with Disabilities (Ruggs & Hebl, 2012). People in general, not only
educators, tend to believe that only Individuals with Disabilities benefit from IE while, on the
contrary, an ideal educational system should include all students (Casanova Correa & González
Pérez, 2010). Anyway, in a sense, everybody is somehow a disabled learner for specific subjects
and skills. It is undeniable that particular topics and skills are easier for some people than for
others. For instance, some students learn to speak a new language or solve complex math
calculations faster and more effectively than others; some, otherwise average students, are
disabled for these subjects while simultaneously, they are acutely able for others.
Hardly anybody would disagree with the importance of making the classroom inclusive at
every level, but how to do it is a more complicated matter (Janney & Snell, 2013). Around the
World, instructors’ lack of the proper tools to make their classes inclusive is one of the principal
obstacles to IE (Munk & Dempsey, 2010; Sharma, Loreman, & Forlin, 2012; Unianu, 2012).
After years of research, basic psychologists have unfolded some of the mechanisms responsible
for the learning process, and, based on that knowledge, applied psychologists have developed
some teaching techniques that have demonstrated their efficacy in different contexts (Chance,
Running head: Active Responding and Inclusion
2008; Layng & Twyman, 2013). The set of procedures known as active responding strategies
(ARS) are some of those techniques. ARS improve learning and increase students’ engagement
(Alcalde & Nagel, 2019). Heward (1994) defined active responding as “observable [student]
responses made to an instructional antecedent” (p. 286). ARS include, among others, choral
responding, response cards, guided notes, and clickers (Heward, 1994; Vargas, 2013). The
effectiveness of ARS for enhancing students’ learning and motivation is, for the time being, a
well-demonstrated fact. Besides their usefulness in the classroom, ARS may offer an additional
advantage: They could make classes more inclusive.
ARSs benefit educators for several reasons. 1) By using ARSs, educators can obtain
immediate feedback from their students' performance in a far more effective way than with any
other technique because any ARS entails a real-time evaluation. In consequence, educators can
adjust their teaching strategies timely. 2) As ARSs yield immediate knowledge of the individual
characteristics of the students in a class, it is easier for a teacher to know what each of them
needs and how to help them. 3) Educators involve their students more deeply with ARS than
with traditional techniques. 4) By increasing their students' engagement in the classroom,
educators have fewer instances of problematic behaviors that can affect the learning process.
That is, it seemed to us that ARSs provide teachers with the means to make real inclusive classes
(Chance, 2008; Embry & Biglan, 2008; Vargas, 2013)
Though, at first sight, some people might relate ARS with elementary and high school
teaching, university lecturers and professors have also discovered the benefits of interactive
technologies. For instance, Clicker Assessment and Feedback (CAF), also known as Classroom
Communication System (CCS), Student Response System (SRS), or Audience Response
Technology (ART) has become increasingly popular in European and North American
Running head: Active Responding and Inclusion
universities (Bruff, 2009). The impact and success of clicker technology on education has been
so significant that by 2008, clickers manufacturers had sold eight million, as Chien, Chang, &
Chang (2016) noted. As Han & Finkelstein (2013) argued, CAF technologies have proven useful
for enhancing students’ learning and engagement. They have been replacing the traditional
university lectures in which just a few students participate. Nevertheless, though CAF
technologies engage students (Tlhoaele, Hofman, Naidoo, & Winnips, 2014), there is no
evidence that they also result in greater inclusiveness at the higher education level where
educators face more frequently than not large numbers of students. Most likely, ARS --CAF
included-- technologies might lead to more inclusive classes, but to understand how, it is crucial
to have a measurement of inclusiveness.
As Chien et al. (2016) claim, following Lasry's (2008) previous argument, clicker
technology is expensive. For most South American public universities, and, perhaps, for most
low and middle-income countries, these technologies may be out of reach, and most importantly,
they may be unnecessary. Lasry (2008), concerned with costs, compared clickers with flashcards
(response cards) and found no meaningful difference between them regarding the amount of
learning they produce: a high investment with clickers may be unnecessary. As ARS might help
teachers to make their classes more inclusive at every level, the purpose of this study was to
evaluate the effect of whiteboards, an effective and low-cost active responding strategy on
students' perception of inclusion in the classroom, which we evaluated with their voluntary
participation and their report on how included they felt. Instead of Lasry's flashcards, we used
response whiteboards (RW), which were, in our case, equivalent to the write-on response cards
that other researchers have used (see Randolph, 2007 and also Heward, 1994). We also choose
Running head: Active Responding and Inclusion
students' responses on whiteboards for this study, instead of flashcards, because the students
could write their short answers to the Professor's questions.
It is worth noting that, though other researchers have measured issues related or
seemingly related to inclusion, they might not have measured actual inclusion. They have
measured perceptions of engagement in the class (Blasco-Arcas, Buil, Hernández-Ortega, &
Sese, 2013; Carnaghan & Webb, 2007; Gauci, Dantas, Williams, & Kemm, 2009; Heaslip,
Donovan, & Cullen, 2014; Martyn, 2007; Zayac, Ratkos, Frieder, & Paulk, 2016), involvement
in learning (Heaslip et al., 2014), motivation to think (Gauci et al., 2009), intrinsic motivation
(Harper, 2009), preference of ARS (Zayac et al., 2016), satisfaction with the class (Beckert,
Fauth, & Olsen, 2009; Carnaghan & Webb, 2007) , improvement of understanding or learning
(Blasco-Arcas et al., 2013; Martyn, 2007; Zayac et al., 2016), improvement of grades (Clayton &
Woodard, 2007; Kellum, Carr, & Dozier, 2001; Martyn, 2007; Stowell & Nelson, 2007),
receiving feedback (Heaslip et al., 2014), increased participation in class (Heaslip et al., 2014;
Zayac et al., 2016), enjoyment of using ASR (Carnaghan & Webb, 2007; Gauci et al., 2009;
Harper, 2009; Martyn, 2007; Zayac et al., 2016) and emotions (Stowell & Nelson, 2007).
As we mentioned, we focused on inclusion for all rather than on students with special
needs. As Lancaster (2014) commented, in the most common situation in the classroom, “higher-
achieving students have the majority of the attention and feedback and reinforcement from the
teacher” (p. 229). In consequence, instructors exclude non-higher achievers. Though a few
people might be something like universal higher achievers, most people are higher achievers in
particular subjects but lower achievers in others. Hence, most students will be excluded
sometime in some courses. Up to some point, performance in a course might measure inclusion,
but there might be situations where that is not the case. Students might even be obtaining good
Running head: Active Responding and Inclusion
grades and still feeling left out. Hence, performance, being as vital as it is, in itself is not enough
as a measure of inclusion.
Measuring inclusion in a higher education context is difficult because, as Gaudiano
(2019), from an organizational rather than an educational context, mentioned, inclusion is
somehow invisible. Bringing definitions, concepts, and strategies from non-educational contexts
can help in obtaining a better, and, by the way, more inclusive notion of inclusiveness in the
educational context, we think. For instance, according to Young (n.d.), inclusion refers to "the
many elements of the workplace that serve to acknowledge and value individual differences and
encourage people to express their unique views." By substituting the word workplace by
educational setting, we have the definition with which we best identify. Of course, this definition
covers the people with physical or psychological impairments --disabilities-- with which some
policymakers and educators seem to be mostly concerned, but it is also more comprehensive.
Under this definition, self-reported inclusion is one of the best measurements a researcher can
have.
In this study, we were explicitly concerned with measuring each student's perception of
inclusion. To measure it, we choose to directly ask the students about how included they felt in
class. Our study had two conditions: Response-on-a-Whiteboard Condition (RWC) and No-
Response-on-a-Whiteboard Condition (NRWC). Our first hypothesis was that students would
report more inclusiveness during the RWC than during the NRWC. Our second hypothesis was
that voluntary, spontaneous participation would increase during the RWC conditions of each
class in comparison with the NRWC conditions. Confirming both hypotheses would have
practical as theoretical implications. What an RWC provides to a lecturer is immediate feedback.
A positive result would demonstrate that immediate feedback results in a higher perception of
Running head: Active Responding and Inclusion
inclusion. In this paper, however, we will focus mostly on the practical aspects. A positive result
would suggest that educators at the college level could incorporate ARS in their methodology to
make their classes more inclusive.
Method
Participants
Fifty-four undergraduate students (32 men and 22 women) who were enrolled in a
program of psychology and were taking a course on Motivation in a Colombian university
voluntarily participated in the study. They were between 18 and 29 years old with a mean of 21.5
years and were between the second and tenth semester of enrollment. All of them were Latin
American and signed informed consent agreeing to participate in the study; if any student had
not signed, his or her data would not have been used. Attendance per session was 54, 46, 49, 40,
46, 39, 44, 40, and 24 students, respectively, from the first to the ninth sessions. Attendance to
the sessions diminished throughout the semester because students from the whole university
participated in social protests, and the academic period ended under a non-conventional
schedule.
Instruments and materials
The professor presented the content and questions for each session with PowerPoint Slides.
For each of the two conditions of every session, the professor had between 10 and 15 questions on
the class topics. Some of the researchers, in the role of the professor’s assistant, provided each
student with a Personal Response Whiteboard (29 x 24cm), a dry-erase marker, and a board eraser.
Students wrote on the board their responses to the teacher’s questions during the RWC. We
recorded most of the sessions with a Sony Handycam HDR-CX405.
Running head: Active Responding and Inclusion
We created an ad-hoc inclusion survey (see Annex 1) based on items from the
Inclusiveness Index that we took in its turn from the Students’ Academic Management
Questionnaire (Correa Alzate et al., 2008).al The index allows educational institutions to self-
assess their inclusive management process. The survey assessed the five components that we
considered relevant: a) feeling included, b) feeling motivated to participate, c) perception of
receiving feedback, d) perception of improvement in learning, and e) feeling of being kept into
account. Students scored the five items on a Likert scale. The instruction on the survey was:
"Based on your classroom experience, rate each section of the class on a scale of 1 to 5, with 1
(strongly disagree), 2 (partially disagree), 3 (neither agree nor disagree), 4 (partially agree), and 5
(strongly agree). Inclusion is understood as the perception of your active participation in the
activities of the class."
Procedure
The study was an intra-subject comparison in which all the students in each class, which
lasted three hours minus a 15 minutes break time, went through the two experimental conditions:
Response Whiteboard Condition (RWC) and No-Response Whiteboard Condition (NRWC). All
the class sessions had two sections, one for each condition.
Before starting data collection, a costume computer application randomized the order to
present the conditions for each session. Four sessions commenced with RWC and five sessions
with NRWC, for a total of nine sessions. During RWCs, the professor asked the students
questions, who had to answer them by writing on the whiteboards. After he had asked a question,
he waited for about one minute to instruct the students to raise the whiteboards to show their
responses. Then, the students would raise them and wait to receive immediate feedback. Then
the professor adjusted his explanations to the student's responses. During the NRWCs, the
Running head: Active Responding and Inclusion
professor asked the students questions, but instead of asking them to raise their boards, he
instructed them to raise their hands if anyone wanted to answer the question freely. After the
students had responded, the professor provided general feedback to the entire class based only on
the voluntary students' interventions. If no student raised his or her hand, the professor provided
general feedback.
As the professor did not know the order of the conditions for each session, one of the
other researchers informed him whether the session would begin with the RWC or the NRWC.
All the lectures had the same structure. The teacher asked questions as the lesson progressed.
Between sections, the group had a 15-minutes break. Students answered one version of the
inclusion survey for each of the two sections at the end of each session. We also video recorded
the audience during some sessions, but, due to technical problems, we ended up with only five
complete session recordings. Subsequently, two of the researchers watched the videos to count
how often the students raised their hands to participate. The observed period was between the
final 15 and 25 minutes of each section.
A voluntary participation was the occasion in which students raised their hands to say something
to the class without being requested by the professor. Interobserver agreement was over 90%.
Data Analysis
We compared the total and individual items scores between the two conditions with the
dependent samples t-test. We also contrasted these measures for each session and reported the
frequency of sessions with significant differences between conditions. We contrasted voluntary
participation frequency for the observed periods of observation of RWC with the periods of
NRWC with the Wilcoxon signed-rank test.
Running head: Active Responding and Inclusion
Results
As students’ attendance varied from session to session, the number of surveys also varied
from session to session. We obtained a total of 758 surveys (379 for each condition), an average
of 84 responded surveys for session (range 48-102). There was a significant difference between
largest difference was for item 1 (feeling of inclusion), and the smallest, for Item 4 (improving
learning). Item 2 (Motivation to participate) had the second largest difference in favor of the RWC,
and Item 5 (The feeling of being taken into account), the third. Item 3 (perception of receiving
feedback) had the fourth largest difference.
We also found an order effect for item 4. Scores in the first section (M=4.26, SD= 0,93)
were significantly lower than those in the second section (M = 4.39, SD = 0.84), t(378) = -3.09, p
< 0.01).
1). Nevertheless, the difference was not significant for all the sessions. Total scores for RWC were
significantly higher than NRWC scores for five out of the nine sessions. Item 1 was the one with
more sessions with significant differences between conditions (6 out of 9 sessions). Items 3 and 4
had the least amount of sessions with significant differences (2 out of 9).
Running head: Active Responding and Inclusion
Regarding the frequency of voluntary participation, we found that during NRWC (M=8.1,
SD=2.38) sections, it was higher than in RWC (M=5.1, SD=1.64). The difference was significant,
Discussion
The students' perception of inclusion in the classroom was our main concern in this study.
We hypothesized that the students would report more inclusiveness during the RWC than during
the NRWC and, second, that they would participate more frequently during the RWC conditions
than during the NRWC conditions. We measured as dependent variables the students' scores on
the inclusion survey and their raised hand –voluntary participation— frequency in each section of
item higher under the RWC than under the NRWC, which support our first hypothesis. However,
it is worth pointing out that the difference between RWC and NRWC scores for some of the
more students raised their hands during the NRWC than on the RWC, contrary to what we
expected.
From the five items that composed the inclusion survey, items 1 and 5 asked directly about
how the students felt about their inclusion during the lecture, so they are a straight report of the
component for which there was the greatest mean difference between conditions for all the sections
but one, the difference was significant and always favored the RWC. When the students used
whiteboards, this was the component that they scored the highest through all the sessions; when
Running head: Active Responding and Inclusion
they did not use them, this was one of the components that they scored the lowest. Item 5, The
feeling of being taken into account, was the third with the most substantial difference between
conditions. Together, the responses to these two items suggest that most students felt more
included under the RWC condition than under the NRWC condition.
Using whiteboards allowed the students to freely express their views by writing open
answers, which we think contributed to producing the observed scores to Items 1 and 5. Feeling
that opinions are taken into account and feeling valuable are both parts of engagement (Blasco-
Arcas et al., 2013). Being taken into account can be the key to feeling involved (engagement) and
might provide a sense of belongingness to the class. These outcomes entail satisfaction with the
class, which coincides with other studies that had demonstrated more satisfied, less bored, and
more proud students when educators use active responding than when educators use more passive,
traditional lectures (Keough, 2012; Stowell & Nelson, 2007). According to Clayton & Woodard
(2007) and Kellum et al. (2001), university students report more enjoyment with active responding
strategies and interest in extending their usage to other classes.
Item 2, Motivation to participate, had the second greatest mean difference in favor of the
RWC, overall it was a significant difference, but over several sessions it was not. This suggests
that Motivation to participate might not correlate with the perception of inclusion. On the other
hand, compared to the other components, Item 2 obtained the lowest score for both NRWC and
RWC, sections 9 and 10. In general, active responding strategies might unnecessarily make the
students' voluntary participation, as Graham, Tripp, Seawright, & Joeckel (2007) suggest. For
instance, usually, non-talkative students prefer active response rather than individual
participation because, in that way, they can receive instructors' recognition (Beckert et al., 2009).
Running head: Active Responding and Inclusion
Some of the students in our study might have preferred not to participate despite
reporting that they felt included. As Heaslip et al. (2014) and Martyn (2007) argued, the
anonymity offered by some of the ARS increases the willingness of students to participate in
class because there is a smaller risk of unfavorable judgment by the instructor or peers
(Randolph, 2005). For instance, some studies suggest that students might prefer clickers over
response cards, probably because of the higher degree of anonymity they allow (Zayac et al.,
2016).
Item 3, the perception of receiving feedback on understanding and Item 4, The perception
of improving learning, showed the smallest differences between conditions, which, from the
students' perspective, indicate that they were learning more or less the same under both
conditions. They also seem to have perceived that they were receiving the same amount of
feedback during both conditions. The small difference between conditions for these components
may have resulted from being dependent on factors that did not vary much between conditions,
such as the professor's explanatory style or the quality of his feedback; under both conditions, the
professor explained the concepts using the same strategy and similarly gave feedback. Some
research has shown, in contrast, that ARS improves performance, learning, and the perception of
improvement in understanding and grades (Clayton & Woodard, 2007; Kellum et al., 2001;
Keough, 2012; Zayac et al., 2016).
Although ARSs do not significantly increase the perception of learning, they do improve
it. Deslauriers, McCartya, Miller, Callaghan, and Kestin (2018) compared the self-reported
perception of learning with the actual learning of two groups of students in an introductory
course to Physics. One of the groups received active instruction while the other, passive
instruction. The researchers provided them with identical class content and handouts. Students in
Running head: Active Responding and Inclusion
active classrooms learned more, but their self-reported perception on their learning, while
positive, was lower than that of their peers in the passive environment. Students under active
learning conditions have more information of the errors they are committing during their
learning process while students under passive conditions may confuse the easiness with which a
lecturer explains a topic with their real understanding of the topic. For instance, it is one thing to
understand how a good math lecturer solves an equation, and another thing is to be able to solve
it by oneself.
Another point we deem worth mentioning is that in this study, the questions the students
had to answer evaluated two types of contents. On the one hand, the questions assessed content
from the texts that the students had to read for each session. On the other hand, the questions
evaluated what the professor taught during each session, but that was not in the texts. Hence, the
questions might have been evaluating two different skills. Some of them might have evaluated
reading comprehension, while others evaluated what the students have learned during each
section. A future study should differentiate between both types of contents. ARS are mostly
concerned with what happens in the class. Having two types of questions might be one of the
reasons for the students to report that they have felt included and simultaneously that they have
not learned that much.
Regarding our second hypothesis, voluntary participation, contrary to what we expected,
decreased during the RWCs. We assumed that participants should have raised their hands to ask
something or gave their opinion about the subject in discussion because the active strategy
should have motivated them to get more engaged in the class. As the students’ response to the
inclusion survey showed, students reported feeling included – Items 4 and 5 – during most of the
sessions, but not necessarily more motivated. The difference between conditions to Item 2,
Running head: Active Responding and Inclusion
feeling motivated, for most of the sessions but two favored the RWC, however, it was
meaningful for only two sessions, and, in general, the scores were lower than for the other items.
The RWC do not seem to have motivated the students to participate more frequently. As
we noted above, under the RWC, voluntary participation by raising hands might have become
unnecessary. During the RWC, the professor knew all the students' answers, because they wrote
them on the white boards, and the professor may have provided more useful feedback than
during the NRWC. Hence, why should the students feel motivated to participate? On the other
hand, using boards demands much more time from the students than raising hands, leaving less
time for voluntary participation. Some students have reported this as a disadvantage of some
active response technologies (Randolph, 2005). Our results agree with Carnaghan & Webb
(2007), who found that although satisfaction increased, voluntary participation declined, but they
contradict Keough's (2012) findings in his meta-analysis.
Some points to discuss are relevant to our conclusions and future studies. First, the
number of students attending each session diminished gradually during the academic period due
to political demonstrations, which at first sight seem to affect our conclusions. Although
conducting the study with all the students who had registered it would have been ideal, we
believe that not having all the students during the course does not affect our conclusions. In any
case, the percentage of students who finalized it constitutes a proper sample size, and the
tendency in all the data is similar along with the sessions.
Second, the perception of inclusiveness did not correlate with self-reported learning. If all
of the students of a class have learned all the contents, in practice, the course effectively included
them. Otherwise, not all of them would have learned, at least regarding the learning of the
contents taught. However, despite having learned all the contents of a course, some might report
Running head: Active Responding and Inclusion
that they did not feel included. This point is relevant because while an instructor might have
effectively included a student from the perspective of teaching and learning, some students might
have different perceptions. As argued in the introduction, the notion of inclusion might be more
comprehensive and extend beyond the teaching-learning process. For instance, minority students
might be learning everything along with their peers, while they might feel that the instructor and
classmates exclude them. An instructor, having effective teaching methods, might respond more
and better to some students than others. Under these conditions, those students receiving less
attention would learn and also report exclusion. We did not explore this issue in this study, but
definitely, it deserves further inquiry.
Individual response boards contribute as appropriate and powerful tools for making
university classes more inclusive. They turn out to be an economical option versus those
involving electronic devices. Compared to the response cards, they allow more flexibility and
creativity in the response. Our results suggest that the use of response boards can help overcome
barriers such as shyness, lack of motivation, and social anxiety when participating in a class.
Future research may determine whether response boards generate better learning, more
motivation, and more inclusion than other active response technologies.
Running head: Active Responding and Inclusion