Dimensional salience varies across verbal and nonverbal domains
Ashley E., Symons1,2†, Magdalena Kachlicka1,2., Emily Wright 2, Raha Razin2, Fred Dick2,3,
Adam T. Tierney2
1 Department of Psychology, Royal Holloway, University of London
2 Department of Psychological Sciences, Birkbeck College, University of London
3 Division of Psychology & Language Sciences, University College London
Ashley E. Symons
Department of Psychology
Royal Holloway, University of London
Egham Hill, Egham,
TW20 0EX
United Kingdom
Email: ashley.symons@rhul.ac.uk.
Abstract
Information in speech and music is conveyed via multiple auditory dimensions. The
informativeness of these dimensions can vary across domains, with pitch typically more
informative for categorizing musical features, and durational cues for categorizing linguistic
features in English speech. Some theories of sound categorization predict that informative
auditory dimensions attract attention. Here we tested whether prior experience with the statistical
regularities present in speech and music increase the salience of informative dimensions.
Listeners heard speech and synthesized tone streams that varied in pitch height and sound
duration at fixed rhythms. In the dimension-selective attention task, listeners attended to pitch or
duration patterns and monitored for repetitions in the attended dimension. In the dimensional
salience task, listeners detected amplitude oddballs while electroencephalography (EEG) was
recorded. Neural tracking of changes in each dimension provided a measure of salience.
Experiment 1 showed enhanced selective attention to and increased neural tracking of pitch for
tone streams and duration for speech streams. Experiments 2 and 3 carefully matched speech and
tones for pitch contour, harmonic range, and spectral slope and yielded a similar pattern of
results, but only in non-percussionists. These findings suggest that long-term prior experience
may influence the salience of acoustic dimensions.
Key words
Attention, speech, music, pitch, duration
Introduction
Certain sounds in the environment attract our attention: the squeal of a fire alarm, the
ping of a just-toasted slice of bread, the voice of someone calling our name. What makes these
sounds capture attention? The propensity of a sound to capture attention (salience) can reflect
variation along dimensions such as pitch, timing, and intensity (Huang and Elhilali, 2020; Kaya
et al., 2020; Kaya and Elhilali, 2014; Kayser et al., 2005). For example, fire alarms tend to be
louder and higher in frequency than other sounds in the listeners’ environment. What we attend
to can also be shaped by prior experience. How does prior experience influence attentional
capture? One way is through enhancing attention to distinct auditory objects: in a crowded room,
hearing our own name captures attention (Moray, 1959; Röer and Cowan, 2021; Wood and
Cowan, 1995) because we have learned that sequence of phonemes carries relevant information.
Likewise, familiar melodies may lead to increases in attention and arousal (Jagiello et al., 2019)
because the pattern of notes matches a previously learned sequence. However, experience may
also shape attention to different acoustic dimensions within a single object.
Long-term experience with the statistical regularities of different sounds (such as a
particular language or musical system) influences the dimensions that listeners rely on during
categorization (Clayards, 2018; Francis et al., 2008; Idemaru and Holt, 2011, 2014; Jasmin et al.,
2020a, 2021; Schertz et al., 2020). Some theories suggest that this process is mediated by
attention: over time, acoustic dimensions that are informative attract attention (Francis et al.,
2000; Francis and Nusbaum, 2002; Gordon et al., 1993; Heald and Nusbaum, 2014; Holt et al.,
2018). For example, most listeners have a preferred (or “primary”) dimension that they rely on
during speech categorization based on the statistical regularities of their language (Idemaru and
Holt, 2014, 2011; Jasmin et al., 2021; Schertz et al., 2020; Zhang and Francis, 2010), and this
primary dimension may be the target of attention (Holt et al., 2018). Under high cognitive load,
listeners have fewer attentional resources to allocate to the primary dimension and therefore
more equally weight multiple dimensions (Gordon et al., 1993; Kong and Lee, 2018; Symons et
al., 2023). Computational modelling work further supports the role of attention in speech
categorization (Jurov et al., 2023). These studies suggest that long-term experience with the
statistical regularities of a particular corpus of sounds (e.g., language) influences the dimensions
to which listeners attend.
Most prior research on sound categorization has focused on identification of speech
sounds. Comparatively less work has focused on the dimensions relevant to distinguishing
sounds across domains. Speech and music are underpinned by a common set of acoustic
dimensions, but the informativeness of these dimensions may vary across domains (Patel, 2010).
Perceiving a stimulus as belonging to a particular domain may involve allocating attention
towards dimensions that are informative within that domain.
Dimensions relevant to speech
Speech is a redundant signal (Winter, 2014), with multiple acoustic dimensions that can
be used for categorization. In English speech, duration is a particularly useful dimension:
durational cues including voice onset time (Lisker, 1986), vowel duration (Hillenbrand et al.,
1995, 2000), and the duration of formant transitions (Walsh and Diehl, 1991) distinguish
different consonants and vowels. Perception of English speech therefore requires precise
perception of duration. By comparison, variations in relative pitch level and contour play a
secondary role during speech perception in non-tonal languages. Although pitch carries prosodic
information (Breen et al., 2010; de Pijper and Sanderman, 1994; Fear et al., 1995; Mattys, 2000;
Streeter, 1978), this information is also conveyed by variations in other dimensions. For
example, while perception of lexical stress in English can be cued by pitch variations (Fear et al.,
1995; Mattys, 2000), this information is also carried via other dimensions such as vowel quality
and duration that may be more informative for English listeners (Chrabaszcz et al., 2014; Zhang
and Francis, 2010). Although variations in pitch can benefit speech comprehension under certain
conditions, such as when speech in embedded in noise, listeners can nonetheless recognize
whispered speech and speech with flat pitch contours (Liu and Samuel, 2004; Patel et al., 2010;
Tartter, 1991; Watson and Schlauch, 2008). Likewise, individuals with severe difficulties with
pitch perception and memory have minimal difficulties perceiving speech (Liu et al., 2015),
possibly because they make greater use of other dimensions (Jasmin et al., 2020a, 2020b).
Dimensions relevant to music
Although pitch tends to serve a secondary role in speech perception in non-tonal
languages, information caried by pitch intervals and contour can serve important functions in
music (McDermott and Oxenham, 2008). In Western tonal music, pitch differences of one
semitone indicate whether a tone is in key (Trainor and Trehub, 1994). Representing precise
pitch intervals is also vital for recognizing melodies, with manipulations of pitch intervals
impairing melody perception (Dowling and Fujitani, 1971; McDermott et al., 2008). The
importance of pitch in music is further highlighted by studies comparing pitch processing in
music versus speech. For example, pitch discrimination ability is enhanced for music compared
to speech in typically-developing children (Järvinen-Pasley and Heaton, 2007). Studies of the
speech-to-song illusion (Deutsch et al., 2011), in which certain spoken phrases begin to sound
more musical after repetition, have found increased activation in pitch-sensitive regions of the
brain when phrases are perceived as song compared to speech (Tierney et al., 2018, 2013), with
illusion strength correlating with individual differences in attention to pitch (Tierney et al.,
2021). Sensitivity to pitch changes increases following the induction of the illusion (Vanden
Bosch der Nederlanden et al., 2015).
Attention to acoustic dimensions across domains
Despite differences in the informativeness of acoustic dimensions in speech and music,
few studies have directly compared listeners’ ability to attend to pitch versus durational
information across domains. In one exception, Sares and colleagues (2018) presented listeners
with phrases and tone sequences that varied in pitch and rhythmic patterns. Listeners were better
at judging pitch direction for tones compared to speech, but better at matching durational
patterns for speech compared to tones. These findings suggest that attention to different acoustic
dimensions may vary across domains. However, there were important differences between the
speech and tone sequences that could have influenced performance across the two tasks,
including differences in pitch contour and the presence of semantic information in speech. While
this study provides initial evidence of enhanced processing of pitch in music and durational
patterns in speech, the mechanisms underpinning these effects remain unclear.
There are at least two ways that prior experience could influence attention to acoustic
dimensions. One possibility is that long-term exposure to the statistical regularities within a
domain sharpens endogenous selective attention to informative dimensions. Alternatively, long-
term exposure to a given language or musical system may change the salience of acoustic
dimensions. Across relatively short timescales, listeners track statistical regularities present
within an acoustic scene, with sounds that deviate from listeners’ expectations along one or more
dimensions capturing attention (Kaya and Elhilali, 2014; Tsuchida and Cottrell, 2012). Longer-
term experience with the regularities present in language or music could increase the salience of
informative dimensions within that domain, even when variations along those dimensions are
temporarily not task-relevant.
One challenge to addressing the effect of prior experience on attention to acoustic
dimensions has been the lack of a paradigm that can reliably measure both exogenous and
endogenous attention to these dimensions. To address this issue, we developed an EEG paradigm
that is sensitive to dimensional salience and dimension-selective selective attention (Symons et
al., 2021). In this study, listeners heard rhythmic sound sequences that varied in two different
dimensions (pitch and spectral peak frequency); each dimension was tagged to a fixed rate. Pitch
could change every 2 sounds (2 Hz) and spectral peak every 3 sounds (1.33 Hz), or vice versa.
The degree to which the brain tracked information at the rates corresponding to pitch and
spectral peak frequency provided a measure of attention to each dimension. To measure
exogenous attention, we varied the salience of the pitch dimension by presenting sequences with
large (+2 semitones) or small (+1 semitone) pitch intervals while holding the salience of the
spectral peak dimension constant. Increasing pitch salience enhanced pitch but not spectral peak
tracking. To measure endogenous attention, we held the pitch interval size constant and instead
instructed participants to attend to pitch or spectral peak and monitor for occasional repetitions in
the attended dimension. As predicted, neural tracking was greater for the attended compared to
unattended dimension. Here we used this paradigm to investigate changes in dimension-selective
attention and dimensional salience across domains.
The current study
Across three experiments, listeners completed dimension-selective attention and
dimensional salience tasks with speech (vowel) and synthetic tones. Synthetic tones were
matched to the vowels along pitch and duration dimensions. Listeners heard speech and synthetic
tone streams that varied in pitch and duration at fixed rates. In the dimension-selective attention
task (an online behavioral task adapted from prior work) (Symons et al., 2021), listeners
monitored for repetitions in one dimension while ignoring variations in the other. The proportion
of correctly detected repetitions provided a measure of dimension-selective attention. In the
dimensional salience task, listeners monitored for rare quiet sounds while EEG was recorded.
This task ensured participants stayed engaged while minimizing top-down selective attention to
either of the two dimensions of interest. Neural tracking of changes in pitch and duration (as
measured by inter-trial phase coherence, ITPC) provided a measure of dimensional salience.
We predicted enhanced attention to pitch relative to duration for synthetic tone compared
to speech streams. If prior experience increases the salience of informative dimensions, we
would further predict this effect to be evident even when listeners are not explicitly directing
attention to either dimension. Moreover, if the salience of acoustic dimensions is influenced by
an individual’s prior experience (as well as their unique auditory system), we would expect
stable individual differences in the relative salience of pitch versus duration across domains.
Listeners for whom pitch is more salient than duration for speech should also find pitch more
salient than duration for tones, and vice versa.
Experiment 1
Introduction
In Experiment 1, we tested the prediction that endogenous and exogenous attention to
acoustic dimensions varies across domains. Listeners completed an online dimension-selective
attention task in which they selectively attended to pitch or duration, and an in-lab dimensional
salience task in which they listened to sequences that varied in pitch and duration without
directing attention to either of the two dimensions. In this experiment, the duration and pitch of
the synthetic tones were matched to the duration and mean pitch of the speech sounds, consistent
with prior work (Sares et al., 2018). We predicted better selective attention to and increased
neural tracking of pitch relative to duration for synthetic tone compared to speech streams.
Methods
Participants
71 native English speakers were recruited for this experiment. 11 of these participants
failed the dimension-selective attention practice task, resulting in a final sample of 60 native
English speakers (40 female, 19 male, 1 other gender) between the ages of 18-40 (mean age =
24.03, sd = 5.56). Additional participant details can be found in the Supplementary Materials.
Dimension-selective attention task
Stimuli. Speech stimuli were extracted from the phrase “Tom likes barbecue chicken”
from the MBOPP database (Jasmin et al., 2020c). Two versions of this phrase that differed in
whether the emphasis was placed on the word “barbecue” or on the word “chicken” were
recorded. For the purposes of this study, we extracted the vowel /a/ from the word “barbecue” in
both versions of the phrase. A 10-ms cosine on/off ramp was applied to the stimuli.
To identify the endpoints of the pitch discrimination continuum, we first morphed the two
versions of the vowel along the pitch dimension using STRAIGHT voice morphing software
(Kawahara and Irino, 2005) from levels 0 (100% contribution of the version where “barbecue”
was not emphasized) to 100 (100% contribution of the version where “barbecue” was
emphasized) while holding duration constant. We then computed the mean F0 of each vowel to
identify the morphing level that differed from level 0 by approximately 2 semitones (difference =
2.03 semitones). We then used Praat. Version 6.1.08 (Boersma and Weenink, 2019) to morph the
duration of the vowel to approximately 70 and 175 ms (difference = 105.25 ms). The result was a
2 (pitch) x 2 (duration) stimulus grid.
The tone stimuli consisted of complex tones (4 harmonics, 10-ms cosine on/off ramp).
The tones varied along two dimensions: pitch (F0) and duration. There were 2 levels of pitch that
differed in F0 (difference = 2.0 semitones) and 2 levels of duration (difference = 105 ms),
resulting in 4 unique tones.
The speech and tone stimuli were concatenated into 2-Hz sequences (separate sequences
for speech and tones) in which pitch and duration changed at fixed rates (0.67 Hz and 1 Hz).
When pitch changed every 3 sounds (0.67 Hz), duration changed every 2 sounds (1 Hz). When
pitch changed every 2 sounds (1 Hz), duration changed every 3 sounds (0.67 Hz). Repetitions, or
instances in which the dimension did not vary at the expected rate, were inserted into half of the
sequences for each dimension. Repetitions could occur at any position within the sequence, with
the position of the repetition in the sequence selected randomly. There were equal numbers of
repetitions for each level of pitch and duration. Thus, the stimuli in each attention condition were
identical, varying only in the focus of attention.
64 speech and 64 tone sequences were generated and assigned to either attend pitch or
attend duration conditions (32 trials/attention condition). The stimuli that were assigned to attend
pitch and attend duration conditions were counterbalanced across participants.
Procedure. Prior to the task, participants heard examples of the different levels of pitch
and duration to ensure they could hear the differences in the two dimensions. Participants then
listened to example sequences in which a single dimension varied while the other dimension was
held constant. Visualizations were provided for example sequences with and without repetitions.
After listening to the examples, participants completed a single dimension practice task.
The practice task was blocked by attended dimension, but with the change rate randomized. At
the start of each block, participants were told which dimension to attend to and the rate at which
that dimension was expected to change. Participants received 8 trials per attention condition (4
per change rate) in which just the attended dimension varied. Participants were required to score
at least 6/8 (collapsed across the two change rates) correct. If participants failed to reach the
threshold, they repeated the training for that dimension up to 3 times. Participants who failed the
practice after 3 attempts did not progress to the experiment.
The main task consisted of 4 blocks presented in a random order, each corresponding to a
different condition (2 attended dimensions x 2 change rates). At the start of each block,
participants were told which dimension to attend to and the rate at which that dimension was
expected to change. Each trial began with 500 ms of silence followed by the presentation of the
stimulus.
Once the stimulus finished playing, participants indicated whether or not they heard a
repetition by pressing response buttons on the screen. Feedback was provided on each trial. Self-
paced breaks were provided between blocks. These tasks lasted approximately 20 minutes.
Data processing and analysis. Statistical analyses were carried out in R, Version 4.3.1
(R Core Team, 2020). Proportion correct (collapsed across change rate) for each dimension was
the dependent variable. A 2 (attended dimension) x 2 (domain) repeated-measures ANOVA was
used to test the prediction that attention to pitch versus durational cues would vary across
domains. Significant interactions were followed up with paired t-tests, with p-values corrected
for multiple comparisons using the Benjamini-Hochberg procedure (Benjamini and Hochberg,
1995). We then computed a measure of relative dimension-selective attention performance for
each domain by dividing the proportion correct in the attend pitch task by the sum of proportion
correct on the attend pitch and attend duration tasks. This measure provides values ranging from
0 (better dimension-selective attention to duration) to 1 (better dimension-selective attention to
pitch). Pearson’s correlations were used to test whether there were stable individual differences
in relative accuracy of pitch versus duration repetition detection across domains.
Dimensional salience task
Stimuli. The base stimuli used for the dimensional salience were the same as those used
in the dimension-selective attention task. Using the 2 (pitch) x 2 (duration) stimulus grid, we
created 5-Hz sequences (120-seconds) in which pitch and duration varied at fixed rates (1.67 Hz,
2.5 Hz). The stimuli consistently varied at these rates except for 20 repetitions which were
inserted into each sequence. These repetitions were inserted to prevent the stimuli from
becoming overly predictable but were task-irrelevant. For each sequence, the amplitude of 3-5
randomly-selected sounds (32 in total) was decreased by 25% (-12.04 dB) to create amplitude
oddballs. Oddball timing was randomized, with the exception that oddballs could not occur in the
first or last 4.8 seconds of the sequence and could not occur within 4.8 seconds of another
oddball. The same sequences were presented to all participants, but with the order randomized.
This task was chosen to keep participants alert throughout the study, and performance was near
ceiling across both domains (see Supplementary Materials).
Task. Participants completed a practice task outside of the booth in which they listened
to two short sequences, each containing three oddball sounds, and pressed the space bar on the
keyboard when they detected those sounds. Visual feedback was provided. If they failed to detect
at least three of the six oddball tones, or if they had more than four false alarms, the task was
explained to them a second time and they were asked to complete a second practice block. All
participants passed the practice task.
In the main task, participants heard each sequence and pressed the trigger button on an
Xbox One game controller when they detected the oddballs. No feedback was provided.
Stimuli were presented using PsychoPy3 (v 3.2.3) and the sound delivered via ER-3A
insert earphones (Etymotic Research, Elk Grove Village, IL) at a level of 80 dB SPL.
EEG acquisition and preprocessing. EEG data was recorded from 32 Ag-Cl active
electrodes using a Biosemi™ ActiveTwo system with electrodes positioned according to the
10/20 montage. Data were recorded at a sampling rate of 16,384 Hz and digitized with 24-bit
resolution. Two external reference electrodes were placed on the earlobes for off-line re-
referencing. Impedance was kept below 20 kΩ.
The data were down sampled to 512 Hz and re-referenced to the average of the earlobe
electrodes. A low-pass zero-phase sixth-order Butterworth filter (cutoff = 30 Hz) and a high-pass
fourth-order zero-phase Butterworth filter (cut-off = 0.5 Hz) were then applied and the data
divided into epochs spanning 6 consecutive tones (1.2-seconds). Independent component
analysis was used to correct for eye blinks and movements. Components corresponding to blinks
and movements were identified and removed based on visual inspection of the time courses and
topographies. Epochs containing artifacts exceeding +/- 100μV were rejected. Trials containing
button presses were also excluded. A Hanning-windowed fast Fourier transform was then applied
to each epoch. The complex vector at each frequency was converted to a unit vector and
averaged across trials. The length of the average vector provides a measure of ITPC, ranging
from 0 (no phase consistency) to 1 (perfect phase consistency).
Prior to analysis, we extracted data from the 9 channels with the maximum ITPC when
averaged across the two change rates (pitch at 1.67 Hz/duration at 2.5 Hz, pitch at 2.5
Hz/duration at 1.67 Hz) and all participants (Symons et al., 2021). This resulted in a cluster of
frontocentral channels (F3, Fz, F4, FC1, FC2, FC5, FC6, Cz, C3), across which data were
averaged.
All EEG data processing was carried out in Matlab (version 2021a, MathWorks, Inc)
using the FieldTrip M/EEG analysis toolbox (Oostenveld et al., 2011) combined with in-house
scripts.
Statistical analysis. The statistical analysis was identical to the dimension-selective
attention task. A 2 (dimension tracking) x 2 (domain) repeated-measures ANOVA tested whether
neural tracking of pitch versus duration was enhanced for synthetic tone compared to speech
streams. Significant interactions were followed up with paired t-tests, with p-values corrected for
multiple comparisons (Benjamini and Hochberg, 1995). Relative dimensional salience was
computed by dividing ITPC to pitch changes by the sum of ITPC to pitch and duration changes.
This measure provides values ranging from near zero (higher duration salience) to near one
(higher pitch salience). Pearson’s correlations were used to test whether there were stable
individual differences in the relative salience of acoustic dimensions across domains.
Results
Dimension-selective attention
A main effect of dimension showed that listeners were better at detecting pitch compared
to duration repetitions, F(1,59) = 5.11, p = 0.03, np2 = 0.08. There was no main effect of domain,
F(1,59) = 0.05, p > 0.05, np2 = 0.00, suggesting that task difficulty was balanced across the two
domains. However, the relative difficulty of detecting pitch versus duration repetitions varied
across domains, F(1,59) = 28.09, p < 0.001, np2 = 0.32 (Fig. 1A). Listeners showed higher
accuracy in the attend pitch task for tone compared to speech streams, t(59) = 5.18, p <
(corrected)
0.001, and higher accuracy in the attend duration task for speech compared to tone streams, t(59)
= 3.42, p < 0.001. Correlational analyses showed stable individual differences in the
(corrected)
relative accuracy of pitch versus duration repetition detection across domains, r = 0.43, p < 0.001
(Fig. 1B).
Dimensional salience
Neural tracking was stronger for duration compared to pitch, F(1,59) = 15.70, p < 0.001,
np2 = 0.21 and for speech compared to synthetic tone streams, F(1,59) = 14.32, p < 0.001, np2 =
0.20. There was a significant interaction between domain and dimension, F(1,59) = 91.73, p <
0.001, np2 = 0.61 (Fig. 1C), with enhanced pitch tracking for tone compared to speech streams,
t(59) = 4.28, p < 0.001, and vice versa for duration tracking, t(59) = 8.94, p <
(corrected) (corrected)
0.001. Correlational analyses showed stable individual differences in the relative salience of
pitch versus duration across domains, r = 0.42, p < 0.001 (Fig. 1D).
Experiment 1 results. (A) Bar plots showing proportion correct for attend pitch and attend duration tasks with points
displaying individual data. Error bars represent the standard error of the mean. (B) Individual differences in relative
accuracy of pitch versus duration repetition detection across the two domains. (C) Line plots showing neural
tracking of pitch and duration with thick line representing the mean and thin lines representing individual data
points. Topographic plots are shown below with colors ranging from 0 (blue) to 0.2 (red). (D) Individual differences
in the relative tracking of pitch versus duration across the two domains. For (B) and (D) dotted line shows the
identity function y = x.
Discussion
Experiment 1 demonstrated that endogenous and exogenous attention to acoustic
dimensions vary across domains. Listeners showed better dimension-selective attention to pitch
and enhanced pitch tracking for synthetic tone compared to speech streams. On the other hand,
listeners showed better dimension-selective attention to duration and enhanced duration tracking
for speech compared to synthetic tone streams. These findings suggest that exposure to the
statistical regularities of sounds within a domain enhances the salience of informative
dimensions.
There were stable individual differences in the relative salience of pitch versus duration
across domains: irrespective of domain, some individuals consistently attended more to one
dimension compared to the other. This variability could be driven by listeners’ auditory abilities;
prior work has suggested that individuals with poor pitch perception may attend less to pitch
relative to duration because pitch is a less informative cue for them (Jasmin et al., 2020a).
Another possible source of this individual variability is prior experience with language and
music. Although all our participants were native English speakers with no tonal language
experience, many had exposure to other languages that vary in their use of pitch and durational
cues that may influence the relative salience of these dimensions (see General Discussion).
Musical training may also lead to enhanced attention to certain acoustic dimensions relevant for
both speech and music (Patel, 2014, 2011). Although musicians showed better dimension-
selective attention, the pattern of results was consistent across participants with and without
musical training (see Supplementary Materials).
One limitation to this study is that the difference in attention to pitch versus duration
could be driven by acoustic differences across domains. Speech and synthetic tones differed in
pitch contour, which was static for the tones but dynamic for speech, and it may have been easier
for listeners to track a static pitch contour. Additionally, speech stimuli contained a larger
harmonic range and greater variation in spectral slope across stimuli. Since spectral variations
can influence pitch perception (Allen and Oxenham, 2014), differences in the amount of spectral
information available across domains may also account for the observed effects. To rule out the
possibility that acoustic confounds drove the differences across domains, we conducted a second
experiment in which we matched the acoustics of the speech and synthetic tone streams.
Experiment 2
Introduction
In Experiment 2, we tested the possibility that acoustic differences rather than prior
experience drove differences in dimensional salience across domains. The tasks were identical to
Experiment 1, but the speech and synthetic tone streams were matched for pitch contour, spectral
slope, and harmonic range. If the results of Experiment 1 reflect acoustic differences, the relative
salience of pitch versus duration should be equivalent across domains when sounds are
acoustically matched. By contrast, if prior experience shapes dimensional salience, the salience
of pitch versus duration should vary across domains in a pattern consistent with the statistical
regularities present within each, even after matching domains for low-level acoustic dimensions.
Methods
Participants
45 participants were recruited from the Prolific online recruitment platform (prolific.co)
for the dimension-selective attention task. 9 of these participants failed the practice task and were
removed from analysis. 2 additional non-native English speakers were removed from analysis,
consistent with the exclusion criteria in Experiment 1. The remaining 34 participants were native
English speakers (18 female, 16 male) between the ages of 18-55 (mean age = 34.47, sd = 9.00).
20 native English speakers (11 female, 9 male) between the ages of 18-39 (mean age =
28.75, sd = 6.08) took part in the dimensional salience task.
Both sample sizes provided over 80% power (alpha = 0.05, number of simulations =
1000) to detect a significant interaction between domain and dimension based on the means and
standard deviations of Experiment 1 (Lakens and Caldwell, 2021).
Stimuli
The speech stimuli were generated in the same manner as Experiment 1 except that a
low-pass Butterworth filter with a 3500 Hz cut-off was applied to match the harmonic range
between speech and synthetic tone stimuli. To generate the synthetic tones, we extracted the
vowel pitch contours using Praat. Using a custom Matlab script, we constructed synthetic tones
(10-ms on/off ramp, 35 harmonics) to create tones with a pitch contour, harmonic range, and
spectral slope matched to the speech stimuli (see Supplementary Materials for details). Stimuli
were concatenated into sequences for the dimension-selective attention and dimensional salience
tasks using identical procedures to Experiment 1.
Task
The procedures for the dimension-selective attention and dimensional salience tasks were
identical to Experiment 1.
Data processing & statistical analysis
Data processing and statistical analysis methods were identical to Experiment 1. The
only exception was the channel selection, which was based on the channels with the maximum
ITPC averaged across all conditions and participants in Experiment 1.
Results
Dimension-selective attention
Contrary to Experiment 1, there was no main effect of dimension, F(1,33) = 0.17, p >
0.05, np2 = 0.01, or domain, F(1,33) = 0.15, p > 0.05, np2 = 0.01. However, dimension-selective
attention to pitch versus duration varied across domains, F(1,33) = 18.91, p < 0.001, np2 = 0.36
(Fig. 2A), with higher accuracy in the attend pitch task for tone compared to speech streams,
t(33) = 2.904, p = 0.007, and higher accuracy in the attend duration task for speech
(corrected)
compared to tone streams, t(33) = 3.01, p = 0.01. Individual differences in relative
(corrected)
accuracy of pitch versus duration detection accuracy were consistent across domains, r = 0.43, p
= 0.01 (Fig. 2B).
Dimensional salience
We observed enhanced neural tracking of duration compared to pitch, F(1,19) = 9.76, p =
0.01, np2 = 0.34 (Fig. 2C). However, there was no effect of domain, F(1,19) = 0.58, p = 0.46, np2
= 0.03, and no interaction between domain and dimension, F(1,19) = 2.11, p = 0.16, np2 = 0.10.
There was no significant relationship between the relative salience of pitch versus duration
across domains, r = 0.10, p = 0.68 (Fig. 2D).
This absence of an interaction between domain and dimension appeared to be driven by
two participants who had a high degree of drumming experience (4+ years of formal training and
regular practice but no training on other musical instruments). 1 Post hoc analysis identified these
participants as outliers (difference in relative pitch tracking for speech versus tone streams > 1.5
x interquartile range). Since percussion training involves directing attention to the durational
patterns in music, drumming experience could lead to increased duration salience for tones
relative to speech. Analysis of the data without these participants yielded a pattern of results
consistent with Experiment 1 (see Supplementary Materials).
1 This contrasts with the participants with drumming experience in Experiment 1, all who played between 1 and 6
other musical instruments. One additional participant in Experiment 2 had < 1 year of drumming training, but did
not show up as an outlier and also had formal training on voice, guitar, and violin.
Experiment 2 results. (A) Bar plots showing proportion correct for attend pitch and attend duration tasks with points
displaying individual data. Error bars represent the standard error of the mean. (B) Individual differences in relative
accuracy of pitch versus duration repetition detection across the two domains. (C) Line plots showing neural
tracking of pitch and duration with thick line representing the mean and thin lines representing individual data
points. Topographic plots are shown below with colors ranging from 0 (blue) to 0.2 (red). (D) Individual differences
in the relative tracking of pitch versus duration across the two domains. For (B) and (D) dotted line shows the
identity function y = x.
Discussion
In Experiment 2, we predicted that prior experience rather than low-level acoustics would
drive differences in dimensional salience across domains. Consistent with this prediction,
listeners showed better selective attention to pitch when listening to synthetic tone compared to
speech streams, and better selective attention to duration when listening to speech compared to
synthetic tone streams. Individual differences in the relative detection accuracy for pitch versus
duration repetitions were stable across domains, in line with Experiment 1. Contrary to our
prediction, neural tracking of pitch and duration did not differ across domains, and individual
differences in relative pitch tracking did not correlate across domains.
There are multiple possible explanations for this discrepancy. One possibility is that prior
experience influences endogenous but not exogenous attention. According to this explanation,
differences in neural tracking observed in Experiment 1 were driven entirely by acoustic
differences. Prior work has shown that neural tracking is sensitive to acoustic manipulations of
salience, such as large versus small pitch step sizes (Symons et al., 2021). Since no prior work
has investigated experience-dependent effects on neural tracking using this paradigm, it is
possible that this measure is not influenced by experience. However, studies of auditory attention
at the object level have shown experience-dependent enhancements of neural tracking as a
function of language experience (Ding et al., 2016). For this reason, we considered the
alternative explanation that variability in listeners’ prior experience could have driven the
absence of an effect in Experiment 2.
During post-hoc testing, two outlier participants demonstrated greater duration tracking
for tones compared to speech. These two participants were both percussionists but reported no
experience with other musical instruments. These participants’ greater duration tracking for
synthetic tones relative to speech could reflect their personal history directing attention to the
timing of musical sounds. As a result, the pattern of results observed in Experiment 2 may not
reflect the pattern found in the general population. When removing these two participants, the
results were consistent with Experiment 1. To test the possibility that the results of Experiment 2
were affected by two outliers with a specific type of musical experience, we conducted a third
experiment in a separate sample of participants with no percussion experience.
Experiment 3
Introduction
In Experiment 3, we tested whether dimensional salience varied across domains in a
sample of participants with no percussion experience. All experimental procedures were identical
to Experiment 2, but participants with any amount of percussion experience were excluded. This
allowed us to determine whether the effects observed in Experiment 1 were driven by differences
in the informativeness of pitch versus durational information across domains while more closely
matching the acoustics of the sounds (as in Experiment 2) and avoiding the possibility that the
relative informativeness of duration compared to pitch in synthetic tone streams is enhanced in
percussionists. Listeners in this experiment completed the dimensional salience task from
Experiment 2. If differences in dimensional salience across speech and tone streams were driven
by acoustic confounds, we would expect to observe a similar pattern of pitch and durational
tracking across domains (as in Experiment 2). However, if dimensional salience is driven by
prior experience, we would expect greater pitch relative to duration tracking for synthetic tone
compared to speech streams (as in Experiment 1).
Methods
Participants
20 native English speakers (16 female, 4 male) between the ages of 18-42 (mean age =
28.80, sd = 6.95) with no percussion experience took part in this experiment. This sample size
was selected on the basis of a power analysis (Lakens and Caldwell, 2021) using the means and
standard deviations obtained in Experiment 2 excluding percussionists. This analysis showed that
20 participants would provide over 80% power to detect an interaction between domain and
dimension (alpha = 0.05, number of simulations = 1000).
Procedure
The stimuli, task, data processing, and statistical analysis were identical to those for the
dimensional salience task in Experiment 2.
Results
Neural tracking was stronger for duration compared to pitch, F(1,19) = 10.83, p < 0.001,
np2 = 0.36, and the degree of neural tracking did not vary across domains, F(1,19) = 1.515, p =
0.23, np2 = 0.07. There was a significant interaction between domain and dimension, F(1,19) =
19.54, p < 0.001, np2 = 0.51, with enhanced pitch tracking for tone compared to speech streams,
t(19) = 4.27, p = 0.001, and vice versa for duration tracking, t(19) = 2.43, p = 0.03
(corrected) (corrected)
(Fig. 3A). There were stable individual differences in the relative salience of pitch versus
duration across domains, r = 0.48, p = 0.03 (Fig. 3B).
Experiment 3 results. (A) Line plots showing neural tracking of pitch and duration tasks with thick lines representing
the mean and thin lines representing individual data points. Topographic plots are shown below with colors ranging
from 0 (blue) to 0.2 (red). (B) Individual differences in the relative salience of pitch versus duration across the two
domains. The dotted line shows the identity function y = x.
Discussion
Consistent with the results of Experiment 1, we found that the salience of pitch and
duration varies across domains. Pitch tracking was enhanced for synthetic tone compared to
speech streams while duration tracking was enhanced for speech compared to synthetic tone
streams. Individual differences in the relative salience of pitch versus duration were stable across
domains. Thus, the failure to observe a difference in dimensional salience across domains in
Experiment 2 may have been driven by two experienced drummers in the sample. This
interpretation can be verified in future research comparing dimensional salience in musicians
who specialize in different instruments (see General Discussion). These findings support the idea
that prior experience with the statistical regularities present in language and music, rather than
acoustic differences, lead to differences in the salience of acoustic dimensions across domains.
General Discussion
Theories of sound categorization propose that long-term experience with statistical
regularities present in the environment enhances attention to informative dimensions (Francis et
al., 2000; Francis and Nusbaum, 2002; Gordon et al., 1993; Heald and Nusbaum, 2014; Holt et
al., 2018). However, the informativeness of dimensions varies across domains, and our findings
suggest that this can lead to patterns of dimensional salience that are characteristic to a given
domain. Across experiments, listeners showed enhanced attention to pitch for synthetic tone
streams and enhanced attention to duration for speech streams. This pattern was present even
when matching the acoustics of sounds across the two domains, suggesting that the effect is
driven by prior experience rather than by acoustic differences.
Long-term experience with statistical regularities within a domain could enhance
endogenous attention (selective attention) or exogenous attention (salience) to relevant acoustic
dimensions. We found better dimension-selective attention to pitch and increased pitch tracking
for synthetic tone compared to speech streams. For speech, we observed the opposite pattern,
with better dimension-selective attention to duration and increased duration tracking. This
difference in attention to pitch versus duration was observed even when variations in the two
dimensions were task-irrelevant, suggesting that prior experience influences dimensional
salience. Our findings are consistent with computational models which predict that salience is
influenced by the statistical regularities present within acoustic scenes (Kaya and Elhilali, 2014;
Tsuchida and Cottrell, 2012). We suggest that longer-term experience with language and music
regularities influences auditory salience as well. Incorporating knowledge of listeners’ prior
auditory experience with the statistical regularities of sounds present within a domain as a global
prior may boost model performance.
These results can be interpreted within a predictive coding framework in which attention
is a precision-weighted estimate of sensory input (Feldman and Friston, 2010; Parr and Friston,
2019, 2017). According to this framework, the brain continuously generates and updates
predictions about the sensory content and reliability: input expected to be reliable (high
precision) is upweighted while input expected to be unreliable (low precision) is down-weighted.
Although direct evidence for precision-weighting in audition is mixed (Heilbron and Chait,
2018), listeners are sensitive to changes in the reliability of acoustic dimensions in speech,
upweighting reliable dimensions and down-weighting unreliable dimensions in noisy
environments (Winn et al., 2013; Wu and Holt, 2022). Predictive coding suggests that listeners’
precision estimate is shaped by the statistical regularities present within a domain. When
listening to speech, listeners may expect more precise temporal information and therefore weight
durational cues more highly. To formally test this account, future studies can expose listeners to
novel sounds that vary in the reliability of different dimensions and test the effect this exposure
has on dimensional salience. A predictive coding account would predict an increase in the gain of
the neural response for dimensions with high compared to low reliability.
Our findings suggest that prior experience influences endogenous and exogenous
attention. However, different lengths or types of experience may act on different mechanisms.
These results echo recent work suggesting that long-term language experience can lead to
differences in the salience of acoustic dimensions. For example, tonal language speakers are
better at selectively attending to pitch when pitch is task-relevant and worse at ignoring pitch
when pitch is task-irrelevant compared to non-tonal language speakers (Jasmin et al., 2021),
suggesting that long-term tonal language experience increases pitch salience. While our study
focused on native English speakers, relative pitch salience in speech versus music may vary
depending on the regularities present in different languages. Future studies comparing speakers
of different languages could directly test this prediction.
Existing research suggests that musical training shapes endogenous rather than
exogenous attention to acoustic dimensions: musicians are better at selectively attending to pitch
when task-relevant but have no difficulty ignoring pitch when task-irrelevant (Symons and
Tierney, 2023). Musicians also show enhanced attention to pitch and rhythmic cues across
domains (Sares et al., 2018). One possible explanation for this difference is that musical training
tends to be more limited (e.g., 6 years in most psychology experiments) (Zhang et al., 2020)
compared to life-long exposure to one’s native language. Changes in dimensional salience might
occur over a much longer timescale than observed in musician samples included in most
experimental studies. However, some forms of musical training may influence dimensional
salience: in Experiment 2, we found no significant difference in dimensional salience across
domains when two experienced drummers were included. These individuals showed enhanced
durational tracking relative to pitch tracking for synthetic tones compared to speech. We
speculate that extensive experience directing selective attention to temporal patterns in music
may enhance the salience of duration when listening to synthetic tones. This hypothesis could be
tested by comparing the salience of pitch versus duration in drummers and musicians who
specialize in melodic instruments.
In conclusion, we show that dimensional varies across domains. Consistent with
attentional theories of sound categorization, these findings suggest that dimensions that are
informative within a domain attract attention (Francis et al., 2000; Francis and Nusbaum, 2002;
Gordon et al., 1993; Heald and Nusbaum, 2014; Holt et al., 2018). Specifically, long-term
experience with the statistical regularities present in language and music enhance the salience of
informative dimensions.