SIMILARITY-INDUCED MEMORY BIAS FOR FACES 1
Perceptual comparisons induce lasting and generalizing changes to face memory reports
Jerrick Teoh1, Joseph M Saito2, Yvanna Yeo1, Sophia Winter1 & Keisuke Fukuda1,2
1University of Toronto Mississauga
2University of Toronto
Author Note
This research was supported by the Natural Sciences and Engineering Research Council
(5009170).
The data, stimuli, and codes will be publicly available at Open Science Framework
Correspondence concerning this manuscript should be addressed to Keisuke Fukuda
(keisuke.fukuda@utoronto.ca) at the Department of Psychology, University of Toronto
Mississauga, 3359 Mississauga Rd, Ontario, L5L 1C6, Canada.
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 2
Abstract
We often have to remember new faces so that we can recognize them later in time. Recently, we
found that memory reports for basic visual features (e.g., colors and shapes) are susceptible to
systematic distortions as a result of comparison with new visual input, especially when the input
is perceived as similar to the memory. In this study, we tested whether this similarity-induced
memory bias (SIMB) would also occur with more complex face stimuli. Here, across two
experiments, we showed that face memories are also susceptible to SIMB. Furthermore, once
induced, SIMB persisted over time across cues through which the face memory was accessed for
memory report. Our results demonstrate the generalizability of SIMB and suggest potential real-
world implications.
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 3
Significance Statement
We and our society rely on our ability to remember faces accurately so that we can report them
later in time (e.g., making friends in new schools and serving as eyewitness testimony). In this
study, we demonstrated that our memory reports for face memories can be systematically
distorted as a consequence of comparisons with similar faces. Furthermore, this similarity-
induced memory bias persisted over time and generalized across retrieval cues that were learned
separately. Thus, our results demonstrate the ubiquity and robustness of the SIMB and
recommend caution when trusting face memory reports.
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 4
In everyday life, we often have to remember faces over a period of time so that we can recognize
them when we see them again. Visual working memory (VWM) allows us to actively represent a
finite amount of visual information registered through vision or retrieved from visual long-term
memory (VLTM) in mind so that we can use it to guide our behavior (e.g., Cowan, 2001;
Draschkow et al., 2021; Fukuda & Woodman, 2017; Luck & Vogel, 2013). Recently, we
demonstrated that VWM representation gets distorted when used for perceptual comparisons
with new inputs, especially when the new inputs are subjectively similar to the memory
representation (Fukuda et al., 2022). Importantly, this similarity-induced memory bias (SIMB) is
significantly larger than the bias observed when the new inputs were perceived but ignored
(Saito et al., 2022), thus implicating the causal role that similarity judgments play in modulating
the memory bias. Furthermore, the SIMB persisted over a 24-hour delay (Saito, Duncan, et al.,
2023), indicating that the SIMB incurs a lasting change to the memory representation.
Although the SIMB has been demonstrated with simple and complex stimuli (e.g.,
geometric shapes and real-world objects), stimulus similarity has been defined using a single
feature space (e.g., color). However, the similarity of real-world stimuli is defined using multiple
features (e.g., Hout et al., 2014; Valentine, 1991), and it remains to be seen whether the SIMB
occurs on such complex objects (e.g., human faces). Additionally, a past study demonstrated the
temporal persistence of the SIMB using consistent retrieval cues to trigger memory retrieval
across delays. Given that memory retrieval can be specific to the memory cue (e.g., Godden &
Baddeley, 1975; Hupbach et al., 2008; Tulving & Thomson, 1973), it is unclear whether the
SIMB persists across changes in retrieval cues.
Here, we conducted two experiments to examine whether the SIMB occurs for multi-
dimensional real-world stimuli (i.e., human faces) and whether it persists across changes in time
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 5
and retrieval cues. To preview the results, we demonstrated that the SIMB for human faces
occurs when they are just encoded into WM through vision (Experiment 1) or retrieved into WM
from visual long-term memory (VLTM, Experiments 2). Furthermore, by having participants
encode a human face with two attributes (i.e., names and university majors), each of which later
served as retrieval cues (e.g., “Remember the face of Emily.”, “Remember the face of
Psychology student”), we demonstrated that the SIMB induces a lasting change to face memories
that generalize across time and retrieval cues even when the cues were learned at separate
occasions. Taken together, these results not only expand the stimulus generalizability of the
SIMB but also demonstrate its robustness through its cue independence.
Method
Participants
Experiment 1
Previous studies that utilized more simplistic stimuli (e.g., colour, shape) reported large
effect sizes (Cohen’s d > 0.8) (Fukuda et al., 2022; Saito, Kolisnyk, et al., 2020). However,
considering that we used more complex, multi-dimensional stimuli (i.e., human faces) and tested
online for the first time, we anticipated a half-sized effect (Cohen’s d = 0.4). As a result, we
aimed to recruit at least 68 participants to establish a statistical power of 0.9 (p < 0.05, two-
tailed).
We recruited participants on a weekly basis in return for course credits for Psychology
courses until the number of qualified participants reached our target sample size. All participants
reported normal hearing and normal or corrected-to-normal vision. For Experiment 1, 73
University of Toronto Mississauga (UTM) students (mean age = 19.0 years, SD = 2.3 years, 19%
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 6
Male, 81% Female) participated. Data from four participants were excluded from the analyses
because they failed to complete 50% or more of the similarity judgments within the pre-
determined time window (2000ms, see Procedures). As a result, data from 69 participants were
subjected to the analyses.
Experiment 2
Experiment 1 demonstrated large effects (Cohen’s d > 0.743) for all the comparisons of
interest. However, because of the reduced number of trials per participant in Experiment 2, we
anticipated medium effect sizes (Cohen’s d = 0.5). Thus, we aimed to collect data from at least
44 participants to achieve the statistical power of 0.9 (p < 0.05, two-tailed), and we continued
recruitment on a weekly basis in return for course credits for Psychology courses until the
number of qualified participants reached our target sample size. As a result, 56 UTM students
(mean age = 19.5 years, SD = 2.8 years, 30% Male, 70% Female) participated. Data from three
participants were removed because they failed to achieve 75% accuracy on the similarity
judgments in the retrieval practice. As a result, data from 53 participants were subjected to the
analyses.
Stimuli and Apparatus
We created eight (4 ethnicities (African, European, East Asian, and South Asian) x 2
genders (Female and Male)) continuous face wheels using artificial faces generated by Facegen
Modeller (Singular Inversions Inc., 2009). The continuity of each face wheel was confirmed
empirically in a separate experiment (See supplementary information).
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 7
The experiment was conducted online using Inquisit Player 6 (millisecond, 2020)
downloaded and installed locally on each participant’s computer. Experimenters provided
instruction and monitored participants’ progress throughout the experiment using Zoom
conferencing (Zoom Video Communications, 2020).
Procedures
Experiment 1
After providing informed consent for the protocol approved by the University of Toronto
began with a presentation of a fixation cross at the centre of the screen. 500 ms later, a target
face (occupying 12% of the screen) was presented at the centre of the screen for 2000ms, and
participants were instructed to remember the face as precisely as possible. The target face was
sampled pseudo-randomly from the seed faces so that each seed face was presented four times
throughout the experiment. In two trials for each seed face, the target face presentation was
followed by a 3000ms maintenance interval (Baseline trials). The face wheel composed of the
target face and 23 faces (each occupying 0.48% of the screen) sampled equidistantly from the
corresponding race and gender group (radius = 40% of the height of the screen) was then
presented, and participants reported the target face by clicking on the face wheel. After selection,
the selected face was displayed at the centre of the screen with two arrows on the side.
Participants then used their mouse to click on the arrows to make fine adjustments to their
selection to obtain the exact face they remembered. Once participants found the exact face they
remembered, they indicated their confidence in the accuracy of their memory report by clicking
on one of the three buttons (i.e., ‘High’ for high confidence, ‘Low’ for low confidence, ‘No’ for
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 8
no confidence). The accuracy of the memory report was emphasized, and therefore, no time limit
was imposed on memory report.
Baseline Compare
Target Target
(2000ms+ (2000ms+
500 ms ISI) 500 ms ISI)
Delay Comparison
(2000ms + (2000ms +
500ms ISI) 500ms ISI)
24 AFC 24AFC
(Until resp. + (Until resp. +
500ms ISI) 500ms ISI)
Adjust + Adjust +
Confidence Confidence
(Until resp.) (Until resp.)
Name Encoding Retrieval Practice Final Recall Attribute Recall
Cued Cued
Target Recall Recall 2AFC
(1000ms) (1000ms) (1000ms) (Until Resp.)
Comparison 24AFC
2AFC (2000ms + (Until resp. + 2AFC
(Until Resp.) 500ms ISI) 500ms ISI) (Until Resp.)
24AFC Adjust +
Feedback 2AFC
(Until resp. + Confidence
(1500ms) (Until Resp.)
500ms ISI) (Until resp.)
Adjust +
2AFC
Confidence
(Until Resp.)
(Until resp.)
Panel A shows an example face wheel for East Asian male faces. Panel B shows the schematics for the
baseline and compare conditions in Experiment 1. Panel C shows the schematics for the name encoding task,
retrieval practice task, final recall task, and attribute recall task.
In the remaining two trials for each seed face (Compare trials), participants completed
one similarity judgment during the maintenance interval. 500 ms after the offset of the target
face, two face probes (each occupying 12% of the screen) sampled from the same face wheel as
the target face were presented on either side of the screen. One of the face probes was 45° away
from the target face (similar probe), while the other face probe was 180° away from the target
face (dissimilar probe). In one of two similarity judgment trials for each seed face, the similar
probe was sampled from the clockwise direction, and it was sampled from the counter-clockwise
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 9
direction in the other trial. Participants’ task was to select the similar face within 2000 ms in
order for a trial to be considered valid. The face probes remained on the computer screen for
2000 ms irrespective of the response time for the similarity judgment, after which the computer
screen remained blank for 500 ms. Subsequently, participants reported the target face with the
same procedure as the baseline trials. In total, participants performed four blocks of 32 trials (16
Baseline and 16 Compare trials).
Experiment 2
Face working memory task
Following the same informed consent procedure as in Experiment 1, participants first
schematics). Each trial began with a target face presented at the centre of the screen for 2000ms,
and participants were instructed to remember the face as precisely as possible. The target face
was pseudo-randomly sampled from four seed faces in the eight face wheels. The target face
presentation was followed by a 1000ms maintenance interval. The target face was then reported
using the same procedure as Experiment 1.
Profile encoding task
Next, participants learned the names and majors of eight target faces by performing the
name and major encoding tasks. Each target face was a seed face randomly chosen from each
3B), and participants clicked on the correct name associated with the face. Upon selection, the
correct name turned green for 1500 ms. The major encoding task was identical to the name
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 10
encoding task except that the target face appeared with two majors. Participants performed eight
blocks of each encoding task in a pseudo-random order. In each block, each target face was
presented twice in a pseudo-random order.
Retrieval practice task
Upon completion of the encoding tasks, participants performed the retrieval practice task.
In this task, participants were first presented with one of the cues associated with a target face
retrieve the associated target face and report their confidence in the accuracy of the retrieved
memory by clicking on one of the ‘High’, ‘Low’, and ‘No’ buttons. Following the confidence
report, participants were presented with similar and dissimilar faces (45° and 180° away from the
target face, respectively), and they were asked to click on the similar face. After the similarity
judgment, participants reported the target face using the same procedure as Experiment 1.
Importantly, for each target face, the cue used to trigger the retrieval (e.g., either name or
major) and the similar and dissimilar faces in the similarity judgments were randomly selected
for each participant, and they remained the same across all retrieval practice trials for the specific
target face. This ensured that one of the cues for each target face remained unused to trigger the
retrieval of the target face, and the direction of the SIMB induced for each target face was
consistent across all the retrieval practice trials.
Final recall task
Subsequently, participants completed the final recall task. This task was identical to the
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 11
judgments. Second, both practiced and unpracticed cues were used to trigger the memory
retrieval. Each target face was recalled twice using the practiced cue and twice using the
unpracticed cue in a pseudo-random order. In total, participants completed 32 trials in one block.
Attribute recall task
Finally, participants completed an attribute retrieval task to verify that they successfully
maintained the association between the face and the two cues. In this task, one cue (e.g., Lisa,
on one of the white alternatives that was associated with the green cue. Each of the cues in eight
learnt cue pairs served as the green cue in a pseudorandom order. Thus, participants completed
16 trials in one block.
Analysis
To measure the SIMB, we computed the signed response offset for each trial using the
following procedure. First, we computed the angular difference between the final memory report
and the target face on the face wheel. The direction of the signed response offset was then
determined so that the positive offset indicated response offset towards the similar face presented
in the similarity judgment. For the baseline condition, the direction of the response offset was
randomly assigned because no similar face was presented in the baseline condition. The signed
response offsets were then averaged across all trials for each condition.
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 12
Results
Experiment1: Face working memory report is distorted by a perceptual comparison toward a
similar input.
First, we examined whether a VWM representation of a perceptually encoded face can be
for the baseline condition clustered tightly around 0°, suggesting that participants maintained an
accurate representation of a target face in their VWM. This was further collaborated by their
near-ceiling accuracy for the perceptual comparison task (mean Accuracy = 0.95%, S.D. =
0.053%). More importantly, the distribution of the signed response offsets was shifted in the
direction of the similar probe. Consistent with this observation, the mean bias magnitude for the
Cohen’s d = 0.99, 95% CI [6.67° 10.96°]), indicating that a report for a face working memory
representation was biased by a perceptual comparison in the direction of a similar face. All the
results were replicated when we restricted the analyses to high-confidence reports (see
Supplementary Information).
Experiment 2: Face long-term memory report is distorted by a perceptual comparison toward a
similar face.
Next, we examined whether the VLTM report of a face retrieved via an associative cue
can be biased by a perceptual comparison. To ensure that participants successfully formed an
association for each face with corresponding cues (i.e., name and major), we found that encoding
performance monotonically increased throughout the blocks and reached a ceiling (mean
accuracy: 0.49, 0.80, 0.93, 0.97, 0.97, 0.97, 0.99 and 0.99, for blocks 1-8, respectively for the
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 13
name task; mean accuracy: 0.55, 0.88, 0.95, 0.97, 0.97, 0.97, 0.99 and 0.99, for blocks 1-8,
respectively for the major task), suggesting that participants successfully formed the association
prior to the retrieval practice task. Furthermore, the ceiling-level comparison accuracy (mean
accuracy: 0.95) during the retrieval practice task and the attribute recall accuracy (mean
accuracy: 1.00) confirm that participants successfully maintained the associated cues and used
them to retrieve face memories.
practice condition (red line) was shifted in the direction of the similar probe. Corroborating this
Baseline
Compare
Panel A shows the distribution of signed response offsets for Experiment 1. The dotted lines represent the
within-subject standard error of the means. Panel B shows the violin plot for the bias magnitude. The black
line indicates the mean bias magnitude. Panel C shows the distribution of signed response offsets for
Experiment 2. The dotted lines represent the within-subject standard error of the means. Panel D shows the
violin plots for the bias magnitudes. The black line indicates the mean bias magnitude for each condition.
noitroporP
esnopseR
Similar Probe (45º)
0.2
0.1
-180 -90 0 90 180
)º(
edutingaM
saiB
CH
-30
-60
Similar Probe (45º)
Signed Response Offset (º)
noitroporP
esnopseR
VWM
Retrieval practice
Final Recall (practiced)
0.2 Final Recall (unpracticed)
0.1
-180 -90 0 90 180
)º(
edutingaM
saiB
CH
-45
-90
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 14
2d, t(52) = 7.46, p < 0.001, Cohen’s d = 1.02, 95% CI [13.86° 24.07°]), indicating that a report
for a face working memory representation retrieved via an associative cue was biased by a
perceptual comparison in the direction of a similar face. All the results were replicated when we
restricted the analyses to high-confidence reports (see Supplementary Information).
Experiment 2: The SIMB for face memories generalizes across time and retrieval cues.
Lastly, we tested whether the similarity-induced memory bias resulted in persisting
the signed response offset distributions for the practiced cue condition in the final recall task
(magenta line) were shifted in the direction of the similar probe. Corroborating this observation,
4.36, p < 0.001, Cohen’s d = 0.60, 95% CI [6.02° 16.29°]), indicating that the similarity-induced
memory bias (SIMB) persisted across time when the face memory was accessed again using the
same retrieval cue as the retrieval practice task.
cue condition in the final recall task (cyan line) were also shifted in the direction of the similar
probe. Corroborating this observation, the mean bias magnitude was significantly higher than
18.31°]), indicating that the SIMB generalized across retrieval cues that were learned separately.
All the results were replicated when we restricted the analyses to high-confidence reports (see
Supplementary Information).
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 15
Discussion
In two experiments, we demonstrated that SIMB occurred for memories of human faces
when they were perceptually encoded (Experiment 1) and when they were retrieved from VLTM
(Experiment 2). Although a past study demonstrated that face memory reports can be distorted
by a presentation of distractor faces (Mallett et al., 2020), our study is the first to report that face
memory reports can be systematically biased through a goal-driven usage of the face memories.
Additionally, our results suggest that retrieving VLTM into VWM restores the VLTM into a
malleable state and allows the memory to interact with new perceptual inputs. Furthermore, this
interaction resulted in lasting memory distortions (cf., memory reconsolidation; Hupbach et al.,
2007; Hupbach et al., 2009) where the memory distortions persisted in subsequent memory
retrievals even when they were triggered by a different associative retrieval cue that was learned
separately. These findings demonstrate the generalizability and robustness of the SIMB that are
fundamental in explaining a wide variety and ubiquity of memory distortions observed not only
in the lab settings but in real-world scenarios (e.g., eyewitness testimonies).
Our findings are not without limitations. Although our results demonstrated a robust shift
in memory reports, it does not necessarily indicate a verbatim shift of the original memory
representation because probabilistic confusion between the original memory representation and
its similar comparator can also produce a similar shift in memory reports (Fukuda et al., 2022).
Indeed, our recent work applied computational modeling on continuous memory report data and
demonstrated both mechanisms can underlie systematic shifts in memory reports with more
simplistic stimuli (e.g., color and shape; Saito, Bae, et al., 2023). More precisely, when
participants perceive subjective similarity between the original memory representation and the
new perceptual input, the shift in memory reports is better explained by the shift of the original
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 16
memory representation. However, when participants perceive “sameness” between them, the
shift in memory reports is better accounted for by the probabilistic confusion between the two.
Since our current data do not allow the adoption of the same approach due to mechanical
constraints (e.g., limited number of trials and less granularity in memory responses), future
studies should examine whether the SIMB reported with multi-dimensional stimuli are better
explained by representational shit or probabilistic confusion.
Although we have demonstrated the SIMB across a wide range of visual stimuli, our
working memory can represent information across all sensory modalities (e.g., auditory and
tactile sensations) to guide our behaviours. Thus, future studies should examine whether the
SIMB occurs with WM representations for other sensory modalities. Given that our everyday
memories are multi-dimensional in nature, such studies would be critical in providing a unified
account of episodic memory distortion and characterizing its real-world implications.
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 17
Reference:
Cowan, N. (2001). The magical number 4 in short-term memory: a reconsideration of mental
storage capacity. Behav Brain Sci, 24(1), 87-114; discussion 114-185.
Draschkow, D., Kallmayer, M., & Nobre, A. C. (2021). When Natural Behavior Engages
Working Memory. Curr Biol, 31(4), 869-874.e865.
Fukuda, K., Pereira, A. E., Saito, J. M., Tang, T. Y., Tsubomi, H., & Bae, G. Y. (2022). Working
Memory Content Is Distorted by Its Use in Perceptual Comparisons. Psychol Sci,
Fukuda, K., & Woodman, G. F. (2017). Visual working memory buffers information retrieved
from visual long-term memory. Proc Natl Acad Sci U S A, 114(20), 5306-5311.
Godden, D. R., & Baddeley, A. D. (1975). Context-dependent memory in two natural
environments: On land and underwater. British Journal of Psychology, 66, 325-331.
Hout, M. C., Goldinger, S. D., & Brady, K. J. (2014). MM-MDS: a multidimensional scaling
database with similarity ratings for 240 object categories from the Massive Memory
picture database. PLoS One, 9(11), e112644.
Hupbach, A., Gomez, R., Hardt, O., & Nadel, L. (2007). Reconsolidation of episodic memories:
a subtle reminder triggers integration of new information. Learn Mem, 14(1-2), 47-53.
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 18
Hupbach, A., Gomez, R., & Nadel, L. (2009). Episodic memory reconsolidation: updating or
Hupbach, A., Hardt, O., Gomez, R., & Nadel, L. (2008). The dynamics of memory: context-
Luck, S. J., & Vogel, E. K. (2013). Visual working memory capacity: from psychophysics and
neurobiology to individual differences. Trends Cogn Sci, 17(8), 391-400.
Mallett, R., Mummaneni, A., & Lewis-Peacock, J. A. (2020). Distraction biases working
019-01707-5
Saito, J. M., Bae, G. Y., & Fukuda, K. (2023). Judgments during perceptual comparisons predict
distinct forms of memory updating. J Exp Psychol Gen.
Saito, J. M., Duncan, K., & Fukuda, K. (2023). Comparing visual memories to similar visual
inputs risks lasting memory distortion. J Exp Psychol Gen.
Saito, J. M., Kolisnyk, M., & Fukuda, K. (2022). Perceptual comparisons modulate memory
022-02133-w
Tulving, E., & Thomson, D. M. (1973). Encoding specificity and retrieval processes in episodic
memory. Psychological Review, 80(5), 352-373.
SIMILARITY-INDUCED MEMORY BIAS FOR FACES 19
Valentine, T. (1991). A unified account of the effects of distinctiveness, inversion, and race in
face recognition. Q J Exp Psychol A, 43(2), 161-204.