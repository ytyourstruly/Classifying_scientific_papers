1 Variability and accessibility of information guide gaze dynamics in decision-making
1,5 3 4 1,2 1,2
3 Douglas G. Lee , Konstantinos Tsetsos , Giovanni Pezzulo , Nitzan Shahar , Marius Usher
4 Tel Aviv University, School of Psychological Sciences
5 Tel Aviv University, Sagol School of Neuroscience
6 University of Bristol, School of Psychological Science
7 National Research Council of Italy, Institute of Cognitive Sciences and Technologies
8 University College Dublin, School of Electrical and Electronic Engineering
13 Email for correspondence:
14 DouglasGLee@gmail.com
Lee, Tsetsos, Pezzulo, Shahar, & Usher 2
15 Abstract
16 Experimental research in decision-making often relies on tasks that provide participants with all
17 the information they need to make their decisions. Here we consider the process by which decision-
18 makers seek information about their choice alternatives when it is not immediately provided.
19 Recent advances in computational theories have proposed that people will seek to process more
20 information about options for which they are less certain about the value. Specifically, they will
21 allocate more attention to options with lower certainty in order to increase their certainty by
22 processing additional information. We tested this hypothesis with a behavioral and eye-tracking
23 experiment in which participants observed pairs of random streams of numerical stimuli and were
24 incentivized to report which streams were generated by the distributions with the greater means.
25 We induced uncertainty by manipulating the variance of the value distribution for each option. In
26 addition, we randomly replaced some of the stimuli with meaningless letters. This decreased the
27 accessibility of information about the options. The results show that people fixate more on options
28 with lower accessibility and to a lesser extent options with greater value. Interestingly, this pattern
29 changes across response time, with early fixations driven by variability and accessibility, and late
30 fixations driven by value and accessibility. Moreover, people were more likely to choose options
31 with greater accessibility, and they felt more confident about their choices when accessibility was
32 greater. This research could help illuminate the process of information seeking to reduce
33 uncertainty during choice deliberation.
35 Keywords: information seeking; process tracing; visual fixations
Lee, Tsetsos, Pezzulo, Shahar, & Usher 3
36 Introduction
37 There is a vast literature showing that people carry out decisions via a process of integration
38 to boundary. In binary, evidence-based decisions (such as perceptual, medical, or legal decisions),
39 the integrated variable corresponds to the likelihood ratio of the two hypotheses (given a sample
40 of information) . In preference-based decisions, the integrated variable corresponds to a difference
41 in the value estimates associated with each alternative. As both likelihood ratios (given a sample
42 of evidence) and value representations are noisy (Gold & Shadlen, 2001; Tajima et al., 2016), the
43 decision mechanism needs to integrate multiple samples across time to enhance the signal-to-noise
44 ratio. Integration to boundary is the most efficient algorithm for executing simple decisions,
45 achieving the fastest response time (RT) for a given accuracy level (Wald, 1945), and is also
46 supported by neural data (Gold & Shadlen, 2001). This decision mechanism accounts well for
47 behavioral data, including the speed-accuracy tradeoff (Bogacz et al., 2010; Schouten & Bekker,
48 1967; Wickelgren, 1977) and the shape of choice-RT distributions, and it has been formalized as
49 the drift-diffusion model (DDM; (Ratcliff, 1978; Ratcliff et al., 2016; Ratcliff & McKoon, 2008)).
50 The DDM is equivalent to normative Bayesian models for simple decisions (Bitzer et al., 2014;
51 Gold & Shadlen, 2001).
52 While there is much behavioral and neural data in both humans and animals supporting the
53 notion of information accumulation as a mechanism for generating choices, less is known
54 regarding the process of information acquisition itself. For example, when choosing among
55 multiple options (of anything from snacks to stocks), the decision maker often needs to gather
56 information about the individual options – separately and sequentially – by focusing attention
57 (often proxied by visual gaze in behavioral experimental data; (Armel et al., 2008a)) on one option
1 This can be extended to choices between more options (n>2), but we will focus on the simple (n=2) case here.
Lee, Tsetsos, Pezzulo, Shahar, & Usher 4
58 or the other. In turn, attention appears to modulate the choice mechanism as formalized in an
59 extension to the DDM known as the attentional DDM (aDDM; (Krajbich et al., 2010)). The aDDM
60 accounts for an important pattern often observed in choice data: people are more likely to choose
61 the option that they looked at longer, even after controlling for other variables such as the relative
62 option values (Armel et al., 2008a; Cavanagh et al., 2014; Eum et al., 2023; Fiedler & Glöckner,
63 2012; Glickman et al., 2019; Krajbich et al., 2010; Shimojo et al., 2003; Smith & Krajbich, 2018,
64 2019; Stewart et al., 2016).
65 The main question we wish to examine here is what guides the decision apparatus as it
66 seeks information relevant for making choices between pairs of options. Under the aDDM, the
67 gaze trajectory is considered to be exogenous to the decision process (Krajbich et al., 2010).
68 Recently, the gaze trajectory was proposed to be guided by the developing preference (e.g., as the
69 accumulation process begins to show a preference favoring one option, attention is more drawn to
70 that option, causing more information to be sampled from it; (Gluth et al., 2018)). Also, attention
71 has been proposed to be attracted towards individual samples with large numerical values (Tsetsos
72 et al., 2012) or towards samples of information that match the decision goal (Glickman et al., 2018;
73 Sepulveda et al., 2020). Moreover, previous studies have reported that extreme values tend to be
74 more memorable and to impact decisions to a greater degree (Ludvig et al., 2018). Another variable
75 that is likely to modulate the search for information is the uncertainty associated with the choice
76 alternatives. In decisions from experience, people seek more information about options that present
77 higher variability in the possible outcomes (Lejarraga et al., 2012). The strategy of seeking more
78 information for less certain options would be normative under the probabilistic approach to
79 reasoning, where decision-making behavior is driven by an understanding that the world is
80 inherently uncertain (Friston et al., 2015; Oaksford & Chater, 2001). The literature on curiosity
Lee, Tsetsos, Pezzulo, Shahar, & Usher 5
81 has shown that people seek information that reduces their uncertainty about the world in addition
82 to information that has a positive valence, although that literature investigates information seeking
83 that is non-instrumental to the current decision (see (van Lieshout et al., 2020) for a review).
84 Some recent theoretical studies have proposed that decision makers should aspire to tune
85 their information processing to maximize decision efficiency. For example, sampling more
86 information about an option for which one is already quite certain of its value would not yield
87 much benefit, as the value of information would be low (Howard, 1966). It would be much more
88 useful to instead sample information about an option for which the value estimate is less precise
89 (or more uncertain). This may be a dynamic process. As one observes more samples for an
90 uncertain option, one becomes more certain about it; at some point, the relative certainty about the
91 options might change direction, and it would then become more useful to start observing samples
92 for a different option. This idea has been formalized in recent computational modeling studies
93 (Callaway et al., 2021; Jang et al., 2021; Song et al., 2019) and is supported by evidence showing
94 that people can assess their feelings of value certainty about different options (De Martino et al.,
95 2013; Gwinn & Krajbich, 2020; Lee & Coricelli, 2020; Lee & Daunizeau, 2020, 2021; Lee &
96 Hare, 2023; Polanía et al., 2019) and should therefore be able to adjust their behavior as a function
97 of certainty. There is also some preliminary evidence that people indeed look more at options with
98 greater uncertainty (Cassey et al., 2013), but there is still more work to be done in terms of directly
99 demonstrating the links between value, certainty, and attention. Providing evidence in that
100 direction is a central aim of this study. To that end, we designed an experimental paradigm that
101 allows us to control (not only to measure) the temporal uncertainty of choice options as people
102 make decisions based on noisy fluctuating evidence, while we continuously monitor their gaze
103 trajectories.
Lee, Tsetsos, Pezzulo, Shahar, & Usher 6
104 Uncertainty makes decisions more difficult, but it is often reducible, in principle, by
105 considering more information. As a real-world example, consider a decision between stocks of
106 different companies that you are considering investing in. In this example, your initial uncertainty
107 about the average performance of a stock (e.g., based on your observation of its performance on a
108 single day) could be reduced by observing its performance over longer periods of time – you will
109 become more certain about the average daily return it generates when you observe its performance
110 on more days (Bhui & Jiao, 2023). Recent work has shown that people do incorporate this concept
111 of reduceable (or epistemic) uncertainty in their value estimations, and that they are aware of how
112 it can impede their accuracy (Olschewski & Scheibehenne, 2024). In this study, we examine a
113 classical source of decision uncertainty – value variability – as well as an additional source related
114 to a new variable that we introduce – information accessibility. We use the term accessibility to
115 refer to the availability of information to be processed about choice options, as well as the ease
116 with which the information can be processed. This could relate to stimulus characteristics such as
117 contrast or clarity for perceptual choices, or to the frequency or recency of previous experiences
118 with an option for memory-based choices. From this perspective, accessibility (or the lack thereof)
119 should affect uncertainty – when a portion of the observed samples of evidence are non-
120 informative, a decision maker will be less certain about the true average value than if all samples
121 were informative. Variability should similarly affect uncertainty – the more stochasticity in the
122 observed samples, the less certain a decision maker will be about the true average value.
123 With respect to the process by which decision makers select what to sample while deciding,
124 we think both sources of uncertainty outlined above might be significant factors. In brief, the
125 reduction of uncertainty that is purported to take place when attending to an option during a
126 decision should occur at a higher rate both when the observed samples are less variable and when
Lee, Tsetsos, Pezzulo, Shahar, & Usher 7
127 accessibility to meaningful samples is higher. Below, we first describe our experimental paradigm
128 and then outline our general predictions with respect to variability and accessibility.
129 Our experimental paradigm displays pairs of sequences of numerical values (on the left
130 and right sides of the computer screen). This could correspond to returns of pairs of stocks, for
131 example. The numbers are samples drawn from two overlapping Gaussian distributions, which
132 change from trial-to-trial but are fixed within each trial. Sometimes a numerical sample is replaced
133 by a meaningless pair of letters, which decreases the accessibility of the decision-relevant
134 information for the associated option. The samples for both options are simultaneously updated at
135 a rate of three times per second, and they continue to update until participants report their decision
137 1 for an illustration). Using this paradigm, we can orthogonally manipulate the option properties
138 (mean, variability, and accessibility) on each trial. The participants maintained control over where
139 they focused their gaze at any point in time while figuring out which option to choose (the direction
140 of which we monitored and recorded) as well as the time at which they terminated each decision.
141 Importantly, the small font size of the displayed samples along with the speed with which they
142 were updated ensured that participants would need to fixate on them in order to properly perceive
143 them. With this design, we were able to make a number of specific predictions (see below) and
144 validate them with the experimental data.
Lee, Tsetsos, Pezzulo, Shahar, & Usher 8
148 Predictions
149 Gaze fixations
150 We predict that people will spend more time (on average within each trial) looking at the
151 option with higher mean, higher variability, and lower accessibility. In general, people tend to look
152 more at an option when they think it is the best response to the task at hand (Armel et al., 2008b;
153 Cavanagh et al., 2014; Fiedler & Glöckner, 2012; Krajbich et al., 2010; Shimojo et al., 2003).
154 Previous theoretical work has also proposed that people should look more at uncertain options in
155 order to reduce that uncertainty by focusing their attention (Callaway et al., 2021; Jang et al., 2021;
156 Song et al., 2019). The more attention an option receives, the more information should be
157 processed about that option. With more information, the initial uncertainty should be reduced to a
158 greater extent than if the option had low uncertainty to begin with (Cassey et al., 2013). There is
159 also initial evidence that people look less at options that are highly accessible ((Gwinn & Krajbich,
160 2020); in that study, accessibility was operationalized in a very different way than in our
Lee, Tsetsos, Pezzulo, Shahar, & Usher 9
161 experiment – participants were asked whether or not they would be willing to consume individual
162 snack foods, and the RT with which they responded was taken as a measure of accessibility for the
163 option; RT was first regressed on rating extremity, and the residuals served as the measure of
164 accessibility). People should pay more attention to poorly accessible options simply because when
165 samples contain less information, more samples will need to be accumulated to achieve the same
166 amount of uncertainty reduction. This should impact where people allocate their attention, as it
167 might behoove them to look more at options with low accessibility in order to extract sufficient
168 information about them.
170 Choices
171 Our first set of behavioral predictions relates to value mean. We predict that choice
172 accuracy will be higher, RT will be lower, and confidence will be higher when the mean difference
173 between the options (often termed choice ease) is greater. This prediction is a critical one, as it
174 will simultaneously serve to demonstrate whether participants performed the task properly and
175 whether our main difficulty manipulation was successful. We also predict that RT will be lower
176 and confidence will be higher when the mean sum of the options is greater. Previous studies have
177 shown that people decide more quickly and with higher confidence when the total overall value
178 across choice options is higher (Frömer et al., 2019; Hunt et al., 2012; Lee & Hare, 2023; Polanía
179 et al., 2014; Smith & Krajbich, 2019). It has sometimes also been observed that choices are more
180 accurate when the value sum is greater (Shevlin et al., 2022), but we withhold from making a
181 prediction about this until more corroborating evidence is available.
182 Our second set of behavioral predictions relates to value variability. We predict that
183 accuracy will be lower, RT will be higher, and confidence will be lower when either the sum of
Lee, Tsetsos, Pezzulo, Shahar, & Usher 10
184 variability across options or the variability of the higher-valued option is greater. Feelings of
185 uncertainty that people have about the value of choice options under consideration have previously
186 been shown to influence choices. Specifically, decisions seem to be facilitated (i.e., they are more
187 accurate, faster, and more confident) when there is less uncertainty about the set of options (Gwinn
188 & Krajbich, 2020; Lee & Coricelli, 2020; Lee & Daunizeau, 2020, 2021; Lee & Hare, 2023).
189 Similar results were found when the higher-valued option was less uncertain relative to the lower-
190 valued option (Lee & Coricelli, 2020; Lee & Hare, 2023). We anticipate similar effects in our data.
191 Our third set of behavioral predictions relates to the key new variable that we examine in
192 this study: information accessibility. We predict that accuracy will be higher, RT will be lower,
193 and confidence will be higher when either the sum of accessibility across options or the
194 accessibility of the higher-valued option is greater. We expected accessibility to impact choice
195 behavior in a way similar to variability. The idea is that when information signals are less
196 accessible (here operationalized as a greater probability of meaningless letters being displayed
197 within the streams of numbers), a decision maker will be less certain about the value of the
198 corresponding option. Note that with our experimental design, lower accessibility would
199 necessarily result in longer RT if participants were to adopt a strategy of seeking comparable
200 amounts of information about all options before deciding. A prediction of longer RT for trials with
201 lower overall accessibility, therefore, is tantamount to predicting that participants will indeed adopt
202 such a strategy. Our predictions for how accessibility should relate to the various decision variables
203 align with the results from previous studies showing that choices between options that are more
204 easily accessible in memory result in faster response times (Fazio et al., 1992), that options that
205 are more accessible in memory are more likely to be chosen (Gwinn & Krajbich, 2020), and that
206 options that feel more familiar are both more likely to be chosen and chosen more quickly and
Lee, Tsetsos, Pezzulo, Shahar, & Usher 11
207 confidently (Lee, 2024). They also conceptually align with previous evidence showing that, in
208 general, people prefer options that are easier to process (Oppenheimer, 2008) or that processing
209 fluency magnifies the informational content of the stimuli (Hertwig et al., 2008; Landwehr &
210 Eckmann, 2020). Such factors might be analogous to one option having greater accessibility, hence
211 our anticipation of the potential impact of accessibility difference.
213 Methods
214 To test the theoretical predictions, we designed an experiment in which we orthogonally
215 manipulate mean, variability, and accessibility. We record gaze fixation patterns with an eye-
216 tracking setup. Our core analyses are based on mixed effects regression models.
218 Participants
219 A total of 50 people participated in the experiment (28 female; age: mean = 24 years, SD
220 = 5, range 19-45). All participants were recruited via Tel Aviv University Sona Systems, either
221 through the Department of Psychological Sciences or the Behavioral Lab at the Coller School of
222 Management. All were self-declared fluent English speakers. As compensation for approximately
223 one hour of time, each participant received either a payment of 40 shekels (approximately $11) or
224 course credit. Each participant also received up to 20 shekels as a bonus payment calculated
225 according to performance. The experimental procedure was approved by the Ethics Board of the
226 Department of Psychological Sciences at Tel Aviv University. All participants gave written
227 informed consent prior to commencing the experiment.
Lee, Tsetsos, Pezzulo, Shahar, & Usher 12
229 Materials
230 The stimuli used in this study were sequential numerical displays. Each option on each trial
231 consisted of a stream of two-digit numbers randomly generated from a Gaussian distribution with
232 a predetermined mean and standard deviation. Randomly interleaved within each stream were pairs
233 of English letters in the place of the numbers. The displays updated three times per second. We
234 independently manipulated three factors for each option on each trial: mean, variability, and
235 accessibility. The mean corresponded to the mean of the Gaussian distribution from which the
236 individually-displayed numbers were drawn. The variability corresponded to the standard
237 deviation of the distribution from which the numbers were drawn. The accessibility corresponded
238 to the probability that each display sample would be a number (rather than a pair of letters, which
239 were explained to be task-irrelevant distractors). We created pairs of options using a 2x2x2 design
240 for mean difference, variability difference, and accessibility difference (low vs high for each
241 variable). Specifically, we created each pair as follows. We set the value of one of the options
242 (randomly assigned to the left or right) to a random sample from a uniform (40,55) distribution.
243 We then set the value of the other option to the value of the first option plus either 4 (low mean
244 difference condition) or 8 (high mean difference condition). We set the variability of one of the
245 options (randomly assigned to the left or right) to 6 and the variability of the other option to either
246 8 (low variability difference condition) or 12 (high variability difference condition). We set the
247 accessibility of one of the options (randomly assigned to the left or right) to 90 and the accessibility
248 of the other option to either 80 (low accessibility difference condition) or 70 (high accessibility
249 difference condition). Crucially, we manipulated these three factors independently so that they
250 were orthogonal to each other, meaning that knowing something about the accessibility of one
251 option does not provide any information about the mean or variability of the other option on any
Lee, Tsetsos, Pezzulo, Shahar, & Usher 13
252 trial. Once all the choice pairs had been created, we shuffled them such that trials from the eight
253 conditions would appear in a random order across the experiment.
255 Procedure
256 Participants were asked to report which stream of numbers (the left or right option) they
257 believed came from the distribution with the greater mean. They were instructed to consider the
258 true generating means of the random processes, not the exact means of the specific samples they
259 observed. They were instructed to ignore the letters that sometimes appeared instead of numbers,
260 as there was no significance to them and they served only as distractors. All participants confirmed
261 that they understood the instructions and were able to successfully explain the task back to the
262 experimenter. Participants were informed that the experiment would consist of 200 trials, without
263 any time limits. They were informed that all trials were independent – they should respond only
264 according to the current trial without considering the previous trials. After every 40 trials,
265 participants were given the opportunity to take a self-paced break before continuing.
266 On each trial, a pair of options was presented on the computer monitor (one on the left side
267 of the screen at 25% of the width of the screen starting from the left, one on the right side at 75%
269 center, the fairly small font size (50 point), and the rapid rate of change rendered it impossible for
270 participants to see what was displayed on a given side of the screen unless they diverted their gaze
271 towards that side. This was confirmed by debriefing during pilot testing. At the top of the screen,
272 the question “Which sequence has the greater average?” was displayed. Trials were self-paced; the
273 displays continued to update until participants entered a response. Participants used the left and
274 right arrows on the computer keyboard to enter their choice of the left or right option, respectively.
Lee, Tsetsos, Pezzulo, Shahar, & Usher 14
275 After reporting their choice on each trial, the options disappeared, and a vertical slider scale for
276 choice confidence appeared at the center of the screen. Participants were asked, “How sure are you
277 about your choice?” They used the up and down arrow keys to move a cursor along the scale
278 anywhere from “Not at all!” (minimum confidence) to “Absolutely!” (maximum confidence).
279 They submitted their confidence rating by pressing the space bar. After reporting the confidence
280 on each trial, the scale disappeared, and participants received feedback about their performance on
281 that trial. Specifically, if they answered correctly on that trial, a green “+1” appeared at the center
282 of the screen; if they answered incorrectly, a red “-1” appeared. Thus, on each trial, participants
283 either gained or lost one point. At the end of the experiment, we converted the cumulative point
284 total to a monetary bonus payment at the rate of 10 points = 1 shekel. A participant who responded
285 correctly on all trials would therefore earn a bonus of 20 shekels; a participant who responded
286 randomly (or otherwise performed at or below chance level) would not earn any bonus. (No
287 participants earned negative points, but if they had, the amount of their bonus would have been
288 zero, not a reduction of their base payment).
290 Eye tracking
291 We recorded eye gaze fixation location (with a particular interest in the x-coordinates)
292 continuously throughout the experiment using a Tobii-Pro eye tracker. We set the sampling rate to
293 120 Hz. Each participant performed the default calibration task prior to commencing the
294 experiment. After collecting the data, we divided it into epochs for each trial (for each participant)
295 using the “trial onset” and “response” triggers that we included in our data collection script. We
296 averaged the x-coordinates for the left and right eyes and used that as our measure for the gaze
297 location. For any points in time where the eye tracker failed to record a signal (e.g., during blinks),
Lee, Tsetsos, Pezzulo, Shahar, & Usher 15
298 we interpolated from the surrounding signals. Specifically, for any contiguous gaps, we set the
299 values within those gaps equal to the average of the immediately preceding and subsequent values.
300 Finally, we classified gaze direction as being toward the left at any point in time if the x-coordinate
301 was somewhere less than 40% of the width of the screen and as being toward the right if the x-
302 coordinate was somewhere greater than 60% of the width of the screen. Whenever the x-coordinate
303 was somewhere between 40% and 60% of the width of the screen, we classified gaze direction as
304 being toward the center. In all relevant analyses reported below, we ignored gazes toward the
305 center and only considered gazes toward the left and right (i.e., toward the choice options).
307 Results
308 Before undertaking our main analyses, we first checked to see if any participants failed to
309 meet our performance threshold of 60% accuracy. We determined this threshold by calculating the
310 standard error of a binomial distribution of random choice (p = 0.5) and adding three times the
311 standard error to chance level. Two participants performed worse than this threshold, so we
312 excluded those participants from our analyses. We also excluded four additional participants
313 because their eye-tracking data did not record properly. All analyses reported below are therefore
314 based on the remaining 44 participants. We note that the behavioral results did not change when
315 we repeated the analyses without excluding the four participants with missing eye-tracking data,
316 but we decided to exclude them nonetheless for consistency with reporting the gaze-related results.
317 For each participant, we excluded from analysis all trials with outlier response times (RTs) –
318 defined as within-participant median log(RT) +/- three times the within participant median average
319 deviation of log(RT). For the model-free analyses reported below, all significance levels were
320 determined by two-sample t-tests. For the regression analyses, we used the fitlme function in
Lee, Tsetsos, Pezzulo, Shahar, & Usher 16
321 MATLAB. All regression analyses were based on mixed effects models with participants as
322 random effects (both intercepts and slopes). In each of our regression models, we replace all
323 predictor variables with their z-score transformations and keep the outcome variables in their
324 original form. By doing so, the resultant regression coefficients are semi-partial correlations
325 between the independent and dependent variables and can thus provide an objective indication of
326 effect sizes that is easy to interpret.
327 As a preliminary check for the general quality of our data, we performed a series of cross-
328 participant tests. First, we observed a clear speed-accuracy tradeoff across participants – those
330 metacognitive calibration (subjective confidence aligned well with objective accuracy) across
331 participants – those whose accuracy was higher had higher average confidence levels (r = 0.43;
333 according to a median split on confidence (within participant), high confidence trials corresponded
334 to accuracy levels significantly greater than those for low confidence trials (mean difference =
336 RT – when separating trials according to a median split on confidence (within participant), low
337 confidence trials corresponded to significantly greater RT than did high confidence trials (RT z-
Lee, Tsetsos, Pezzulo, Shahar, & Usher 17
341 represent individual participant averages. Error bars represent means +/- standard errors. *** p <
342 .001
344 For the remaining analyses, we computed what we call the observed input variables to use
345 instead of what we call the generative input variables. The generative (i.e., hypothetical or steady-
346 state) input simply refers to the trial-by-trial parameters that we established in our experimental
347 design: the mean and standard deviation of each Gaussian random number generator and the
348 probability that each display update would contain a number rather than a letter. The observed
349 input refers to parameters that summarize what the participants actually saw on each trial. Because
350 we designed the experiment such that participants would not likely be able to see the stimulus on
351 the right side of the screen while their gaze was focused toward the left (and vice versa), we decided
352 that it made the most sense for us to include as input data only the information from stimuli that
Lee, Tsetsos, Pezzulo, Shahar, & Usher 18
353 the participants explicitly gazed at. We were able to do this because on each trial, we recorded the
354 exact streams of numbers and letters that were displayed as well as the exact timing of when
355 participants were looking at the left or right options. We thus know exactly which sets of numbers
356 and letters participants observed for each option on each trial. Our observed input for each option
357 is the mean and standard deviation of these observed sets of numbers, and the percentage of
358 numbers contained within each set . From this point forward, when we refer to the mean,
359 variability, and accessibility variables, we refer to these observed input variables.
361 Dependency of gaze on decision variables
362 We wanted to test how the decision variables (mean, variability, and accessibility) might
363 affect gaze allocation across the full duration of each trial. We thus first calculated the percentage
364 of time within each trial that the gaze was to the left or to the right (or neither). We calculated the
365 percentage of time within a trial that the gaze was to the left minus the percentage to the right
366 (ignoring gazes toward the center) and labeled this variable as gaze percentage difference (dGaze).
367 We then regressed dGaze on differences in each of the decision variables (dMean, dVar, and
368 dAccess; all left minus right). All variables were z-scored across trials and participants before
369 entering the regression design matrix. We found that participants gazed more at the option (within
370 a choice pair) with the higher mean (regression coefficient = 0.05, p = .006) and less at the option
371 with higher accessibility (regression coefficient = -0.11, p < .001), in line with our predictions.
2 We also considered an alternative approach, in which the input variables were “accumulated”. Specifically, within
each gaze fixation, we weighted the contribution of each sample according to the amount of time that it was observed.
This basically meant that samples at the beginning and end of each fixation were given less weight than the other
samples. The results of all analyses reported below were qualitatively identical and quantitatively similar when using
these accumulated input variables.
Lee, Tsetsos, Pezzulo, Shahar, & Usher 19
372 However, we did not find our predicted effect of variability on gaze allocation (p = .821). Together,
376 coefficient estimates when regressing gaze percentage difference (left minus right) on differences
377 (all left minus right) in mean (dMean), variability (dVar), and accessibility (dAccess). Plot a shows
378 the effects at the full trial level. Plot b shows the effects for the first, second, third, and fourth
379 quarters of each trial (Q1-4; see legend for color code). The regressors within each time interval
380 are based on an accumulation of observed samples since trial onset. Error bars represent 95% C.I.
382 We thought it might be possible that the drivers of gaze allocation were dynamic in the
383 sense that they might develop across decision time. Specifically, the impact of each decision
384 variable on gaze might differ from the beginning to the end of each trial. The idea is that people
385 would look more at uncertain options at the beginning of the trial in order to gather more
386 information and increase their certainty about the mean estimates, whereas towards the end of the
387 trial, people might instead look more at the options for which their mean estimates were highest.
388 To test this, we divided the data into quarters based on time from stimulus onset until eventual
389 response (within each trial for each participant). We regressed dGaze during the first quarter of
390 each trial on the same regressors as before (dMean, dVar, dAccess) except now calculated using
Lee, Tsetsos, Pezzulo, Shahar, & Usher 20
391 only the samples that the participants observed during the first quarter of each trial. We then
392 regressed dGaze during the second, third, and fourth quarters of each trial (Q1-4) on dMean, dVar,
393 and dAccess, now calculated according to all samples that participants observed through that time
394 interval (i.e., Q2 included samples from Q1-2, Q3 included samples from Q1-3, Q4 included
395 samples from Q1-4). This is because during each quarter of a trial, participants would retain the
396 information that they had acquired during the previous quarters of that trial. The values of dGaze
397 for each quarter were calculated in a similar manner. All variables were z-scored across trials and
398 participants before entering the regression design matrix. We found that at the beginning of trials,
399 participants did indeed gaze more at more uncertain options (regression coefficient = 0.17, p <
400 .001). They also gazed less at more accessible options (regression coefficient = -0.09, p < .001).
401 We did not find a significant effect of mean on early gaze fixations (p = .189). The pattern was
402 different at the end of trials. Now, mean did have a significant impact on gaze allocation, with
403 participants looking more at the higher-valued option (regression coefficient = 0.05, p = .007) as
404 well as the lower-accessibility option (regression coefficient = -0.10, p < .001). We did not find a
405 significant effect of variability on where participants looked towards the end of each trial (p =
406 .974). This differentiation between early and late effects seems to have arisen across time, as
408 gradual increase in weight for mean was only a trend, but the decrease in weight for variability
409 was statistically robust for every time bin (see Supplementary Material).
410 Finally, we tested whether the duration of fixations changed across time (within trials). We
411 found that the duration gradually decreased, with early fixations lasting longer and later fixations
413 assuming that early fixations need to endure longer to enable the decision maker to establish the
Lee, Tsetsos, Pezzulo, Shahar, & Usher 21
414 "context" (e.g., which option has greater variability or information accessibility) for the current
415 decision.
418 duration than later fixations.
420 Are the observed gaze patterns normative?
421 From a normative perspective, as participants refine the precision of their mean estimates,
422 they should sample more when the samples they observe are either less accessible or more variable.
423 We tested for such normative behavior by examining the streams of samples that participants
424 observed. First, we counted the observed meaningful samples (i.e., numbers rather than letters) for
425 each option on each trial for each participant. We then calculated the mean of the count of
426 meaningful samples for each participant (across trials and options), separately for low and high
427 accessibility options (median split within participant). We found that there was no significant
428 difference between the low and high accessibility options (low = 13.22, high = 13.87, difference p
429 = .154). This suggests that participants used a similar sampling strategy for options with low or
430 high accessibility, after accounting for the meaningless samples. We then tested for correlations
431 between accessibility and number of meaningful samples (within participant). Across participants,
Lee, Tsetsos, Pezzulo, Shahar, & Usher 22
432 we found a significant average correlation (0.05, p = .018). This qualitatively differs from the
433 average correlation between accessibility and number of total samples (-0.06, p < .001). This
434 demonstrates that participants appropriately observed more total samples for options with lower
435 accessibility, but that they might not have fully compensated for lower accessibility by observing
436 enough additional samples (possibly due to an increasing cost of sampling or an urgency signal
437 encouraging a response).
438 We repeated the above analyses with respect to variance instead of accessibility. We did
439 not find a significant difference between the low and high variability options (low = 13.36, high =
440 13.39, difference p = .823). This suggests that participants used a similar sampling strategy for
441 options with low or high variability, after accounting for the meaningless samples. We then tested
442 for correlations between variability and number of meaningful samples (within participant).
443 Across participants, we did not find a significant average correlation (0.02, p = .105).
444 The theoretical benefit of observing more samples when estimating the mean of a
445 distribution would be to reduce the standard error of the mean estimate (SEM). We thus tested
446 whether participants seemed to sample in a manner that might best achieve this goal. For each
447 option for each trial for each participant, we traced the evolution of the SEM across the observed
448 samples. Then, for each trial, we recorded both the final SEM of each option at the time of the
449 response and the maximum SEM for each option over the course of the trial. We then divided
450 individual options based on accessibility (median split within participant) and pooled the options
451 across participants. We found that there was no difference in either the max SEM (low mean =
452 5.68, high mean = 5.64, difference p = .362) or the last SEM (low mean = 2.59, high mean = 2.52,
453 difference p = .069) between low and high accessibility trials. We performed a similar test based
454 on low versus high variability options and found a significant difference in max SEM (as expected;
Lee, Tsetsos, Pezzulo, Shahar, & Usher 23
455 low mean = 5.17, high mean = 6.12, difference p < .001) as well as in last SEM (low mean = 2.36,
456 high mean = 2.75, difference p < .001). The difference in last SEM, however, was much smaller
457 than the difference in max SEM (-0.39 versus -0.95, p < .001). Together, this suggests that
458 participants considered the accessibility and to a lesser extent the variability of observed samples
459 when determining how long to continue sampling, perhaps with the notion of achieving a target
460 level of SEM for each option before deciding.
462 Relationships between decision variables and choice behavior
463 We then examined choice behavior (accuracy, RT, and confidence) to test our predictions.
464 We tested for effects of all our independent decision variables – mean sum (sMean), mean
465 difference (dMean), variability sum (sVar), variability difference (dVar), accessibility sum
466 (sAccess), and accessibility difference (dAccess) – on each of our dependent variables separately.
467 Recall that all independent variables were calculated based only on the samples (numbers and
468 letters) that the participants actually observed for each option on each trial. All the difference terms
469 were calculated based on the higher-mean-valued option minus the lower-mean-valued option. In
470 this way, the correlations that would have otherwise existed between sVar and dVar and between
471 sAccess and dAccess are nullified (see Supplementary Material). Accuracy is based on the greater
472 true generative mean for each trial, which is what participants knew they had to report. To test for
473 potential effects when examining all independent variables simultaneously, we conducted a series
474 of mixed effects regression analyses. The fixed effects regressors in each model were the
475 independent variables listed above. All variables were z-scored across trials and participants before
476 entering the regression design matrix. The models included a logistic regression of accuracy and
477 linear regressions of log(RT) and confidence.
Lee, Tsetsos, Pezzulo, Shahar, & Usher 24
478 As expected, there was a strong effect of mean difference on all three behavioral variables
479 (regression coefficients: accuracy: = 0.11, p < .001; RT = -0.16, p < .001; confidence = 0.06, p <
480 .001). Consistent with previous findings, there was a significant effect of mean sum on RT
481 (regression coefficient = -0.03, p = .003) and confidence (regression coefficient = 0.02, p < .001),
482 but not on accuracy (p = .515). Consistent with previous findings, there was an effect of variability
483 sum on all three behavioral variables (regression coefficients: accuracy = -0.02, p < .001; RT =
484 0.02, p = .029; confidence = -0.01, p = .001). There was a significant effect of variability difference
485 on all three behavioral variables, but the pattern of results was the opposite of what has previously
486 been reported (regression coefficients: accuracy = 0.03, p < .001; RT = -0.02, p = .005; confidence
487 = 0.01, p = .004). As we predicted, there was a significant effect of accessibility sum on RT
488 (regression coefficient = -0.07, p < .001), but we did not find our predicted effect of accessibility
489 sum on accuracy or confidence (p = .186 and p = .153, respectively). As we predicted, there was
490 a significant effect of accessibility difference on accuracy (regression coefficient = 0.02, p < .001)
491 and confidence (regression coefficient = 0.01, p < .001), but we did not find our predicted effect
492 of accessibility difference on RT (p = .961). Together, our regressors accounted for 13%, 60%,
496 estimates when regressing accuracy (plot a), log(RT) (plot b), and confidence (plot c) on mean
Lee, Tsetsos, Pezzulo, Shahar, & Usher 25
497 sum (sMean), mean difference (dMean), variability sum (sVar), variability difference (dVar),
498 accessibility sum (sAccess), and accessibility difference (dAccess). Error bars represent 95% C.I.
500 Next, we examined the eye-tracking data to test for associations between gaze and choice,
501 while accounting for the primary explanatory variables analyzed above. First, we ran a logistic
502 regression of choice (probability of choosing the left option) on the differences (left minus right)
503 of mean, variability, accessibility, and gaze percentage (i.e., the percentage of time within a trial
504 that the gaze fixation was to the left minus the percentage to the right). All fixed effects coefficients
505 were positive and significant (mean difference = 1.90, variability difference = 0.23, accessibility
507 true for the coefficient reflecting the relationship between gaze and choice (beyond the effects of
508 mean, variability, and accessibility), which replicates previous findings (Gwinn & Krajbich, 2020).
509 Interestingly, but in line with the results reported above, the coefficient for variability difference
510 shows that people were more likely to choose the option associated with greater variability, which
511 is counter to previous findings as well as our prediction. We also note that the intercept term was
512 positive and significant (0.50, p < .001), indicating that participants tended to prefer the option on
513 the left. Together, our regressors accounted for 58% of the variance in choice probability.
Lee, Tsetsos, Pezzulo, Shahar, & Usher 26
516 when regressing choice (probability of choosing the left option) on differences (all left minus right)
517 in mean (dMean), variability (dVar), accessibility (dAccess), and gaze percentage (dGaze). b)
518 Fixed effects coefficient estimates when regressing choice on dMean, dVar, and the difference in
519 the product of accessibility and gaze proportion (d(Acc*Gaze)). Error bars represent 95% C.I.
521 Gaze time and accessibility rate both represent different aspects of a similar phenomenon:
522 accumulating information. The number of total samples observed is determined by gaze time, and
523 the percentage of those samples that are informative is determined by accessibility rate. Together,
524 this means that the combination of the two (gaze*accessibility) represents the number of
525 informative samples observed for an option. To validate our hypothesis that gaze and accessibility
526 were two parts of a unified variable, we repeated the regression of choice this time replacing
527 dAccess and dGaze with d(Acc*Gaze). The results were very similar (regression coefficient for
529 identical to that of the more complex model (both r = 0.58), suggesting that information sampling
530 rate is the critical element whether controlled by the experimenter (via accessibility) or the
531 participant (via gaze fixation). We repeated the regression again this time replacing dAccess and
532 dGaze with dN, where dN was the difference (left minus right) in the total count of numerical
533 samples observed for each option within a trial. Again, the results were very similar (regression
534 coefficient for dN = 0.41, p < .001; r = 0.57).
535 A correlation matrix of the main decision variables, a summary of the correlations between
536 generative parameters and observed parameters, and a histogram of gaze fixation locations are
537 provided in the Supplementary Material.
Lee, Tsetsos, Pezzulo, Shahar, & Usher 27
539 Discussion
540 In this study, we examined the drivers of gaze fixation patterns across decision time in a
541 two-alternative forced choice paradigm. Specifically, we sought to validate recent theoretical
542 claims that fixations should be directed more towards choice options whose values are more
543 uncertain. Attention to a specific option is thought to trigger additional information processing
544 about that option, which in turn should help reduce the uncertainty about its value. Fixations should
545 thus be directed towards options with higher variability in noisy evidence about their true value.
546 For similar reasons, fixations should be directed towards options with lower information
547 accessibility. The beneficial information processing that attention can enable will be reduced when
548 the accessibility of information about an option is lower, meaning that people would have to
549 maintain their gaze fixation longer on that option in order to extract information about it. Our data
550 only partially validated these hypotheses. At the full-trial level, relative gaze dwell time favored
551 options whose observed stimulus samples were less accessible (i.e., more of the samples were
552 meaningless letters), but not those whose samples were more variable (i.e., the standard deviation
553 of the observed numerical values was greater).
554 The former is consistent with the idea that the purpose of a gaze fixation is to allocate
555 attention to an option with the intention of extracting information about it. Non-numeric samples
556 directly reduce the information content in a given stream. Once people shift their gaze towards an
557 option, the informativeness of the samples that they obtain might determine how long they linger
558 before shifting their attention towards the other option. It thus seems that people might behave at
559 least somewhat normatively when deciding how long to fixate on each option, at least with respect
560 to information accessibility. It could be that the goal is to extract a specific amount of information
Lee, Tsetsos, Pezzulo, Shahar, & Usher 28
561 about each option and to respond when a pre-defined certainty criterion has been achieved for one
562 estimate being greater than the other. Our findings related to the final standard errors of the mean
563 estimates on each trial – irrespective of accessibility – support this idea. Future studies are needed
564 to identify the putative normative criterion to terminate a fixation, which should depend on
565 participant-specific parameters for how costly accumulating evidence is and how beneficial
566 increased certainty is (Fudenberg et al., 2018; Lee & Daunizeau, 2021; Tajima et al., 2016).
567 Our participants seemed to pay more attention to highly variable streams of numerical
568 samples at the beginning of each trial. However, as noted above, it seems that they did not pay
569 more attention to highly variable streams of numerical samples across the full duration of a trial.
570 This might make sense if gaze fixations serve to enable information gathering. People may
571 accumulate information across fixations rather than within them, in which case they may simply
572 observe a series of samples for each option before switching their attention back to the other option
573 – hence, at the whole-trial level, they would have no need to look more at the option with greater
574 variability.
575 With respect to value, people should seek information about both options (at least at the
576 beginning of each trial). The purpose of a fixation might thus be to extract information regardless
577 of its content, because developing a sense of the average value of an option would benefit from
578 obtaining both high- and low-valued samples. However, after multiple fixations to each option,
579 people may start to form a belief about which is more valuable, and they will respond when this
580 belief becomes strong enough. By the end of the trial, people will start to look more at the option
581 that they are preparing to choose. This could explain our finding that our participants fixated more
582 on the option with the higher mean across the full trial – and especially late in the trial.
Lee, Tsetsos, Pezzulo, Shahar, & Usher 29
583 According to our interpretation of the gaze allocation results discussed above, we expected
584 a different pattern early in the trial that would gradually transform into the full-trial pattern as
585 information accumulated across the trial. Indeed, this is what we found. Specifically, we found
586 that our participants did not pay more attention to more valuable options at the beginning of the
587 trial, but that a bias in attention gradually increased with longer time epochs. We also found that
588 our participants paid more attention to the more variable options at the beginning of the trial, and
589 that this bias in attention gradually disappeared when considering increasing time epochs. With
590 respect to accessibility, we found that our participants paid more attention to options with lower
591 accessibility, both early on and across the whole trial. This is interesting because it distinguishes
592 the detriment to mean estimation caused by variability from that caused by accessibility. When
593 people seek more information by initiating an additional fixation, the presence of distractor
594 samples never provides any information. In that case, people may maintain their fixations longer
595 as they wait for the information that they continue to seek. This explanation for the dynamic pattern
596 of these results also aligns with our finding that early fixations endured longer than later fixations.
597 It could be that at the beginning of each trial, uncertainty is maximal, so more samples are needed
598 when the variability of the samples is high. Later in the trial, samples obtained from additional
599 fixations might simply be accumulated together with earlier samples to fine-tune the emerging
600 value representations. In that case, fewer samples (i.e., shorter fixations) would be needed to revise
601 a value representation (later in the trial) than to establish it in the first place (early in the trial). This
602 speculative interpretation of our findings remains to be fully tested in future studies.
603 Previous studies have reported a “gaze bias” in which people choose options that they
604 viewed for longer, even after controlling for value difference. This has been shown in preferential
605 choice (Gluth et al., 2020; Sepulveda et al., 2020; Smith & Krajbich, 2019), risky choice (Fiedler
Lee, Tsetsos, Pezzulo, Shahar, & Usher 30
606 & Glöckner, 2012; Smith & Krajbich, 2018; Stewart et al., 2016), and even perceptual choice
607 (Tavares et al., 2017). We show that this effect also holds in the domain of numerical averaging.
608 This is intriguing since there was no subjective component to our task – participants simply had to
609 form rough latent estimations of the means of the two numerical streams and report which one was
610 greater. Our finding aligns with the interpretation that attention magnifies information that aligns
611 with any decision goal (Sepulveda et al., 2020).
612 Although previous studies have interpreted the observed effect of gaze on choice as a bias,
613 this is not the only possible interpretation. It could be that looking longer at an option is tantamount
614 to collecting more information samples about that option, in which case the subjective precision
615 about the value estimate of that option would be greater than for the other option. Since people
616 prefer options for which their subjective precision or certainty is greater (Frömer et al., 2022; Lee
617 & Coricelli, 2020), this could be a simple explanation for the “gaze bias”. In our experimental
618 paradigm, gazing longer at an option is synonymous with observing more samples about it, holding
619 constant the accessibility rate. For any option, the relative gaze time multiplied by the relative
620 accessibility rate directly computes the relative number of informative samples about that option.
621 We validated this logic by showing that a regression of choice that included the difference in
622 accessibility*gaze provided results indistinguishable from those of a model including the
623 difference in accessibility and the difference in gaze proportion as independent regressors.
624 Furthermore, a model that replaced accessibility and gaze with a direct count of numerical samples
625 (left option minus right option) was also nearly indistinguishable.
626 With our behavioral results, we demonstrated the importance of information accessibility
627 and its influence on choice: accuracy, response time (RT), and confidence. We found that choices
628 are significantly faster when there is greater overall accessibility across the options. This makes
Lee, Tsetsos, Pezzulo, Shahar, & Usher 31
629 sense, because it means that the same amount of information can be gained sooner as the potential
630 rate of information processing is higher. This increase in speed was not matched with an increase
631 in confidence, as is usually the case. Perhaps this is because people often use the speed with which
632 they could determine their response as an indicator of the likelihood that they were correct, whereas
633 in this case, this correspondence is polluted by the inclusion of distractors. Simply put, people
634 might realize they are slower when accessibility is lower not because the trial is more difficult, but
635 simply because they have to wait longer to ignore the distracting letters. We also found that our
636 participants were more accurate and more confident when the correct option had greater
637 accessibility than the incorrect option. This could be due to the apparent preference that they had
638 for choosing the option with greater accessibility (and thus they would be more accurate when that
639 option was the correct one).
640 The preference that our participants showed for options with high accessibility – on top of
641 their preference for high mean – is intriguing. Perhaps when accessibility is low in our task, the
642 presence of many distractor letters makes mean estimates less precise, and this lack of precision
643 deters participants. Future work could test this hypothesis by requiring participants to report mean
644 estimates and confidence levels for individual options with different accessibility levels. A
645 tendency to prefer high accessibility options could also be indicative of a leaky accumulation
646 process while people are developing a value estimate from incoming input signals (Usher &
647 McClelland, 2001). The latent mean estimates that participants form during our task could be
648 updated optimally (e.g., in a Bayesian manner) with each new numerical sample that they observe.
649 But, when they observe letters rather than numbers, their value representations might decay
650 towards their (flat) priors. Future work should investigate this issue further, possibly by varying
651 the length of time between stimulus updates and/or the presence of distractors versus empty space.
Lee, Tsetsos, Pezzulo, Shahar, & Usher 32
652 Our behavioral results replicate many previous findings, including the unsurprising result
653 that high mean difference corresponds to higher accuracy, faster RT, and higher confidence. We
654 also replicated the intuitive result that the sum of variability in information about a pair of options
655 corresponds to lower accuracy, slower RT, and lower confidence (Lee & Coricelli, 2020; Lee &
656 Daunizeau, 2021; Lee & Hare, 2023). Interestingly, we also replicated the finding that the sum of
657 values across options corresponds to faster RT and higher confidence. This has been show in
658 preferential choice (Frömer et al., 2019; Lee & Hare, 2023; Smith & Krajbich, 2019), risky choice
659 (Hunt et al., 2012), and even perceptual choice (Polanía et al., 2014). We show that this effect also
660 holds in the domain of numerical estimation. This might suggest that individual samples with large
661 numerical values are inherently salient, causing them to be processed faster because they receive
662 more attentional resources. Or it might simply be that “large” stimuli contain more information,
663 regardless of the form that the information takes. The idea would be that neural activity in response
664 to the query, “How large is this (in whatever relevant dimension)?” would be greater for larger-
665 valued samples and thus allow the response to be formed more quickly.
666 Perhaps the most unexpected of our behavioral results was the apparent preference that
668 more accurate, faster, and more confident on trials where the correct option displayed more sample
669 variance than the incorrect option. This is the opposite of what has been reported in preferential
670 choice, where people favor options for which they feel more certain about the values (Frömer et
671 al., 2022; Lee & Coricelli, 2020; Lee & Daunizeau, 2021; Lee & Hare, 2023). It is also opposite
672 to the very concepts of ambiguity aversion (Ellsberg, 1961) and risk aversion (Pratt, 1964).
673 However, it is in line with the tenets of Selective Integration (SI) Theory (Glickman et al., 2018;
674 Tsetsos et al., 2012; Usher et al., 2019). According to that line of work, when participants must
Lee, Tsetsos, Pezzulo, Shahar, & Usher 33
675 choose between a pair of numerical streams (as in our experiment), they are biased in favor of the
676 option whose samples are generated by the distribution with the greater variance. The theory
677 explains this phenomenon by proposing an increase in the relative weighting of the sample draw
678 (left or right) that is greater in numerical magnitude at any point in time. The option with the
679 greater variance will have more numerically high sample draws, which will receive an increased
680 weighting. The same option will also have more numerically low sample draws, but those will
681 effectively be ignored because attention will be directed toward the other option during those time
682 epochs. The net effect is that the comparison of mean estimates ends up being biased in favor of
683 the high-variance option. A key difference between the designs in the SI studies and ours relates
684 to the ability to view both streams of numbers simultaneously. In those previous studies, the stimuli
685 displays were positioned close together on the computer screen, intentionally allowing participants
686 to view everything at the same time. In our study, we intentionally positioned the stimuli displays
687 far apart on the computer screen because we wanted to be sure that participants could only observe
688 one option at a time by directing their gaze towards one side of the screen. Therefore, we cannot
689 directly apply the SI theory (as it has previously been described) to our current work. However, it
690 is possible that the fundamental principles of the theory nevertheless apply. If numerically larger
691 samples are more salient than numerically smaller samples, this would trigger a larger automatic
692 arousal when larger numbers are displayed. The increase in attention caused by the arousal would
693 in turn give those samples a greater weight as they are combined with other samples to form an
694 estimate of the mean. The end result would be that people would overestimate the means for
695 streams of numbers with high variance relative to low. If true, this would explain the preference
696 for options with greater variability that we observed in our data. Preliminary (unpublished)
697 evidence from our team supports this – in a task where participants had to estimate the means of
Lee, Tsetsos, Pezzulo, Shahar, & Usher 34
698 solitary streams of numbers, there was an average overestimation and the degree of overestimation
699 positively correlated with the standard deviation of the observed samples (but see (Olschewski et
700 al., 2021) for conflicting evidence). Future work might attempt to better understand this curious
701 result and resolve its origin. Perhaps the explanation is something as simple as: when people see a
702 very high outlier sample for an option, it makes it seem obvious that that is the option with the
703 greater mean; since the task is precisely to find the option with the greatest mean, there might not
704 be a similar effect for very low outlier samples.
705 Finally, there is an interesting relationship between the concepts of variability and
706 inaccessibility. In some ways, the concepts are similar. For example, variability and inaccessibility
707 both reduce the efficiency of information sampling. They both, therefore, likely interfere with the
708 ability of participants to estimate the mean values of the number streams in our experiment. Yet
709 the concepts are also different in some fundamental respects. For example, variability (in the form
710 of sample distribution variance) makes it more difficult to infer the mean value but inaccessibility
711 should only slow it down (i.e., a display of letters should not impact the latent value
712 representations). However, inaccessibility might also make the task more difficult if the dynamic
713 mean estimation process has a leak or decay. In that case, the precision of the option value
714 representations that develops over time by incorporating additional numerical samples might
715 dissipate when letters are instead observed. This could explain why low accessibility (sum) and
716 high variability (sum) showed very similar effects in the behavioral data (choice, RT, and
717 confidence). This speculative interpretation of our findings remains to be fully tested in future
718 studies that include computational modeling.
Lee, Tsetsos, Pezzulo, Shahar, & Usher 35
720 Constraints on Generality
721 The participants in our study were predominantly Israeli citizens. We have no good reason
722 to believe that the results should differ in participant pools of other origins, but that is an empirical
723 question. Similarly, our participants were predominantly aged in their early 20s, so we cannot be
724 sure if testing older adults would yield similar results. The choice options in the dataset we
725 analyzed were all snack foods, so we cannot be sure if similar results would arise in other domains.
726 We believe that different elicitation methods for or different operalizations of the concept of
727 familiarity or information availability should yield similar results, though we acknowledge that
728 that is an empirical question.
730 Data and Code Availability
731 The data and analysis code used in preparation of this manuscript are publicly available on
734 Funding
735 DL was supported by the Israel Academy of Sciences and Humanities & Council for
736 Higher Education Excellence Fellowship Program for International Postdoctoral Researchers. This
737 research received funding from the European Research Council under Grant Agreement No.
738 820213 (ThinkAhead) to GP.
Lee, Tsetsos, Pezzulo, Shahar, & Usher 36
740 References
741 Armel, K. C., Beaumel, A., & Rangel, A. (2008a). Biasing simple choices by manipulating relative
742 visual attention. Judgment and Decision Making, 3(5), 396–403.
744 Armel, K. C., Beaumel, A., & Rangel, A. (2008b). Biasing simple choices by manipulating relative
745 visual attention. Judgment and Decision Making, 3(5), Article 5.
747 Bhui, R., & Jiao, P. (2023). Attention Constraints and Learning in Categories. Management Sci-
749 Bitzer, S., Park, H., Blankenburg, F., & Kiebel, S. (2014). Perceptual decision making: Drift-diffu-
750 sion model is equivalent to a Bayesian model. Frontiers in Human Neuroscience, 8.
752 Bogacz, R., Wagenmakers, E.-J., Forstmann, B. U., & Nieuwenhuis, S. (2010). The neural basis
753 of the speed–accuracy tradeoff. Trends in Neurosciences, 33(1), 10–16.
755 Callaway, F., Rangel, A., & Griffiths, T. L. (2021). Fixation patterns in simple choice reflect optimal
756 information sampling. PLOS Computational Biology, 17(3), e1008863.
758 Cassey, T. C., Evens, D. R., Bogacz, R., Marshall, J. A. R., & Ludwig, C. J. H. (2013). Adaptive
759 Sampling of Information in Perceptual Decision-Making. PLOS ONE, 8(11), e78993.
761 Cavanagh, J. F., Wiecki, T. V., Kochar, A., & Frank, M. J. (2014). Eye tracking and pupillometry
762 are indicators of dissociable latent decision processes. Journal of Experimental Psychol-
764 De Martino, B., Fleming, S. M., Garrett, N., & Dolan, R. J. (2013). Confidence in value-based
Lee, Tsetsos, Pezzulo, Shahar, & Usher 37
766 Ellsberg, D. (1961). Risk, Ambiguity, and the Savage Axioms. The Quarterly Journal of Econom-
768 Eum, B., Dolbier, S., & Rangel, A. (2023). Peripheral Visual Information Halves Attentional Choice
769 Biases. Psychological Science, 09567976231184878.
771 Fazio, R. H., Blascovich, J., & Driscoll, D. M. (1992). On the Functional Value of Attitudes: The
772 Influence of Accessible Attitudes on the Ease and Quality of Decision Making. Personality
773 and Social Psychology Bulletin, 18(4), 388–401.
775 Fiedler, S., & Glöckner, A. (2012). The Dynamics of Decision Making in Risky Choice: An Eye-
777 cles/10.3389/fpsyg.2012.00335
778 Friston, K., Rigoli, F., Ognibene, D., Mathys, C., Fitzgerald, T., & Pezzulo, G. (2015). Active infer-
779 ence and epistemic value. Cognitive Neuroscience, 6(4), 187–214.
781 Frömer, R., Callaway, F., Griffiths, T., & Shenhav, A. (2022). Considering what we know and what
782 we don’t know: Expectations and confidence guide value integration in value-based deci-
784 Frömer, R., Dean Wolf, C. K., & Shenhav, A. (2019). Goal congruency dominates reward value
785 in accounting for behavioral and neural correlates of value-based decision-making. Nature
787 Fudenberg, D., Strack, P., & Strzalecki, T. (2018). Speed, Accuracy, and the Optimal Timing of
788 Choices. American Economic Review, 108(12), Article 12.
Lee, Tsetsos, Pezzulo, Shahar, & Usher 38
790 Glickman, M., Sharoni, O., Levy, D. J., Niebur, E., Stuphorn, V., & Usher, M. (2019). The formation
791 of preference in risky choice. PLOS Computational Biology, 15(8), Article 8.
793 Glickman, M., Tsetsos, K., & Usher, M. (2018). Attentional Selection Mediates Framing and Risk-
794 Bias Effects. Psychological Science, 29(12), 2010–2019.
796 Gluth, S., Kern, N., Kortmann, M., & Vitali, C. L. (2020). Value-based attention but not divisive
797 normalization influences decisions with multiple alternatives. Nature Human Behaviour,
799 Gluth, S., Spektor, M. S., & Rieskamp, J. (2018). Value-based attentional capture affects multi-
801 Gold, J. I., & Shadlen, M. N. (2001). Neural computations that underlie decisions about sensory
803 6613(00)01567-9
804 Gwinn, R., & Krajbich, I. (2020). Attitudes and attention. Journal of Experimental Social Psychol-
806 Hertwig, R., Herzog, S. M., Schooler, L. J., & Reimer, T. (2008). Fluency heuristic: A model of
807 how the mind exploits a by-product of information retrieval. Journal of Experimental Psy-
808 chology: Learning, Memory, and Cognition, 34(5), 1191–1206.
810 Howard, R. A. (1966). Information Value Theory. IEEE Transactions on Systems Science and
811 Cybernetics, 2(1), 22–26. IEEE Transactions on Systems Science and Cybernetics.
813 Hunt, L. T., Kolling, N., Soltani, A., Woolrich, M. W., Rushworth, M. F. S., & Behrens, T. E. J.
814 (2012). Mechanisms underlying cortical activity during value-guided choice. Nature Neu-
Lee, Tsetsos, Pezzulo, Shahar, & Usher 39
816 Jang, A. I., Sharma, R., & Drugowitsch, J. (2021). Optimal policy for attention-modulated deci-
817 sions explains human fixation behavior. eLife, 10, e63436.
819 Krajbich, I., Armel, C., & Rangel, A. (2010). Visual fixations and the computation and comparison
820 of value in simple choice. Nature Neuroscience, 13(10), 1292–1298.
822 Landwehr, J. R., & Eckmann, L. (2020). The nature of processing fluency: Amplification versus
823 hedonic marking. Journal of Experimental Social Psychology, 90, 103997.
825 Lee, D. G. (2023). Lee, Tsetsos, Pezzulo, Shahar, & Usher, 2024.
827 Lee, D. G. (2024). A Supply and Demand Approach to Information Processing in Decision-Mak-
829 Lee, D. G., & Coricelli, G. (2020). An Empirical Test of the Role of Value Certainty in Decision
831 Lee, D. G., & Daunizeau, J. (2020). Choosing what we like vs liking what we choose: How choice-
832 induced preference change might actually be instrumental to decision-making. PLOS
834 Lee, D. G., & Daunizeau, J. (2021). Trading mental effort for confidence in the metacognitive
835 control of value-based decision-making. eLife, 10, e63282.
837 Lee, D. G., & Hare, T. A. (2023). Value certainty and choice confidence are multidimensional
838 constructs that guide decision-making. Cognitive, Affective, & Behavioral Neuroscience,
Lee, Tsetsos, Pezzulo, Shahar, & Usher 40
840 Lejarraga, T., Hertwig, R., & Gonzalez, C. (2012). How choice ecology influences search in deci-
842 tion.2012.06.002
843 Ludvig, E. A., Madan, C. R., McMillan, N., Xu, Y., & Spetch, M. L. (2018). Living near the edge:
844 How extreme outcomes and their neighbors drive risky choice. Journal of Experimental
846 Oaksford, M., & Chater, N. (2001). The probabilistic approach to human reasoning. Trends in
848 Olschewski, S., Newell, B. R., Oberholzer, Y., & Scheibehenne, B. (2021). Valuation and estima-
849 tion from experience. Journal of Behavioral Decision Making, 34(5), 729–741.
851 Olschewski, S., & Scheibehenne, B. (2024). What’s in a sample? Epistemic uncertainty and met-
852 acognitive awareness in risk taking. Cognitive Psychology, 149, 101642.
854 Oppenheimer, D. M. (2008). The secret life of fluency. Trends in Cognitive Sciences, 12(6), 237–
856 Polanía, R., Krajbich, I., Grueschow, M., & Ruff, C. C. (2014). Neural oscillations and synchroni-
857 zation differentially support evidence accumulation in perceptual and value-based deci-
859 Polanía, R., Woodford, M., & Ruff, C. C. (2019). Efficient coding of subjective value. Nature Neu-
861 Pratt, J. W. (1964). Risk Aversion in the Small and in the Large. Econometrica, 32(1/2), Article
863 Ratcliff, R. (1978). A theory of memory retrieval. Psychological Review, 85, 59–108.
Lee, Tsetsos, Pezzulo, Shahar, & Usher 41
865 Ratcliff, R., & McKoon, G. (2008). The Diffusion Decision Model: Theory and Data for Two-Choice
866 Decision Tasks. Neural Computation, 20(4), 873–922.
868 Ratcliff, R., Smith, P. L., Brown, S. D., & McKoon, G. (2016). Diffusion Decision Model: Current
869 Issues and History. Trends in Cognitive Sciences, 20(4), 260–281.
871 Schouten, J. F., & Bekker, J. A. M. (1967). Reaction time and accuracy. Acta Psychologica, 27,
873 Sepulveda, P., Usher, M., Davies, N., Benson, A. A., Ortoleva, P., & De Martino, B. (2020). Visual
874 attention modulates the integration of goal-relevant evidence and not value. eLife, 9,
876 Shevlin, B. R. K., Smith, S. M., Hausfeld, J., & Krajbich, I. (2022). High-value decisions are fast
877 and accurate, inconsistent with diminishing value sensitivity. Proceedings of the National
879 Shimojo, S., Simion, C., Shimojo, E., & Scheier, C. (2003). Gaze bias both reflects and influences
881 Smith, S. M., & Krajbich, I. (2018). Attention and choice across domains. Journal of Experimental
883 Smith, S. M., & Krajbich, I. (2019). Gaze Amplifies Value in Decision Making. Psychological Sci-
885 Song, M., Wang, X., Zhang, H., & Li, J. (2019). Proactive Information Sampling in Value-Based
886 Decision-Making: Deciding When and Where to Saccade. Frontiers in Human Neurosci-
888 Stewart, N., Hermens, F., & Matthews, W. J. (2016). Eye Movements in Risky Choice. Journal of
Lee, Tsetsos, Pezzulo, Shahar, & Usher 42
890 Tajima, S., Drugowitsch, J., & Pouget, A. (2016). Optimal policy for value-based decision-making.
892 Tavares, G., Perona, P., & Rangel, A. (2017). The Attentional Drift Diffusion Model of Simple
894 ticles/10.3389/fnins.2017.00468
895 Tsetsos, K., Chater, N., & Usher, M. (2012). Salience driven value integration explains decision
896 biases and preference reversal. Proceedings of the National Academy of Sciences,
898 Usher, M., & McClelland, J. L. (2001). The time course of perceptual choice: The leaky, competing
899 accumulator model. Psychological Review, 108(3), 550–592.
901 Usher, M., Tsetsos, K., Glickman, M., & Chater, N. (2019). Selective Integration: An Attentional
902 Theory of Choice Biases and Adaptive Choice. Current Directions in Psychological Sci-
904 van Lieshout, L. L., de Lange, F. P., & Cools, R. (2020). Why so curious? Quantifying mechanisms
905 of information seeking. Current Opinion in Behavioral Sciences, 35, 112–117.
907 Wald, A. (1945). Sequential Tests of Statistical Hypotheses. The Annals of Mathematical Statis-
908 tics, 16(2), 117–186.
909 Wickelgren, W. A. (1977). Speed-accuracy tradeoff and information processing dynamics. Acta
Lee, Tsetsos, Pezzulo, Shahar, & Usher 43
912 Supplementary Material
913 for
914 Variability and accessibility of information guide gaze dynamics in decision-making
1,5 3 4 1,2 1,2
916 Douglas G. Lee , Konstantinos Tsetsos , Giovanni Pezzulo , Nitzan Shahar , Marius Usher
917 Tel Aviv University, School of Psychological Sciences
918 Tel Aviv University, Sagol School of Neuroscience
919 University of Bristol, School of Psychological Science
920 National Research Council of Italy, Institute of Cognitive Sciences and Technologies
921 University College Dublin, School of Electrical and Electronic Engineering
924 We designed our experiment such that the differences in the generative mean, the
925 generative variance, and the generative accessibility (probability of each sample being a number
926 rather than letters) of the options within each trial would be orthogonal to each other. However,
927 due to the manner in which we established the parameters for each trial, the sum and difference of
928 variability and the sum and difference of accessibility were perfectly correlated. Nevertheless, the
929 fact that we based on analyses on observed samples rather than generative parameters and our
930 definition of difference to be the measure of the higher-mean-valued option minus the measure of
931 the lower-mean-valued option should have removed such correlations. To validate that the
932 intended orthogonality held for the observed variables that we included in our analyses, we tested
933 for correlations across all primary decision variables (sums and differences in mean, variability,
Lee, Tsetsos, Pezzulo, Shahar, & Usher 44
934 and accessibility: sMean, dMean, sVar, dVar, sAcc, dAcc). We did not find any correlations (see
938 with each other.
940 When designing our experiment, we established discrete levels of mean, variability, and
941 accessibility, which in turn resulted in pre-determined discrete levels of the sums and differences
942 of each decision variable (sMean, dMean, sVar, dVar, sAcc, dAcc). These pre-determined levels
943 were used to generate the samples that each participant was shown on each trial. However, our
944 analyses were based on the actual samples that participants observed, not on the generative levels
946 observed levels of each decision variable across participants and trials.
Lee, Tsetsos, Pezzulo, Shahar, & Usher 45
949 pre-determined discrete generative values resulted in a range of observed values across trials and
950 participants. Each blue dot represents one trial.
952 Our gaze fixation location analyses relied on a simple coarse classification of left versus
953 right. However, it could have been the case that participants frequently viewed towards the middle
954 of the screen as they attempted to simultaneously view both options in their peripheral vision. Or
955 perhaps participants might have gazed towards other parts of the computer screen in ways that we
957 participants was predominantly towards either the left or right options, with a high degree of
958 precision. Gaze was very rarely directed towards the center of the screen (this typically occurred
959 only at the beginning of each trial).
Lee, Tsetsos, Pezzulo, Shahar, & Usher 46
962 always directed toward the choice options (either left or right) and only rarely toward the center
963 (mostly at the beginning of each trial). Solid red lines indicate the exact center of each stimulus.
964 Dotted red lines indicate the frontiers by which we defined whether a gaze was directed toward
965 the left, center, or right side of the screen.
967 Test for significance of changes in regression weights for gaze across time bins
968 In the main text, we showed that the drivers of gaze allocation might be dynamic in the
970 the data into quarters based on time from stimulus onset until eventual response (within each trial
971 for each participant). We regressed dGaze during the first quarter of each trial on the same
972 regressors as before (dMean, dVar, dAccess) except now calculated using only the samples that
973 the participants observed during the first quarter of each trial. We then regressed dGaze during the
974 second, third, and fourth quarters of each trial (Q1-4) on dMean, dVar, and dAccess, now
Lee, Tsetsos, Pezzulo, Shahar, & Usher 47
975 calculated according to all samples that participants observed through that time interval (i.e., Q2
976 included samples from Q1-2, Q3 included samples from Q1-3, Q4 included samples from Q1-4).
977 The values of dGaze for each quarter were calculated in a similar manner. We found that at the
978 beginning of trials, participants gazed more at more uncertain options and less at more accessible
979 options. We found that at the end of trials, participants gazed more at the higher-valued option as
980 well as the lower-accessibility option. This differentiation between early and late effects seems to
981 have arisen across time, as demonstrated by the gradual change in regression coefficients from Q1-
983 design matrices and outcome vectors from all of the separate regressions (for each time bin) into
984 one expanded design matrix and one expanded outcome vector. In this expanded model, we also
985 included the following indicator variables: "includes Q2" for the data from quarters 2-4, "includes
986 Q3" for the data from quarters 3-4, and "includes Q4" for the data from quarter 4. The regression
987 model thus consisted of each primary regressor (mean, variability, and accessibility) plus the
988 interactions of each primary regressor and each of the indicator variables. The main effects of
989 variability and accessibility were significant (variability beta = 0.18, p < .001; accessibility beta =
990 -0.10, p < .001), showing that these variables had an impact on gaze in Q1. The interaction effects
991 for variability were all significant (“includes Q2” beta = -0.04, p = .005; “includes Q3” beta = -
992 0.06, p < .001; “includes Q4” beta = -0.09, p < .001), showing that the impact of variability on
993 gaze reliably diminished across trial time. The interaction effects for mean were not statistically
994 significant (“includes Q2” beta = 0.01, p = .584; “includes Q3” beta = 0.00, p = .799; “includes
995 Q4” beta = 0.01, p = .466).