How to get from ‘AI Tools’ to ‘AI Selves’
Liane Gabora
University of British Columbia
December 27, 2022
Abstract:
Recent programs such as ChatGPT and Dall E-2 are captivating, the AI powering them is
impressive, and their outputs are creative. However, there is a tradition of defining creativity in
terms of, not external products, but internal transformation during a creative task. This kind of
GABORA / ‘AI TOOLS’ TO ‘AI SELVES’
creativity requires selfhood not just at the bodily level, but at the level of one's thoughts, beliefs,
and ideas. Both levels of selfhood have been modelled using autocatalytic networks. The paper
discusses how he architecture of autocatalytic networks allows the emergence of a ‘self,’ and
notes that current AI programs do not possess this kind of structure.
GABORA / ‘AI TOOLS’ TO ‘AI SELVES’
Perhaps you’ve had chills running up your spine as you tried out ChatGPT, the latest artificial
intelligence natural language program, that knowledgeably chats with you about just about any
ask it to adopt the persona of a great poet and rewrite its last response as a rhyming poem, or in
gangsta-style rap, or…) Or perhaps you’ve marvelled at how Dall E-2 takes any prompt you give
it (like ‘create a watercolor painting of a knitted wool bowl of mystery in the style of Dahli’) and
you’ve been binging on AI-generated videos (For fun, check out:
say that the AI advances behind them are impressive is an understatement. Surely, they surpass
many human-generated creations. But does that necessarily mean we’ve reached the pinnacle of
what makes us distinctively human: our creativity? Have we achieved artificial general
intelligence (AGI)? Is it time to be scared?
What is Creativity?
Many AI systems are creative in terms of their outputs, and indeed, psychologists commonly
define creativity according to the usefulness and originality of the products that result from
creative thinking (Runco, & Jaeger, 2012; Stein, 1953). However, it isn’t universally agreed that
creativity should be defined in terms of the products that result from creative thinking. This
definition has pitfalls; for example, it leads one to conclude that if Person X invents a new
widget, and it turns out that widget was invented earlier by Person W, then (even if X was
ignorant of W’s work), X can no longer be considered creative (because X’s version was no
longer new).
In fact, there is a long tradition in India (Sen & Sharma, 2011), which has been adopted
by some cognitive scientists (Gabora, 2017), of assessing creativity in terms of, not external
outputs, but internal (often therapeutic) restructuring or transformation that comes about through
immersion in a creative practise. In the extreme, the product can be viewed as the external
residue or excrement of the creative process. For the creator, this product serves as an external
tracker and reminder of cognitive change, and for others, it prompts reciprocal cognitive change.
But the cognitive change is what matters—what defines the process as creative—as opposed to
the outputs that result. In this view, creative products matter only insofar as they meaningfully
alter the minds and worldviews of those who create or are touched by them. What would it take
for an AI to be creative in the sense that it is meaningfully transformed through engagement in a
creative task?
Like human neural networks, AI architectures change as they generate poetry, art, or
problem-solving advice. They form new associations, and learn from mistakes, such that they are
less likely to repeat them. But what would it take for an AI to be creative in the sense that it is
meaningfully transformed through engagement in a creative task?
GABORA / ‘AI TOOLS’ TO ‘AI SELVES’
Two Levels of Self-hood
For starters, it requires a self that senses and interacts with its world, and strives to preserve its
integrity as a structure separate from other structures in that world. That’s relatively
uncontroversial; it’s related to the concept of embodiment (having a body that acts upon, and is
acted upon by, the world) and the symbol-grounding problem (that mental representations must
be connected to real-world perceptions).
I argue, however, that to be meaningfully transformed through engagement in a creative
task requires a second level of self-hood: an internal model of one’s world and one’s place in that
world. This second level is quite distinct from the first; indeed, these two levels may be at odds
with each other, as when a scientist stops eating to write out a new idea for an experiment, or an
artist engrossed in painting ignores the children. The desire to care for one’s children stems from
the somatic (biological) level of self-hood, while the desire to paint the painting stems from
one’s mental (cultural) level of self-hood. The first is concerned with the integrity of the soma
(i.e., the body), while the second is concerned with the integrity of one’s internal model of the
world, or worldview (i.e., the mind, as experienced from inside). This second level seeks
viability, not at the level of the physical body, but at the level of one's thoughts, beliefs, and
ideas, and how they are organized into a web of understandings.
For a machine to be meaningfully transformed through engagement in a creative task, it
must possess self-hood not just at the somatic (biological) level, but at the mental (cultural) level.
In other words, the machine’s model of its reality must include, as a central component, a model
of itself as an entity that is distinct from (yet connected to) others, not just with respect to its
external (bodily) actions, but also with respect to its internal (mental) processes.
The Nature of a Self
To understand how an AI could achieve this second level of selfhood, it is instructive to examine
how it develops in humans.1 A young child undergoes an autonomous transition from not being
able to prioritize, or combine concepts, or spontaneously retrieve items from memory without a
cue, to possessing these abilities. These (and other) abilities require an integrated mental model
of the world, with subsequent knowledge assimilating into and building on this integrated
cognitive structure. In humans, such a structure not only emerges spontaneously, but it is self-
generating, self-mending, and self-perpetuating. Your mental model of reality is continuously
revised in response to, not just information from the outside world, but the stream of thought
playing itself out in your mind. To achieve this, it must be autocatalytic (Kauffman, 1986, 1993;
see also (Maturana & Varela, 1991) on the related concept of autopoiesis). More precisely, it
must be a cognitive Reflexively Autocatalytic Foodset-generated (RAF) network (Gabora &
Steel, 2017, 2020a,b; Gabora, Beckage & Steel, 2022; Ganesh & Gabora, 2022a,b). Let’s now
1 Although this piece focuses on the development of cultural selfhood in a young child, elsewhere the biological
evolution of the capacity for this second level of selfhood has been investigated (Gabora, 2001; Gabora & Steel,
2017, 2020a,b; Smith, Gabora, & Gardner-O’Kearney, 2018).
GABORA / ‘AI TOOLS’ TO ‘AI SELVES’
look at what that means, and why it holds the key to creative, human-style cognition, and self-
hood.
Like other complex networks (including neural networks), a RAF network is composed
of points (or nodes) connected by edges (or links). The nodes can represent units of information
(such as catalytic molecules, or even words or concepts), and the links can represent
relationships between these units (such as how likely one is to catalyze, or activate, the other).
(For example, one molecule may catalyze the reaction by which another is formed, or a
particular concept may ‘prime’, or bring to mind, other closely related concepts). The two key
criteria for a network to be a RAF network are:
1. Each link is catalyzed (i.e., brought into being) by, either one of the original ‘foodset’
nodes, or a ‘foodset-derived’ node that forms through interactions, or restructurings
(sometimes called ‘reactions’) in the network, and
2. All nodes can be generated from interactions (‘reactions’) amongst ‘foodset’ or
‘foodset-derived’ nodes.
This may sound complicated, but in essence what it means is that, unlike conventional
neural networks, RAF nodes don’t just passively spread activation, they actively restructure the
network (or in the RAF lingo, ‘catalyze reactions’), resulting in the formation of new nodes and
links. RAFs can form spontaneously, and expand through the merger of subRAFs. They are self-
preserving and self-regenerating; without RAF structure there is no self-preserving, self-
regenerating entity, i.e., no self.
As hinted above, humans possess RAF structure at two levels: the soma/body level
(making us participants in biological evolution), and the neural network—or as it is experienced
from the inside—worldview level (making us participants in cultural evolution). Indeed, you
may have noticed that the RAF terminology harks back to its original application to the origin of
life (Hordijk & Steel, 2016; Hordijk, Hein, & Steel, 2010; Hordijk, Kauffman, & Steel, 2011;
Hordijk, & Steel, 2004; Steel, Hordijk, & Xavier, 2019; Vasas, Fernando, Santos, Kauffman, &
Szathmáry, 2012; Xavier, Hordijk, Kauffman, Steel, & Martin, 2020).
Just as reactions amongst catalytic molecules generate and perpetuate living structures,
streams of thought generate and perpetuate cognitive structures, i.e., our mental models of the
world, and our place in it. RAF networks are simply abstract mathematical structures, and it is
equally correct to apply them to cognition (and the origin of cultural evolution) as to biology
(and the origin of biological evolution). The origin of life application may have been developed
first, but they are equally valid manifestations of a certain deep mathematical structure; one is no
more an ‘analogy’ than the other. It has been hypothesized that RAFs are essential to the formal
description of the origin of any possible evolutionary process (Gabora & Steel, 2021).
An Artificially Intelligent, Creative Self: What Would it Take?
Can you tell from an AI’s creative outputs whether its cognitive network meets the criteria for
such a RAF? Not necessarily, because it was programmed by us, and our cognitive networks
GABORA / ‘AI TOOLS’ TO ‘AI SELVES’
meet the criteria for a RAF; it may inherit characteristics of RAF structure from us. That is, an
AI might be able to prioritize, combine concepts, adapt knowledge to new situations, or make
something in the style of something else. However, given that an AI is only indirectly tethered to
our RAF structure, telltale signs of something distinctly non-human tend to bleed through. At a
certain point, it becomes clear that you’re not interacting the same kind of feeling, intelligent
being that we are.
Is it possible for an AI program to have the kind of structure that would endow it with a
genuine, autonomous, creative self? Sure, there’s no reason why not. A computational RAF
network would not necessarily possess these qualities, nor have the capacity to be meaningfully
transformed through engagement in a creative practise. But a double-decker computational RAF
network, wherein the second level consists of mental representations of its world, could
potentially possess these qualities. It would have self-hood not just at the somatic (biological)
level, but at the mental (cultural) level. It’s model of its reality would include a model of itself as
an entity that is distinct from (yet connected to) others, not just with respect to its external
(bodily) actions, but also with respect to its internal (mental) processes. Autocatalytic networks
have inspired computer programs for both computer-generated creativity (Bell & Gabora,
2016a,b; DiPaola & Gabora, 2009; DiPaola & Gabora & McCaig, 2018; Goes et al., 2016;
McCaig, DiPaola & Gabora, 2016) and models of human creativity (Gabora & DiPaola, 2012;
Gabora, & Saberi, 2011; Gabora, Leijnen, Veloz, & Lipo, 2011; Gabora & Tseng, 2014, 2017;
Gabora & Smith, 2018; Veloz, Temkin, & Gabora, 2012). These efforts, though successful, have
given us glimpses into how complex an artificial RAF would have be to autonomously
restructure itself through the process of ‘catalyzing’ meaningful new ideas from existing ones.
However, I posit that unless AI programs possess RAF structure, they are merely
extensions of our dual level RAF selves, much like tools, or artificial limbs. They are not selves.
A computer program for generating and analyzing RAFs does exist [link:
talking about here.
In short, once our AI programs assume the structure of a double-decker RAF, they will
possess a sort of self-hood, and be creative according to how anyone measures and defines
creativity. Until that point, however, our computer programs may be creative, but in my view
they are merely tools, and their creativity is an expression of us.