Color needs luminance for visual selection
during scene search
Anke Cajar & Jochen Laubrock
University of Potsdam, Germany
Address correspondence to:
Jochen Laubrock
Department Psychologie
Universita¨t Potsdam
Karl-Liebknecht-Str. 24-25
14476 Potsdam, Germany
e-mail: jochen.laubrock@uni-potsdam.de
phone: +49-331-9772346
fax: +49-331-9772793
Abstract
When searching visual scenes, in addition to high-level scene semantics,
we use low-level visual information from objects’ defining features, such
as color and luminance contrasts. What is the relative influence of
color and luminance? Basic perceptual research suggests that we are
not very sensitive to peripheral color. Yet color is thought to be an
important basic feature guiding visual search. Previous gaze-contingent
research shows that targets can be identified faster in color than in
black-and-white scenes, therefore the availability of color in the visual
periphery indeed helps visual search. However, color contrasts and
luminance contrasts usually covary at object boundaries. Here we study
the isolated roles of color and luminance during object-in-scene search
by presenting either only color or only luminance contrasts in peripheral
vision, using a gaze-contingent moving-window display and varying the
amount and type of peripheral preview. We found that peripheral
target selection was more efficient with luminance contrasts, whereas
color was hardly used beyond the parafovea. We conclude that color
contrasts in peripheral vision can only be efficiently used in scene search
when they are correlated with luminance contrasts.
Key words: Visual search; Scene perception; Eye tracking; Gaze-contingent displays;
Color perception; Luminance perception
SCENE SEARCH WITH PERIPHERAL COLOR AND LUMINANCE FILTERS 2
When we look at a color photograph, we have the impression of a colorful scene,
with color everywhere in the picture. However, basic perceptual research indicates
that the use of peripheral color for visual search is severely limited. In contrast,
results from the visual search tradition suggests that color is a basic feature guiding
search. How can these results be reconciled? Here we investigate the contribution
of color to search efficiency in real-world scenes. We restricted the amount of color
and luminance previews at any given fixation. Before detailing our research setup, we
briefly review existing research on the use of color and luminance in visual perception
and visual search.
Peripheral and foveal vision in visual search. When searching a visual scene,
we need to solve two ongoing tasks in parallel. The object at fixation is inspected
with high acuity foveal vision, while at the same time we select the next object
of interest with peripheral vision, to which we then execute a saccade to bring it
into foveal vision. Foveal inspection tends to dominate fixation duration, because it
usually takes longer than peripheral selection (Laubrock, Cajar, & Engbert, 2013).
We receive visual input from about 200 degrees horizontally × 130 degrees vertically,
but the central foveola covers only about 1.5 degrees of visual angle.
Color vs. luminance in peripheral perception. How does sensitivity to lumi-
nance or color contrasts change across the visual field? Most of the evidence comes
from studies using non-moving eyes. For cone vision, contrast sensitivity relies on
two opponent processes coding for red vs. green and blue vs. yellow color contrasts,
and one additive mechanism coding for luminance. Rod vision is generally insensitive
to color and only sensitive to luminance. Cone spacing as well as the cone-to-rod
ratio increase with retinal eccentricity, therefore spatial acuity decreases. (Mullen &
Kingdom, 2002; Witzel & Gegenfurtner, 2014).
Foveally, overall contrast sensitivity is highest for high frequency gratings of
about 3-7 cpd. The overall bandpass characteristic is due to integration over a num-
ber of channels centered at different spatial frequencies (Campbell & Robson, 1968).
At lower intensities, the overall characteristic becomes lowpass (Robson, 1966), due
to fewer high frequency channels. Sensitivity for luminance contrasts decreases as a
function of eccentricity. The gradient is very steep for high spatial frequencies, but
considerably shallower for lower spatial frequencies. Both the maximum sensitivity
SCENE SEARCH WITH PERIPHERAL COLOR AND LUMINANCE FILTERS 3
and the spatial frequency at which it occurs decrease in the periphery (Hilz & Cavo-
nius, 1974). Therefore the visual periphery favors broader object blobs rather than
fine detail.
The spatial resolution of color vision in the periphery decreases even more
strongly (Mullen & Kingdom, 2002; Mullen, Sakurai, & Chu, 2005). Red-green sen-
sitivity decreases more steeply with eccentricity than blue-yellow sensitivity. Nev-
ertheless color discrimination is still possible at eccentricities as far as 30-50 deg if
stimuli are big enough to counteract the loss of spatial resolution (Hansen, Pracejus,
& Gegenfurtner, 2009).
In summary, visual acuity and our ability to discriminate colors decrease rapidly
with retinal eccentricity, which explains why we need to move our eyes. These results
were obtained with simple stimuli and static eyes. How relevant are they for the
perception of realistic scenes?
Color in visual search. Given the above, one might expect color to be inefficient
in guiding peripheral selection. However, color is considered one of the few basic
features in visual search that produce a pop-out effect (Treisman & Gelade, 1980;
Wolfe, 2021). Unlike for many other features, search times for a uniquely colored
item among a set of distractor items does not increase with the number of distractors.
Color is thus considered a basic feature that can preattentively guide attention. Basic
features attract attention automatically, in a bottom-up fashion, whereas top-down
attention involves a higher-level control system that can weigh different basic and
higher-level features according to task demands (Itti & Koch, 2000).
Color is considered one of the most effective basic features. However, its pop-
out efficiency depends on color similarity to other items in the search display, and
color differences need to be considerably larger for search efficiency than for color
discrimination (Nagy & Sanchez, 1990). This fact might limit the use of color infor-
mation in real-world search. Efficient search for color is possible given the appropriate
conditions (Duncan, 1989), but guidance by color lacks efficiency when colors are not
widely separated in color space (D’Zmura, 1991). Typically a range of colors are
present in any scene, reducing the probability of the target having a distinctive color.
Nevertheless color similarity might act to narrow down the search space, therefore
color can still be considered an important feature for visual selection in real-world
scenes.
SCENE SEARCH WITH PERIPHERAL COLOR AND LUMINANCE FILTERS 4
Color for target selection in realistic scenes. Gaze-contingent studies manip-
ulating peripheral color availability provide a mixed pattern of results. Most find-
ings argue that color is an important feature for peripheral target selection in scene
search (Cajar, Engbert, & Laubrock, 2020; Nuthmann & Malcolm, 2016; Hwang,
Higgins, & Pomplun, 2007), and even dominates visual guidance over other features
like intensity or contrast (Hwang et al., 2007). For example, using gaze-contingent
spatial frequency filtering, Cajar et al. (2020) found that attenuating high spatial fre-
quencies in the periphery was more detrimental for search in grayscale than in color
scenes. However, observers typically do not become aware of a lack of peripheral color
in real-world scenes. Using a gaze-contingent virtual reality setup, Cohen, Botch, and
Robertson (2020) showed that observers do not notice if the periphery lacks color,
although they are able to detect a lack of color when explicitly instructed to attend
to the periphery. Apparently, peripheral color is not a very strong cue for top-down
guidance of attention. Similarly, the distribution of fixation locations is largely iden-
tical on grayscale and color scenes, although the absence of color leads to longer
fixation durations (Ho-Phuoc, Guyader, Landragin, & Gu´erin-Dugu´e, 2012). This
finding suggests color is more important for foveal inspection than for peripheral tar-
get selection. Clearly more research is needed to resolve these seemingly inconsistent
findings.
Disentangling the effects of color and luminance. The role of peripheral color
vision in target selection remains unclear. On the one hand, basic perception results
indicate that color is relatively unimportant in the periphery. On the other hand,
search times and eye movement statistics in gaze-contingent displays are affected
by a lack of color in peripheral vision. Displays in previous gaze-contingent studies
confounded color and luminance by comparing grayscale with color previews. Color
was always added on top of luminance contrasts that were already present. Thus,
while these studies point to color as an important contributor to search efficiency,
they do not allow to clearly disentangle the effects of color and luminance on scene
viewing.
Previous work investigating the individual contributions of chromatic and achro-
matic signals with simple stimuli suggest that shape discrimination is better with
luminance than with color contrasts (Mullen & Beaudot, 2002), and that abrupt
luminance changes pop out, whereas abrupt color changes do not, suggesting preat-
SCENE SEARCH WITH PERIPHERAL COLOR AND LUMINANCE FILTERS 5
tentive parallel processing of luminance, but not of color signals (Theeuwes, 1995).
Furthermore, rapid scene categorization has been shown to rely on luminance infor-
mation, but not on color cues (Delorme, Richard, & Fabre-Thorpe, 2000). In contrast,
Hardman and colleagues (2020) showed that preattentive processing of visual stimuli
is facilitated when stimuli contain both luminance and color signals, compared with
luminance signals only. Both color and luminance also seem to be necessary features
for unimpaired object recognition (Poth & Schneider, 2016).
The present experiment. To assess the role of color independent of luminance
in target selection during scene viewing, we compared equiluminant with grayscale
peripheral previews. We asked participants to perform a visual search task in pho-
tographs of real-world scenes while monitoring their eye movements. Keeping central
vision unimpaired, we presented grayscale or equiluminant color versions of the scene
to the periphery using a gaze-contingent moving window. We varied the size of the
window to find out at which eccentricities color or luminance contrasts dominate.
Following the logic of the moving-window paradigm, a manipulation that causes eye-
movement behavior to deviate from control suggests that the manipulated variable
has an influence on processing at a given eccentricity. Extrapolating from percep-
tion experiments, we expected luminance to have a higher weight in the periphery.
Therefore we expected luminance effects at larger window sizes, where color might
already fail to affect viewing behavior. As in previous research (Laubrock et al., 2013;
Cajar, Engbert, & Laubrock, 2016; Cajar, Schneeweiß, Engbert, & Laubrock, 2016)
we expected effects on search times, saccade amplitudes and fixation durations.
Method
Participants
Twenty-eight University of Potsdam students (16 female, 10 male, 2 diverse,
mean age: 22.8, range: 17 to 33 years) participated in the experiment. Participants
had normal or corrected-to-normal vision and normal color discrimination. They
were naive to the purpose of the experiment and received course credit or monetary
compensation. Participants gave written informed consent prior to the experiment
conforming to the Declaration of Helsinki.
SCENE SEARCH WITH PERIPHERAL COLOR AND LUMINANCE FILTERS 6
Apparatus
Stimuli were presented on a VIEWPixx monitor (VPixx Technologies) with
a resolution of 1920 × 1080 pixel and a refresh rate of 120 Hz. Presen-
tation was controlled with Matlab (The Mathworks, Natick, MA) using the
Psychophysics (Brainard, 1997; Kleiner, Brainard, & Pelli, 2007) and Eye-
link (Cornelissen, Peters, & Palmer, 2002) Toolboxes. Viewers were seated 60 cm
(23.6 inches) away from the monitor with their head stabilized by a head-chin rest.
Gaze position of the dominant eye was tracked during binocular viewing with the
EyeLink 1000 system (SR Research, Ontario, Canada).
Stimuli and design
Stimuli were 119 images of real-world scenes from the BOiS database (Mohr et
◦ ◦
al., 2016) resized to 1400 × 1050 pixels, subtending a visual angle of 36.3 × 27.2 .
Of these images, 100 depicted indoor and 19 depicted outdoor scenes. Each scene
showed the target object at a predictable location regarding scene context (e.g., a
For each scene, color- and luminance-filtered versions were prepared in advance.
Color filtered versions were created by converting the color images to black and white.
For luminance filtered versions, we took an approximate approach, as the applicability
of more sophisticated methods to create equiluminance is limited to simple stimuli.
We subtracted the black-and-white image from the color image, and added the mean
intensity of the black-and-white image, hoping that this procedure would be good
enough to take out most of the usable luminance contrasts.
For gaze-contingent filtering of the peripheral visual field, a foreground and a
background image were merged in real-time using alpha blending. The foreground
was the original scene and the background was the filtered version of the scene. A
2D hyperbolic tangent with a slope of 0.06 served as a blending function for creating
the alpha mask. The inflection point of the function corresponded to the radius of
the gaze-contingent window, see below. The alpha mask was centered at the current
gaze position and defined the transparency value. At fixation, only the foreground
image was visible; with increasing eccentricity, the peripheral background image was
weighted more strongly until it was fully visible.
Two filter types (color/luminance) were crossed with three filter sizes (small,
medium, large), yielding six filter conditions: peripheral luminance removed beyond
SCENE SEARCH WITH PERIPHERAL COLOR AND LUMINANCE FILTERS 7
red cross indicates the current gaze position. (Top left) Luminance removed beyond 4
eccentricity. (Top right) Luminance removed beyond 6 eccentricity. (Bottom left) Color
removed beyond 8 eccentricity. (Bottom right) Unfiltered control condition.
◦ ◦ ◦ ◦ ◦ ◦
4 , 6 , or 8 eccentricity, or peripheral color removed beyond 4 , 6 , or 8 eccentricity
baseline. This resulted in 17 trials per condition.
A Latin square design assured counterbalancing of condition–scene assignments
across participants. Scenes were presented in random order.
Procedure
At the beginning of the experiment and after every 15 trials a 9-point calibration
was performed. At the beginning of each trial, fixation was checked. The viewer’s
◦ ◦
gaze had to stay within an area of 1.5 × 1.5 around the screen center for 200 ms.
After a successful check, the actual trial started; if the check failed three times, a
SCENE SEARCH WITH PERIPHERAL COLOR AND LUMINANCE FILTERS 8
re-calibration was scheduled.
Three example trials familiarized participants with the task and the gaze-
contingent window procedure. Each trial started with a pictorial cue of the target
object on a black background presented for two seconds. Subsequently, a central black
cross was presented to ensure viewers always started exploring in the center of the
image. After the cross was fixated, the scene was revealed. Viewers were instructed
to find the target object in the scene as quickly as possible and to press the left but-
ton of the computer mouse once they found it. There was a response deadline of 60
seconds.
Data preparation
Saccades were detected in the time series of gaze positions using a velocity-based
algorithm (Engbert & Kliegl, 2003; Engbert & Mergenthaler, 2006) with a relative
velocity threshold of 6 standard deviations and a minimum duration of 8 data samples.
A total of 18 trials (0.99%) were removed owing to poor calibration or too much data
loss. One additional trial was removed because it reached the response deadline of 60
s. Single fixations and saccades were removed if they neighbored eye blinks or were
outside the scene. If the first or last trial event was an ongoing saccade, it was also
removed. In total, 20,405 fixations and 17,439 saccades remained for eye movement
analyses. For analyzing fixation durations, the last ongoing fixation of each trial was
excluded.
Data analyses
Search times and eye movements were analyzed using linear mixed-effects mod-
els (LMMs) (Bates, Maechler, Bolker, & Walker, 2015) in R (version 4.2.1; R Core
Team, 2022) with random intercepts for participants and scenes.
We predefined contrasts to test for the deviation of each experimental condition
from control. Fixed-effects parameters were estimated with the following six contrasts:
(1) luminance removed at 4 deg vs. control, (2) luminance removed at 6 deg vs.
control, (3) luminance removed at 8 deg vs. control, (4) color removed at 4 deg vs.
control, (5) color removed at 6 deg vs. control, and (6) color removed at 8 deg vs.
control. We used the lmerTest package to test for significance of effects.
In order to achieve normally distributed residuals in model fitting, we trans-
formed measures using the Box-Cox procedure, which was indicated for all measures
SCENE SEARCH WITH PERIPHERAL COLOR AND LUMINANCE FILTERS 9
due to positive skew.
Results
fixations and search times for all seven conditions of the experiment.
Search times
Mean search time across conditions was 1594 ms (SD = 1881 ms). Search
times were shorter for all window sizes when luminance was removed (b = 2.57, t =
13.7, p < .001; b = 1.06, t = 5.7, p < .001; b = 0.45, t = 2.4, p = 0.018 for 4 vs.
6. vs. 8 degrees, respectively). In contrast, search times only deviated from the
control condition for four and six degree windows when color was removed, and the
effects were smaller overall (b = 1.50, t = 8.0, p < .001; b = 1.09, t = 5.8, p < .001;
b = 0.28, t = −1.5, p = 0.14 for 4 vs. 6. vs. 8 degrees, respectively).
Fixation durations
Mean fixation duration across conditions was 213 ms (SD = 102 ms). Again,
luminance removal (b = 7.24, t = 5.6, p < .001; b = 2.30, t = 1.7, p = 0.093; b =
0.38, t = 0.3, p = .775 for 4 vs. 6. vs. 8 degrees, respectively) caused stronger
effects than color removal (b = 2.60, t = 1.9, p = .093; b = 1.51, t = 1.1, p = .277;
b = −1, 07, t = −0.8, p = .449 for 4 vs. 6. vs. 8 degrees, respectively). Effects on
fixation duration were limited to the smallest window size, and were significant only
for luminance removal, indicating that fixation durations were mainly controlled by
foveal vision.
Number of fixations
Across conditions, participants made an average of six fixations per scene
2). Again, effects were stronger for luminance removal than for color removal. Lu-
minance removal led to an increased number of fixations for all window sizes tested
(b = 6.02, t = 10.7, p < .001; b = 2.41, t = 4.28, p < .001; b = 1.23, t = 2.2, p = 0.030
for 4 vs. 6. vs. 8 degrees, respectively), whereas color removal had only had smaller
effects at the smaller window sizes up to six degrees (b = 2.71, t = 4.8, p < .001;
SCENE SEARCH WITH PERIPHERAL COLOR AND LUMINANCE FILTERS 10
Control 4 deg 6 deg 8 deg
Filter size
]sm[
noitarud
noitaxiF
5.0
4.5
4.0
Control 4 deg 6 deg 8 deg
Filter size
]ged[
edutilpma
edaccaS
Control 4 deg 6 deg 8 deg
Filter size
snoitaxif
fo
rebmuN
Control 4 deg 6 deg 8 deg
Filter size
]sm[
emit
hcraeS
Filter type
Control
Luminance removed
Color removed
saccade amplitudes (top right), mean number of fixations (bottom left) and mean search
times (bottom right) for all conditions of the experiment. Error bars represent 95% within-
subject confidence intervals, with the Cosineau-Morey correction applied (Cousineau, 2005;
Morey, 2008)
SCENE SEARCH WITH PERIPHERAL COLOR AND LUMINANCE FILTERS 11
b = 1.80, t = 3.2, p = .001; b = 0.18, t = 0.3, p = .744 for 4 vs. 6. vs. 8 degrees,
respectively).
Saccade amplitudes
◦ ◦
Mean saccade amplitude across conditions was 4.6 (SD = 3.8 ). Again, saccade
amplitudes were affected more strongly by luminance removal than by color removal.
As with search times, luminance removal had an effect at all window sizes tested
(b = 1.30, t = 5.5, p < .001; b = 1.04, t = 4.2, p < .001; b = 0.63, t = 2.5, p = .012; for
4 vs. 6. vs. 8 degrees, respectively). In contrast, color removal only affected saccade
amplitudes at the smallest window size (b = 0.59, t = 2.4, p = .018; b = 0.72, t =
0.3, p = .776; b = 0.89, t = 0.3, p = .731; for 4 vs. 6. vs. 8 degrees, respectively).
Discussion
The present study investigated the isolated effects of luminance and color in the
visual periphery during object search in real-world scenes. We selectively removed
luminance or color contrasts from the scenes at various levels of eccentricity. Results
show that luminance removal had an effect on saccade target selection for all window
sizes tested, whereas the effect of color removal was restricted to parafoveal viewing.
Luminance had a particularly strong influence on saccade amplitudes, suggesting
that luminance drives saccade target selection at eccentricities at least as far as 8
in the periphery. For other measures, luminance influenced behavior only at smaller
eccentricities, where its effects were generally larger than the effects of color, especially
with 4 windows. In contrast, removing color hardly affected any measure when the
window was larger than 4 . Therefore, the use of pure color contrasts for search in
natural scenes seems to be limited to foveal and parafoveal vision. These results are
in line with findings obtained using resting eyes, showing that sensitivity for color
drops off more sharply with eccentricity than sensitivity for luminance contrasts.
Previous work from visual search as well as from gaze-contigent scene-viewing
also suggests that search times with color scenes are shorter than with grayscale
scenes and that low-frequency peripheral color information is critical for facilitating
search (Cajar et al., 2020; Nuthmann & Malcolm, 2016; Hwang et al., 2007). However,
in all of these studies, luminance and chromaticity were confounded.
The present results show that color is only beneficial if luminance information
is additionally available, and that color alone does not guide search in the periph-
SCENE SEARCH WITH PERIPHERAL COLOR AND LUMINANCE FILTERS 12
ery. They rather point to an interactive mechanism for peripheral selection, where
luminance is mandatory and color can provide additional benefits. The most par-
simonious interpretation in the context of earlier findings is that peripheral color is
beneficial for search, but only if it is supported by luminance. This interpretation is
in accord with Hardman et al. (2020), who found in a task with fixation demands
that luminance contrast added to chromaticity contrasts speeded up an event-related
EEG component, in comparison to pure luminance contrasts. Color and luminance
might be integrated during pre-attentive processing, but luminance dominates.
Recent research suggests that objects are more important than low-level visual
properties in guiding search in real-world scenes (Henderson & Hayes, 2017; Hayes
& Henderson, 2019; Ku¨mmerer, Bethge, & Wallis, 2022). In context, the present
results suggest that color is important for peripheral object identification, but only if
the objects differ from their surrounding in luminance. Interestingly, although edges
defined by color and luminance contrasts often coincide, real-world scenes also contain
many isoluminant color edges (Hansen & Gegenfurtner, 2009). Possibly, joint color
and luminance contrasts are more likely at object boundaries.
A limitation of the present study is the rather simplistic approach at creating
equiluminant stimuli. In the worst case, some residual luminance contrasts might
have been available in the ‘equiluminant‘ version. We do not consider this a major
problem, because even if so, the results indicate that residual luminance contrasts
were not sufficient to support peripheral object discrimination at the same level as
the contrasts available in the grayscale peripheral preview.
In summary, color contrasts in the absence of luminance contrasts contribute
little to the selection of peripheral objects for close inspection during scene viewing.
How can this be reconciled with earlier results showing that color facilitates visual
search? Earlier studies confounded color and luminance. The present results suggest
that luminance is more important for visual selection during scene search. Color can
only aid in peripheral object segmentation and identification after luminance contours
have been identified.
Acknowledgements
This work was supported by DFG grant LA 2884/2 to JL. We would like to
thank Petra Schienmann for support in testing participants.
The data and analyis scripts for the experiment are available at
SCENE SEARCH WITH PERIPHERAL COLOR AND LUMINANCE FILTERS 13