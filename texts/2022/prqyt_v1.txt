Operationalization Bias
Operationalization Bias: A Suboptimal Research Practice in Psychology
Nagireddy Neelakanteswar Reddy (Ph.D.)
Ahmedabad, India
Abstract
The recent replication crisis in psychology has alerted researchers to the presence of suboptimal
research practices ― that are not the cases of fraud per se ― such as the practice of stopping data
collection or deleting some of the data to attain statistical significance and the tendency to refrain
from publishing null results. The suboptimal research practices may be motivated by the
theoretical biases a researcher ― consciously or unconsciously ― holds and may be facilitated by
the flexibility in collecting, analyzing, and reporting the data. This article discusses a suboptimal
research practice, the operationalization bias, i.e., the practice of operationalizing a construct or
phenomenon selectively, through the exclusive employment of one or very few variables and, in
turn, neglecting to employ alternative operationalizations. Using the example of the
operationalization of perception in the field of cognitive penetration, this article illustrates how
operationalization biases can lead to false-positive findings and how the improvements in theory
concerning a psychological construct will keep a check on the suboptimal research practices like
the operationalization bias.
Keywords: operationalization bias, confirmation bias, suboptimal research practices
Operationalization Bias
Introduction
In recent years, many have attempted to replicate psychological research and found that a large
number of studies failed to yield the same results (e.g., Open Science Collaboration, 2015). These
replication failures are attributed either to the contextual differences between the original study
and the replication study (Stroebe & Strack, 2014; van Bavel et al., 2016; but see Inbar, 2016 for
an argument against the role of contextual differences in replication failures), or to suboptimal
research practices [John, Loewenstein, & Prelec, 2012; Jussim et al., 2019; but see Fiedler &
Schwarz, 2015 for an argument that the earlier estimates of the prevalence of suboptimal research
practices are inflated].
Some of the suboptimal research practices that can lead to invalid research findings include
the tendency to intermediately stop collecting further data at the point where a researcher finds
that the current data can yield statistical significance, the practice of a researcher to selectively ―
ad hoc or non-blindedly ― discard some of the (outliers or otherwise) data to obtain a strong
statistical significance with the retained data, and dispensing with some of the results if the data
do not support the intended theory. Indeed, it is found that selective reporting occurs in at least
50% of the psychological publications ― that are published based on doctoral dissertations
(defended between 1999 and 2017) ― where dissertations that found support for their hypothesis
are more likely to culminate as journal publications over those dissertations whose hypotheses
were not unsupported (Cairo et al., 2020). Similarly, experiments may sometimes yield results per
the experimenter’s scientific expectations, i.e., the experimenter expectancy effect (Rosenthal,
1966). However, it has to be noted that the suboptimal research practices do not amount to research
fraud per se, as the suboptimal research practices do not involve cases of fabrication of data.
Suboptimal research practices primarily involve data omissions that fail to yield statistical
significance or are inconsistent with the prior assumptions or theories held by the researcher ―
where the retained data are still the result of legitimate methodological practice. Although
suboptimal research practices are not cases of fraud per se, they still lead to invalid research
findings ― mostly false positives or type 1 errors ― and thus need to be kept in check.
A significant facilitator for suboptimal research practices is the “researcher degrees of
freedom” in data collection and analysis (Wicherts et al., 2016). For instance, researchers have the
opportunity or the convenience to omit the data that do not produce the intended statistical
Operationalization Bias
significance or the desired experimental results. One likely reason behind the suboptimal research
practices ― mostly occurring under the scope of the researcher degrees of freedom ― is the
(theory) “confirmation bias,” the tendency of the researcher to selectively gather, analyze, report,
and favour the data or information that aligns with their prior beliefs and theories, and discredit
the opposing views or theories. It is possible that psychologists ― including the author of this
article ― are susceptible to theoretical and experimental biases (Ioannidis et al., 2014). For
instance, it was found that psychologists who disagree with a hypothesis, say, as presented in an
abstract, tend to judge the quality of the study to be superior when the abstract concludes that the
study had disconfirmed the hypothesis. Analogously, the participant-psychologists evaluated the
hypothetical study as inferior if its conclusions did not align with their prior views (Hergovich,
Schott, & Burger, 2010). Similarly, peer reviewers tend to discredit the results of those manuscripts
that oppose their theoretical views (Mahoney, 1977). The tendency to prefer one’s own theories is
so spontaneous that the mere induction of a trivial nominal link between self (contra others) and a
theory will make people prefer and regard the associated theory to be true (Gregg, Mahadevan, &
Sedikides, 2017). So, academic research practices can be affected by confirmation biases.
Controlling confirmation biases may be challenging as any threat to the preferred theories
might activate motivated reasoning (Jussim et al., 2016; Lilienfeld, 2010), mainly when the
research psychologists are uncertain of the inaccuracy of their theories (MacCoun, 1998).
Moreover, confirmation biases are independent of a researcher’s intelligence; thus, even
knowledgeable researchers can fall prey to confirmation biases (Stanovich, West, & Toplak,
2013). Accordingly, it is proposed that confirmation bias is a byproduct of reasoning whose
primary function is defending one’s already adhered views (Mercier & Sperber, 2011). One’s
motivated tendency to engage in confirmation biases can be attributed to human tribalism, i.e., an
evolved tendency to accept, favour, and defend the views of one’s in-group over that of the out-
group (Clark & Winegard, 2020). Accordingly, Holtz (2020) states, “Scientists more often than
not build their careers around a certain ‘pet theory’ and their writings are mostly read and in turn
cited by other scientists from the same research community. Such communities are built upon the
assumption that a given theory is ‘true’ or at least useful in explaining relevant phenomena” (p. 3).
This sort of “canonization” is “the process by which research findings and conclusions become
part of a field’s accepted and established base of knowledge” (Honeycutt & Jussim, 2020, p. 80)
may often result from research that employs valid scientific standards as well as on rare occasions
Operationalization Bias
also due to a researcher’s (confirmatory) commitment to the views of their academic in-group.
Thus, sometimes, an inaccurate knowledge base can become canonized in a scientific domain
(Nissen et al., 2016) which may have resulted from non-epistemic factors such as “popularity,
prestige, having the right allies and supporters, compellingness of narrative” (Honeycutt & Jussim,
2020, p. 81) but not from valid scientific practices. For instance, the purported relationship
between cardiovascular mortality and type D personality is an invalid canon established in its
respective field due to replications by inbred (or the same) scientific teams or obedient and obliged
replication by other teams (Ioannidis, 2012).
Suppose motivational factors like confirmation biases affect research practices. In that
case, the prevalent suboptimal research practices can be due to a researcher’s tendency to confirm
their prior theories that are further facilitated by the researcher degrees of freedom in collecting
and analyzing data [or merely to attain a statistical significance of the data gathered (Gigerenzer,
2018)]. Theory confirmation biases may affect one’s experimental practices. For instance,
participants who are instructed to pretend-perform scientific research ― in an artificial simulated
environment ― tended to employ only those experimental manipulations that confirmed their
hypotheses, and they tended to neglect to test and disconfirm alternative hypotheses (Mynatt,
Doherty, & Tweney, 1977). Accordingly, it is found (in an analysis of 2434 published papers) that
the research in psychological sciences ― compared to that of the research in “hard” biological and
physical sciences ― is more likely to find positive, full or partial support for the hypotheses that
are being tested (Fanelli, 2010); [but, it has to be noted that a prevalence of positive findings might
not always suggest a presence of confirmatory research strategy as it can also be due to HARKing,
i.e., hypothesizing after the results are known]. The tendency to be biased toward confirmatory
hypothesis testing parallels a general confirmation bias in human reasoning (for instance, as
depicted in the Wason selection task [Wason, 1960]). Accordingly, a confirmation bias in scientific
hypothesis testing is an instance of a general positive testing strategy where “there is a tendency
to test cases that are expected (or known) to have the property of interest rather than those expected
However, it is possible that although confirmation biases may lead to epistemic errors at an individual-researcher
level, at a group level, they may contribute to reliable scientific inquiry as researchers motivated by (theory)
confirmation biases will critically evaluate opposing/disconfirming views and in turn, their theories will also be
critically analyzed by researchers who also are motivated to confirm their own views, thus, cancelling out each other’s
erroneous theoretical biases (Peters, 2021).
Operationalization Bias
(or known) to lack that property” (Klayman & Ha, 1987, p. 211). However, a confirmatory
research strategy may still lead to the accumulation of false positives and, thus, threaten the validity
of the research findings (Simmons, Nelson, & Simonsohn, 2011).
Many metascientific efforts so far disclosed suboptimal research practices like p-hacking,
overemphasizing statistical significance in publication, low sample power, and not publishing null
results. In this article, I discuss an additional suboptimal research practice, the “operationalization
bias,” i.e., the practice of operationalizing a psychological phenomenon selectively, using
particular/exclusive independent and dependent variables, and forgoing the employment of
alternative, albeit rather bona fide, variables that equally represent a psychological phenomenon.
I will discuss the possible instance of operationalization bias by considering cognitive penetration
research as an example.
Operationalization Bias
One of the ways through which (theory) confirmation bias can impact experimental research
practices is by giving rise to an operationalization bias ― either consciously or unconsciously ―
that is, the suboptimal research practice of operationalizing a psychological construct selectively
(using particular variables) and neglecting alternative operationalizations of the
construct/phenomenon. A biased operationalization of a construct may most often lead to false-
positive findings. For instance, the findings that support the purported process of cognitive
penetration ― where non-sensory cognitive (independent variable) factors like desires, beliefs,
However, some argue that the positive testing strategy or the confirmation strategy, although faulty, can still be
normatively appropriate as what a psychologist is often interested in testing are the non-absolute hypotheses ― of
whether a particular psychological process sometimes occurs or not ― rather than the universal hypotheses ― of
whether a process always occurs or not ― and psychologists do not always attempt a (Popperian) falsification at a
(universal) theory level (Sanbonmatsu et al., 2015).
Haucke, Hoekstra, and van Ravenzwaaij (2021) point out that “So far, suggestions to enhance the reproducibility of
findings often revolve around the use of statistics, for example the false interpretation of p-values or a lack of control
for statistical power. One important methodological concern related to replicability that has received little attention in
this discussion is the validity of the operationalization. … Even if one successfully reduces statistical practices that
increase false positives, one can still be faced with erroneous conclusions from falsely mapping empirical results onto
constructs. That is, although the results may seem convincing, they do not necessarily warrant the conclusions drawn
with respect to one’s construct or theory. … a study can lead to convincing statistical results, while actually not
operationalizing the underlying concept well. Therefore, we believe researchers need to be attuned towards invalid
operationalizations” (p. 2).
The biased selection of the variables to study is not just limited to the context of experimentation but also applicable
to psychological measurement. For instance, Flake and Fried (2020) discuss the causes and consequences of the
suboptimal measurement practices and propose strategies to avoid them.
Operationalization Bias
thoughts, concepts, language, actions, bodily states etc., generate or modify (dependent variable)
sensory perception ― might not manifest on all possible operationalizations of (sensory)
perception. For instance, almost all the studies of cognitive penetrability have selectively and
exclusively operationalized (the dependent variable) perception to be an inaccurate “perceptual”
report ― as in a magnitude estimation task (e.g., Philbeck & Witt, 2015) ― and forgone the
alternative operationalization of perception as accurate reports ― as in a category identification or
discrimination task (e.g., Valenti & Firestone, 2019). In the typical magnitude estimation tasks,
the participants estimate the quantities of the perceived world like distances, heights, slants, sizes,
weights, speeds, and shades of colours; and in the cognitive penetration experiments, they estimate
these magnitudes under the influence of (non-sensory) independent variables like thoughts, beliefs,
semantic and linguistic knowledge, memory, motor actions, emotions, effort, motivated states etc.
The participants’ verbal reports are considered to demonstrate the phenomenon of cognitive
penetration. However, it has to be noted that the perceptual reports of the participants in a
magnitude estimation task ― as employed in the cognitive penetration experiments ― are
inaccurate because what the participants report is either the subjective overestimation or
underestimation of the objective magnitude presented to them (see Reddy, 2021 for further details).
For instance, participants may subjectively overestimate the steepness of a hill ― presumably
under the influence of cognitive penetration factors like being hungry or fatigued or encumbered
(e.g., Philbeck & Witt, 2015) ― which is an inaccurate report. However, inaccurate magnitude
estimations may be inadequate evidence of the cognitive penetration phenomenon for the
following reasons.
Sensory perception will manifest as an epistemic awareness about the immediate perceived
world so that perception can be measured as perceptual verbal reports. Although not all perceptual
episodes are accurate ― such as, for instance, sensory illusions ― all accurate (immediate, online)
knowledge about the objects/events in the perceptual field can be attributed to sensory perception.
So, inaccurate reports can either be due to perceptual or non-sensory cognitive/thought errors.
Thus, if a researcher’s measure of perception accepts inaccurate reports, then such
operationalization fails to distinguish between perceptual and thought processes. Thus, the
measure also fails to control confounding by non-perceptual factors such as response or decisional
factors. If perception can lead to both accuracy and inaccuracy, and if only those tasks that give
rise to inaccurate reports are used as measurements of perception, then this can be regarded as an
Operationalization Bias
instance of operationalization bias. Indeed, cognitive penetration research has been characterized
by inaccurate reports ― that occur due to constant error in magnitude estimation ― as the measure
of perception. The tendency of the ‘constant error’ (or inaccurate) in magnitude estimation is a
result of the fuzziness in magnitude estimation (in psychophysical terms, due to the “interval of
uncertainty” [Urban, 1910] of magnitudes). So, the inaccurate verbal report ― generated by the
magnitude estimation ― operationalization of perception produces results that support the
hypothesis of cognitive penetration solely because this type of operationalization leads to
perceptual uncertainty, which in turn, permits confounding by non-perceptual
thought/cognitive/judgment factors (see Reddy, 2021 for more details). In this way, biased or
limited operationalization can result in false-positive support for postulations like cognitive
penetration.
Keeping a Check on Operationalization Biases
To improve science, some checks on researcher degrees of freedom are recommended, such as the
analysis of data through “new statistics” (e.g., Cumming, 2014), pre-registration of experiments
(e.g., Nosek et al., 2018), and regular attempts to replicate studies (e.g., Open Science
Collaboration, 2015). These suggestions for improving psychology ― that solely focus on
statistics and research reporting practices ― are incomplete as there are researcher degrees of
freedom at the level of theorization and operationalization of psychological constructs as well,
because of which the validity of findings can be in jeopardy. Accordingly, there exist many
psychological constructs whose theoretical validity is doubtful. Because the operationalization
biases are contingent on theory confirmation biases, rigorous theory-making concerning the
psychological phenomenon in question will ultimately check operationalization biases.
Thankfully, many researchers are proposing improvements in theory (particularly in terms of the
explanatory mechanisms involved) in addition to statistical and other methodological
For instance, Schimmack (2021) points out that “It is very unlikely that all hunches by psychologists lead to the
discovery of useful constructs. Given the current state of psychological science, it is rather more likely that many
constructs turn out to be non-existent. However, the history of psychological measurement has only seen development
of more and more constructs and more and more measures to measure this expanding universe of constructs. … The
proliferation of constructs and measures is not a sign of a healthy science. Rather it shows the inability of empirical
studies to demonstrate that a measure is not valid, a construct does not exist, or a construct is redundant with other
constructs. This is mostly due to self-serving biases and motivated reasoning of test developers” (p. 6).
As proposed by researchers like Peters (2021), confirmation biases themselves may (paradoxically) sometimes
improve theories, as opposing confirmation biases of (opposing) researchers may cancel each other out, and thus
improve theories at a scientific-community level.
Operationalization Bias
improvements (Eronen & Bringmann, 2021; Eronen & Romeijn, 2020; Fiedler, 2017; Gervais,
2021; Haig, 2021; Klein, 2014; Muthukrishna, & Henrich, 2019; Oberauer & Lewandowsky, 2019;
Schaller, 2016; Smaldino, 2019; Starns et al., 2019; van Rooij & Baggio, 2021). In this line, Scheel
et al. (2021) suggest researchers spend less time on hypothesis testing versus theory generation
since “by focusing primarily on confirmatory research and jumping straight to the hypothesis test,
psychologists too often neglect the groundwork that is necessary to ensure a sound link between
the test and the tested theory. … The statistical prediction at the end of a derivation chain is highly
specific. Without paying sufficient attention to the elements that link this prediction to the theory,
a hypothesis test has unknown validity” (p. 746).
Improvements in a theory that are specific to a construct can keep a check on
operationalization biases. A mature theory will guide a researcher in conceiving and designing all
possible operationalizations or accomplishing a methodological triangulation of a
construct/phenomenon (Fiske & Campbell, 1992; Kuorikoski & Marchionni, 2016). Suppose only
a select few of all possible operationalizations are employed in a field. In that case, a mature theory
will hint at what other alternative operationalizations had been missed to be employed.
Consequently, the validity of a phenomenon or construct can be established if it is found that all
possible operationalizations or a methodological triangulation of the construct yield mutually
consistent results. Accordingly, in the field of cognitive penetration, a fierce debate concerns
whether perception and thought/cognition are different processes (Beck, 2018; Block, 2022;
Firestone & Scholl, 2016; Kriegel, 2019; Mandelbaum, 2018; Montague, 2019; Nes, Sundberg, &
Watzl, 2021; Phillips, 2019; Pylyshyn, 1999; Stokes, 2021; Zeimbekis & Raftopoulos, 2015),
whether the accuracy of a “perceptual” report can distinguish between thoughts and perceptions
(Chudnoff, 2019; Ghijsen, 2016; Raftopoulos, 2019; Silins, 2016), and whether uncertainty
mediates the process of penetration in perception by cognitive/thought processes (Cermeño-Aínsa,
2021; Hohwy, 2017; Vance & Stokes, 2017; Zeimbekis, 2013, 2015). The experimental research
employing the exhaustive operationalizations of perception that are inspired by the mature theory
Similarly, Phaf (2020) suggest that researchers emphasize reading the literature and theorizing over hypothesis
testing; and researchers like Borsboom et al., (2021) chart out a general methodology to develop theories.
And, triangulation has to be contrasted with replication “because methodological triangulation employs multiple
independent methods, it can fairly be regarded as a restricted form of conceptual replication – restricted in the sense
that it deliberately alters methods, but not the other elements of a full conceptual replication (Haig, 2014). Note,
however, that direct replication, unlike conceptual replication, is not a method of robustness in the sense employed
here, because it secures agreement by straight repetition, rather than by convergence of evidence” (Haig, 2021, p._).
Operationalization Bias
of perception will ultimately resolve whether the construct of cognitive penetration is a false
positive. For instance, in an alternative or a triangulated operationalization of perception where the
participants can accurately compare or discriminate between the magnitudes that fall outside the
(psychophysical) ‘interval of uncertainty’ (Urban, 1910) [or outside of the range between the upper
and lower difference thresholds/limens], the evidence for cognitive penetration will not be found
(Reddy, 2021; Valenti & Firestone, 2019). Indeed, Valenti and Firestone (2019) experimentally
showed that if those magnitudes that are discriminable or distinguishable between themselves are
used as the experimental stimuli, and the act of perception is measured as the discrimination or
finding the odd-one-out between the dissimilar magnitudes or categories, then the cognitive
to estimate the magnitudes of “how yellowish is a banana” or “how reddish is a heart,” alternatively, experimenters
can ask “is B of the same colour as A or C?” or “is E of the same colour as D or F?” [Cognitive penetration concerning
B assumes that the knowledge or memory that bananas are yellow influences the perception of the colour of a grey
banana and concerning E the understanding of hearts being red influences the perception of the colour of an orange
heart]
In this way, the false-positive findings that result from the suboptimal research practices,
like the operationalization biases, can be kept in check through advances in corresponding theory
and the alternative operationalizations developed with the insights from the theory. In this spirit,
many researchers are encouraging “adversarial collaborations” (Kahneman, 2003) ― between
researchers with competing scientific views ― to develop theories (e.g., Cleeremans, 2022) and
experimental designs (e.g., Clark et al., 2022) aiming to falsify research findings, if at all they are
false.
Conclusion
Recent metascientific undertakings in psychology have reported many ― consciously or
unconsciously engaged ― suboptimal research practices by research psychologists; the
‘operationalization bias’ is one such suboptimal research practice that contributes to the
proliferation of false-positive findings in psychology. The improvements in the theory will keep a
Operationalization Bias
check on the operationalization biases by supplying the researchers the alternative
operationalizations for potential methodological triangulation.
Operationalization Bias