TESTING SDT IN WORKING MEMORY 1
A Critical Test of Signal Detection Theory in Visual Working Memory
Yiou He1, David Kellen2, and Henrik Singmann1
1 Department of Experimental Psychology, University College London
2 Department of Psychology, Syracuse University
Author Note
Yiou He and Henrik Singmann, Department of Psychology, University College London,
London, UK. David Kellen, Department of Psychology, Syracuse University, Syracuse, NY,
USA. David Kellen was supported by the National Science Foundation (NSF CAREER
Award, ID 2145308). Correspondence: Yiou He (yiou.he.23@ucl.ac.uk) or Henrik Singmann
(singmann@gmail.com).
TESTING SDT IN WORKING MEMORY 2
Abstract
Signal detection theory (SDT) provides a dominant framework for modelling recognition
memory judgments. Although specific SDT model variants have been extensively tested in
working memory, fundamental properties like random-scale representation and receiver
operating characteristic (ROC) symmetry have not been critically examined in this domain.
Here, we tested these core assumptions across two experiments using multi-alternative
forced-choice tasks. In Experiment 1 (N = 123), participants viewed displays of eight images
and made recognition judgments among varying numbers of alternatives. Results
demonstrated that these decisions satisfied theoretical constraints required by random-scale
representations, validating a key assumption of the broader SDT framework. In Experiment 2
(N = 304), we directly tested ROC symmetry by comparing performance between standard
recognition tasks and a modified version where participants selected novel rather than studied
items. This revealed systematic evidence for ROC asymmetry, mirroring patterns previously
observed in long-term memory. Together, these findings validate fundamental SDT properties
in visual working memory while revealing important characteristics shared with long-term
recognition memory. Our results establish crucial constraints for recognition models and
suggest common computational principles across memory systems.
Keywords: visual working memory, signal detection theory, critical tests, recognition
memory, receiver operating characteristic
TESTING SDT IN WORKING MEMORY 3
A Critical Test of Signal Detection Theory in Visual Working Memory
Visual working memory allows us to temporarily maintain and manipulate visual
information, playing a crucial role in cognitive tasks from visual search to change detection
(Cowan, 2017). A fundamental aspect of this memory system is our ability to recognise
whether we have recently seen a stimulus â€“ a process that relies on comparing a presented
item against representations held in memory. This recognition process in visual working
memory has been extensively studied using various paradigms, perhaps most commonly
using change detection tasks, where observers must decide if a test item is different from the
corresponding item in the memory set (e.g., Rouder et al., 2008).
Signal detection theory (SDT; Green & Swets, 1966; Kellen et al., 2021), since its
early applications to recognition memory (Egan, 1958), has served as a prominent framework
for understanding recognition decisions in visual working memory tasks (Robinson et al.,
2023; Schurgin et al., 2019). According to SDT, observers compare latent strength values
when making recognition decisions. Whereas SDT has been successfully applied to numerous
visual working memory phenomena (e.g., Ricker et al., 2017; Wilkens & Ma, 2004), the
foundational assumptions of SDT in the context of visual working memory warrant closer
examination.
Most studies applying SDT to visual working memory have focused on specific
parametric implementations, typically assuming a continuous memory resource. The most
prominent SDT variant in this domain is the equal-variance SDT model, which assumes
Gaussian (i.e., normal) distributions with equal variances for both signal and noise items. The
alternative to continuous-resource models is discrete-slots models, which assume a discrete
visual working memory capacity. Despite a number of influential attempts to tease these two
types of models apart empirically (e.g., Rouder et al., 2008; Donkin et al., 2014), this has
been a difficult task (Robinson et al., 2024). The problem is that both types of models provide
TESTING SDT IN WORKING MEMORY 4
a good account of the data typically arising in visual working memory tasks. Distinguishing
between both models thus requires considering exactly how certain auxiliary assumptions
interact with the modelsâ€™ performance. One way to summarise the current state is to concede
that both types of models are generally sufficient for explaining visual working memory data.
What is missing from the literature is a rigorous assessment of the modelsâ€™ necessity: Are
their core assumptions required for explaining visual working memory performance?
This distinction between sufficiency and necessity becomes crucial when we consider
that both continuous-resource models and discrete-slots models, despite their apparent
differences, belong to the general class of SDT models that share fundamental properties,
most importantly a random-scale representation of the memory information (Kellen et al.,
2021). These properties imply specific constraints on choice behaviour that should manifest
regardless of the particular parametric form the model takes. Rather than contrasting specific
implementations, a more principled approach for theory development in visual working
memory involves testing whether recognition decisions exhibit the basic signatures required
by any SDT model. Critical tests developed in the domain of long-term recognition memory
by Kellen et al. (2021) translate the theoretical constraints of random-scale representation
into testable empirical predictions, demonstrating how core properties of SDT models can be
tested independently of specific parametric assumptions.
The critical tests of Kellen et al. (2021) depart from typical change-detection tasks by
using a multi-alternative forced choice (m-AFC) task. In this approach, participants are
presented with m options drawn from two stimulus classes â€“ signal and noise â€“ with each test
trial containing one signal target alongside ğ‘š âˆ’ 1 noise lures. These tests provide a critical
method for examining the core assumptions of signal detection theory by systematically
investigating how recognition performance varies across different choice set sizes.
Mathematical work by Block and Marschak (1960) and Falmagne (1978) established that
TESTING SDT IN WORKING MEMORY 5
choice probabilities in forced-choice tasks are consistent with a random scale representation
if and only if they satisfy a specific set of order constraints, known as the Block-Marschak
(BM) inequalities. Because random scale representation is the defining property of all SDT
models, violations of these inequalities would rule out not just specific parametric
implementations but the entire class of SDT models as viable accounts of recognition
memory decisions.
This critical test approach has established SDT properties in long-term memory
(Kellen et al., 2021; McCormick & Semmler, 2023), but their applicability to visual working
memory cannot be assumed, given the potential differences in how information is maintained
and accessed across these memory systems (Cowan, 2008). Our study addresses this
fundamental gap by extending critical tests of the class of SDT models to the domain of
visual working memory. We examine whether recognition decisions in visual working
memory satisfy the BM inequalities by testing participants across different numbers of
alternatives in forced-choice recognition tasks. This approach allows us to evaluate whether
visual working memory judgments exhibit the systematic constraints predicted by random
scale representations. Rather than evaluating specific parametric implementations, our
approach examines whether the basic assumptions underlying all SDT models accurately
characterise how observers make recognition judgments about items held in visual working
memory. The results of these critical tests will not only constrain the space of viable models
for visual working memory recognition but also reveal whether the mechanisms underlying
recognition decisions differ fundamentally between visual working memory and other
memory systems. These findings will help determine whether a unified theoretical framework
can account for recognition processes across different memory domains or whether distinct
theoretical approaches are needed.
Experiment 1
TESTING SDT IN WORKING MEMORY 6
Methods
To test whether recognition decisions in visual working memory satisfy the BM
inequalities, we employed a standard m-AFC task with images of everyday objects under
signal-recognition instructions, with choice set size m ranging from 2 to 8. Each trial began
with a simultaneous study phase featuring eight items, followed by a test phase in which one
previously studied target item was presented alongside ğ‘š âˆ’ 1 novel foils. The memory set
size remained fixed at eight items to ensure that any observed differences in performance
across conditions were attributable solely to the decision-making process rather than
variations in memory fidelity (Robinson et al., 2023). Conformance with the BM inequalities
would demonstrate that the joint distribution of signal and noise items remains consistent
across alternative sets, thereby supporting a random-scale representation in visual working
memory. We selected a study set size of eight items to align with Experiment 2, which
employed another forced-choice task that required a larger set of studied items to be reused
during the test phase.
Participants
Participants were recruited via Prolific and received Â£2.25 as compensation for their
time. The initial sample comprised 124 participants aged 18 years or older, all residing in the
UK. Eligibility criteria also included having normal or corrected-to-normal vision, which was
essential given the visual nature of the experimental stimuli.
During data processing, one participant's data was excluded due to persistent technical
issues with the image display, which compromised the integrity of their responses.
Additionally, individual trials were screened for display timing accuracy. Two trials were
omitted because their study display durations fell outside a critical range of 4000ms Â± 250ms,
which could affect memory encoding and performance. This narrow window was chosen to
ensure consistent exposure time across all trials, as variations in stimulus presentation
TESTING SDT IN WORKING MEMORY 7
duration could introduce unwanted variance in memory performance. After these exclusions,
a total of 6,886 valid trials were retained for analysis from 123 participants.
Stimuli
Six hundred and seventy-nine images were selected from a repository (Brady et al.,
2008) of categorically distinct real-life objects to be used in this experiment. To ensure
unique experimental exposures for each participant, the order of images from this pool was
randomly shuffled, creating individual sequences of target images across trials. Each image
appeared exactly once as a study or as a test item throughout the experiment, preventing any
potential learning effects or interference from repeated exposures of the same images (i.e., the
only items that appeared exactly twice were the target items that were shown both in the
study set and then as well in the test set).
In the experiment display, all study and test images were presented in a circular layout
centred on the screen. The circleâ€™s radius was set to 35% of the smaller viewport dimension,
with images positioned at equal angular intervals (i.e., 45 degrees apart). The size of each
image was scaled to 15% of the smaller dimension of the viewport. On the test screens, the
target image was always displayed in a different position than on the study screen, and the
ğ‘š âˆ’ 1 novel foils were randomly assigned to the remaining locations.
Procedure
Participants provided informed consent before beginning the experiment. The
experiment consisted of one practice trial and 56 main experimental trials. The practice trial
used a 4-AFC test format with a separate set of images to familiarise the participants with the
task procedures. The main trials were organised into eight sequences, which were presented
consecutively without a break. Each sequence contained all seven choice set sizes (ğ‘š = 2 to
8 alternatives) presented in randomised order. Thus, in total, each participant worked on eight
TESTING SDT IN WORKING MEMORY 8
trials per choice set size m. Participants received no feedback on response accuracy
throughout the experiment.
Each trial followed a fixed structure: first, a screen displayed the current trial number,
followed by the memory set showing eight images simultaneously for 4000ms. This was
immediately succeeded by a 300ms visual mask (a dense grid of small, multicoloured squares
covering the study items' display area) and then a 400ms central fixation cross. Finally,
participants viewed an unspeeded test screen consisting of m items, one of which was the
target item that was repeated from the memory set. Participantsâ€™ task was to select the
repeated item using the mouse cursor by clicking on it. After their response, an inter-trial
interval was presented as a blank screen for 500ms before the next trial began.
Upon completing the 56 trials, participants provided demographic information and
completed a self-reported attention measure, which also served as an exclusion criterion. The
experiment concluded with a debriefing. Each experimental session lasted approximately 13
minutes.
Data Analysis
To test whether visual working memory recognition decisions satisfy the BM
inequalities, we employed a two-stage bootstrapping approach adapted from Kellen et al.
(2021). After calculating mean observed choice probabilities for different choice set sizes
across participants, we used quadratic programming to fit a model that minimised the
discrepancy between observed and predicted probabilities while satisfying BM inequality
constraints. To assess model fit, we computed G2-statistics and derived p-values through a
double bootstrapping procedure with 10,000 iterations. This procedure first generated
synthetic datasets from observed data (i.e., a non-parametric bootstrap), fitted them to BM
inequalities, and then created second-stage synthetic datasets from these fits (i.e., a
parametric bootstrap). We then fit the BM inequalities against the second-stage synthetic data
TESTING SDT IN WORKING MEMORY 9
and recorded the resulting G2-statistics to establish a null distribution of G2-statistics. By
comparing our observed G2-statistics against this null distribution, we could assess whether
recognition decisions in visual working memory violated the systematic constraints predicted
by the general class of SDT models.
Results and Discussion
set sizes and showed an overall pattern of regularity (i.e., monotonically decreasing
performance with increasing m). This suggests that participants maintained studied
information with sufficient fidelity to make systematic recognition decisions based on latent
memory information rather than relying on random guessing or arbitrary strategies. While we
observed a slight deviation from this monotonic pattern at ğ‘š = 4, this did not affect the
overall fit of the data to the BM inequalities. With ğº = 6.32 and ğ‘ = .123, the observed fit
is consistent with the expected distribution of GÂ²-values under the null hypothesis that the
BM inequalities hold.
Experiment 1 Results
mâˆ’AFC Performance Reconstructed Yesâˆ’No ROC
0 0
. .
1 1
Data
t 8 8
. .
e 0 BMI 0
6 6
. .
0 0
o i
t 4 4
r . .
o 0 0
r 2 2
P . .
0 0
BMI
BMIâˆ’LRM
0 0
. .
0 0
2 3 4 5 6 7 8 0.0 0.2 0.4 0.6 0.8 1.0
Choice Set Size (m) False Alarms
TESTING SDT IN WORKING MEMORY 10
Note. Left panel: observed and predicted performance in the m-AFC trials. The bars represent
the 95% confidence intervals for the observed data. BMI = Best-fitting predictions that
respect the Block-Marschak inequalities. Right panel: Reconstructed Yes-No ROC of the data
using the predicted forced-choice performance under the Block-Marschak inequalities with
and without likelihood-ratio monotonicity (BMI/BMI-LRM) constraints. In both panels, the
dashed lines delimiting the grey areas indicate chance-level performance.
The results from Experiment 1 demonstrate that visual working memory recognition
judgements conform to the systematic constraints predicted by random scale representations,
a defining property of SDT models. This finding extends beyond showing that specific
parametric implementations can account for recognition performance in visual working
memory â€“ it demonstrates that the basic architecture of SDT itself is necessary to characterise
how observers make these judgments.
Experiment 2
Whereas Experiment 1 provided evidence for random-scale representation in visual
working memory, a deeper question remains about how to characterise the memory evidence
that drives recognition decisions. Traditional approaches in the field have centred on
comparing the equal-variance SDT model against discrete-slot models, which are both part of
the class of SDT models which received support from Experiment 1. In Experiment 2, we test
a further property that both types of models share: both models predict receiver-operating
characteristic (ROC) curves that are symmetric relative to the negative diagonal.
ROC curves are traditionally constructed from change detection tasks by plotting hit
rates (correct identifications of changes) against false alarm rates (incorrect reports of
changes on â€œsameâ€ trials) across different response criteria (Brady et al., 2023). However,
this traditional approach faces several methodological challenges. The common practice of
manipulating response criteria through base rates or confidence ratings to produce an ROC
TESTING SDT IN WORKING MEMORY 11
makes specific assumptions that do not necessarily need to hold (BrÃ¶der & SchÃ¼tz, 2009;
Kellen & Klauer, 2015; Van Zandt, 2000). Similarly, participants often show limited
sensitivity to such response criteria manipulations, resulting in ROC curves that are either too
noisy or too restricted in range to meaningfully distinguish between competing models
(Robinson et al., 2024). Beyond these methodological issues, results based on model
comparisons based on ROCs are inherently limited â€“ they can only tell us which parametric
assumptions perform best, not whether these assumptions are necessary features of
recognition memory.
As an initial investigation of ROC symmetry in visual working memory, we
reconstructed a yes-no ROC function from the data of Experiment 1 following the conversion
method proposed by Kellen and colleagues (2021). In addition to the direct reconstruction
(BMI), we also performed a reconstruction that applied likelihood-ratio monotonicity
constraints (BMI-LRM), which captures the SDT principle that better-encoded memories
should be more easily discriminated from novel items. The resulting ROC exhibited
leftward peak in the upper region that aligns with findings from the broader recognition
memory literature (Dobbins, 2023; Jang et al., 2009; Killeen & Taylor, 2004).
Nevertheless, drawing conclusions about ROC symmetry based solely on this
reconstruction would be premature. A more rigorous approach examines ROC symmetry
through critical tests. Iverson and Bamber (1997) showed that ROC symmetry makes a strong
empirical prediction: performance should be equivalent between tasks requiring the selection
of a studied item among novel ones and tasks requiring the selection of a novel item among
studied ones. By comparing performance across choice set sizes for these two types of forced
choice tasks, we can therefore directly test ROC asymmetry. Any deviation from equal
performance for these two tasks when ğ‘š > 2 provides evidence for ROC asymmetry and
TESTING SDT IN WORKING MEMORY 12
against the assumption of equal-variance SDT and traditional discrete-slots models. Kellen et
al. (2021) performed this critical test in long-term recognition memory and found evidence
for ROC asymmetry. Here, we perform this test in visual working memory using an extended
design.
Methods
In this between-subjects experiment, participants were randomly assigned to one of
two forced-choice recognition conditions: the standard m-AFC task from Experiment 1 or a
modified m*-AFC task where participants selected a novel item presented among m âˆ’ 1
studied items. By comparing performance between these complementary tasks for m = 2 to 8,
we could evaluate ROC symmetry through behavioural signatures that must be present if the
equal-variance SDT model accurately characterises visual working memory recognition.
Participants
A separate group of 304 participants were recruited through Prolific and were
compensated Â£2.25 for their time. Of these, 147 were assigned to the m-AFC condition, and
157 were assigned to the m*-AFC condition. Following the same data quality criteria
established in Experiment 1, we examined study screen display times and excluded six trials
from three participants where display durations fell outside our pre-set range of 4000ms Â±
250ms. All other screening criteria remained identical to those reported in Experiment 1,
including requirements for normal or corrected-to-normal vision and completion of the
attention check measure.
Procedure
The general experimental procedure followed that of Experiment 1, with one key
modification to the practice phase. Instead of a single practice trial, participants completed
five practice trials with varying levels of m (m = [3, 8, 4, 5, 2], presented in fixed order).
During these practice trials, all participants received feedback on their responses â€“ a feature
TESTING SDT IN WORKING MEMORY 13
specifically added to ensure participants in the m*-AFC condition fully understood their task
requirements of selecting the new item. Following the practice phase, participants completed
56 main trials as in Experiment 1, with no feedback provided. The entire experimental
session lasted approximately 15 minutes.
Results and Discussion
Experiment 1, we tested the assumptions of random-scale representation. We found that
accuracy for all seven choice sizes was well above chance, with performance decreasing as
the choice size increased. The best-fitting BM inequalities aligned closely with the observed
data in both tasks, as indicated by the fit statistics (m-AFC: ğº = 1.25, ğ‘ = 0.780; m*-
AFC: ğº = 0.601, ğ‘ = 0.914). This replicates the results from Experiment 1 and shows
that random-scale representation also holds for m*-AFC tasks in which a new item has to be
selected.
Experiment 2 Results
mâˆ’AFC and m*âˆ’AFC Performance
Choice Set Size (m)
tcerroC
noitroporP
0.1
8.0
6.0
4.0
2.0
0.0
mâˆ’AFC
m*âˆ’AFC
BMI
2 3 4 5 6 7 8
TESTING SDT IN WORKING MEMORY 14
Note. The bars represent the 95% confidence intervals. BMI = Best-fitting predictions that
respect the Block-Marschak inequalities for each of the two conditions.
exceeded that of the m*-AFC task for all ğ‘š > 2, which provides evidence for asymmetric
ROCs in visual working memory. To further corroborate this pattern, we performed two
analyses. Before examining ROC asymmetry through performance differences between
conditions for ğ‘š > 2, we first needed to establish that any observed differences would not be
attributable to the change in task instructions between selecting old versus new items when
ğ‘š = 2, because differences in probe type (â€œoldâ€ versus â€œnewâ€) could potentially affect
performance independently of the underlying evidence distributions (Meyer-Grant & Klauer,
2023). Hence, we compared the proportions correct for ğ‘š = 2 using a repeated-measures
ANOVA and found no significant difference in performance, ğ¹(1, 302) = 0.26, ğ‘ = .608
(estimated marginal means for m-AFC: 0.83, 95% ğ¶ğ¼: [0.80, 0.85]; for m*-AFC:
0.82, 95% ğ¶ğ¼: [0.79, 0.84]). These findings provide support for the target-probe invariance
assumption at ğ‘š = 2, suggesting that any observed differences at larger m values can be
attributed to decision processes rather than differences in task instructions.
For ğ‘š = 3 to 8, we performed a mixed ANOVA to examine the difference in
accuracy between the two conditions. The analysis revealed a significant main effect of task
type, ğ¹(1, 302) = 19.73, ğ‘ < .001, with higher accuracy in the m-AFC condition, and a
significant main effect of the number of choice alternatives, ğ¹(5.80, 1750.89) =
170.12, ğ‘ < .001, indicating that accuracy decreased as m increased. In addition, a
significant interaction between task type and number of choices, ğ¹(5.80, 1750.89) =
5.05, ğ‘ < .001, showed that the difference in accuracy between m-AFC and m*-AFC tasks
became more pronounced at larger m. Pairwise comparisons confirmed that accuracy in the
m-AFC task was significantly higher than in the m*-AFC task, particularly from ğ‘š = 5
TESTING SDT IN WORKING MEMORY 15
onward. This pattern supports the presence of an asymmetric ROC, with accuracy in the m-
AFC condition consistently exceeding that of the m*-AFC condition at larger m. Thus,
Experiment 2 provides direct evidence for ROC asymmetry in visual working memory
without requiring the construction of ROCs using a manipulation of response criteria.
General Discussion
The development of scientific theories often follows a hierarchical structure: from
broad theoretical frameworks to specific model implementations, and finally to empirical
instantiations. However, this hierarchical relationship can sometimes obscure a crucial
distinction â€“ distinguishing between a theoretical framework's core assumptions are
necessary versus whether specific model implementations are sufficient for explaining the
data pattern. In the domain of recognition memory, this distinction becomes particularly
relevant when examining SDT, which has generated numerous model variants while
maintaining certain fundamental assumptions about how recognition decisions are made. Our
investigation focused on testing whether the fundamental assumptions of SDT are necessary
features of visual working memory recognition, moving beyond evaluating how well
particular SDT models fit the data to examine whether any viable account must possess
certain basic properties.
In two experiments we showed that recognition performance in visual working
memory satisfies the BM inequalities. This finding provides evidence for the most
fundamental property shared by all SDT models â€“ the existence of a random scale
representation â€“ that recognition judgements are based on a joint distribution of latent
strength values for signal and noise items (Kellen et al., 2021). These results indicate that
SDT models are not only sufficient, but necessary for describing visual working memory.
This finding provides support for all models that fall into the broad category of the SDT
model class encompassing both continuous-resource and discrete-slots models.
TESTING SDT IN WORKING MEMORY 16
In Experiment 2, we implemented an additional critical test that allowed us to
constrain the properties that an SDT model needs to have in the domain of visual working
memory. In particular, we tested ROC symmetry by comparing performance across two types
of forced-choice tasks and found evidence for ROC asymmetry. The results of Experiment 2
thereby rule out all models that predict symmetric ROC, including the models that are most
commonly used for describing change-detection performance. For example, both the equal-
variance Gaussian SDT model and the commonly used discrete-slots variants predict
symmetric ROCs (e.g., Donkin et al., 2014). Our results are in line with the literature on long-
term recognition memory where the necessity of models predicting asymmetric ROCs, such
as unequal-variance SDT or discrete-state models with two separate memory states, has long
been recognised (e.g., Yonelinas & Parks, 2007; Kellen et al., 2021).
These findings about core SDT properties in visual working memory have
implications for our understanding of memory systems more broadly. In line with Schurgin et
al. (2020), our findings suggest a reconceptualization of the relationship between working
memory and long-term memory through the lens of SDT. Schurgin and colleagues showed
that once psychophysical similarity is properly accounted for, seemingly disparate data
patterns from working memory and long-term memory can be explained using the same
underlying SDT framework. By replicating central results from Kellen et al. (2021), who
investigated long-term memory, our work provides complementary evidence for this
unification through a different approach demonstrating that critical properties of SDT
manifest in both working memory and long-term memory recognition. Together this indicates
that these memory systems rely on fundamentally similar decision processes.
Our results also resolve a debate about the assumptions underlying critical tests of
ROC asymmetry. Meyer-Grant and Klauer (2023) expressed concern that the mnemonic
information accessed during recognition decisions might fundamentally change depending on
TESTING SDT IN WORKING MEMORY 17
whether participants are searching for old versus new items. This would challenge critical
tests that assume any performance differences between selecting old versus new items reflect
properties of the underlying evidence distributions. However, as Kellen and Singmann (2022)
noted, this concern could be directly tested by comparing performance in 2-AFC and 2*-AFC
tasks. Our Experiment 2 implemented this test, finding equivalent performance between both
tasks and suggesting no fundamental difference in memory access based on probe type. The
subsequent divergence at larger m values follows the pattern expected from ROC asymmetry,
without needing to invoke probe-dependent changes in memory access.
Our departure from traditional change detection paradigms might raise questions
about comparability with existing literature. However, this methodological choice strengthens
rather than limits our conclusions. Change detection tasks, despite their prevalence, introduce
significant measurement ambiguity through their reliance on combining hit rates and false
alarm rates into unified performance measures (Williams et al., 2022). These measures rest
on often unverified assumptions about memory signal distributions, potentially leading to
qualitatively incorrect conclusions about how experimental manipulations affect memory
(Brady et al., 2023). Our forced-choice methodology circumvents these issues by providing
direct measures of recognition performance that do not require combining multiple response
types.
This methodological critique leads to broader implications for the field. While change
detection tasks remain valuable for studying rapid visual updating and comparison processes,
their role in investigating the fundamental nature of memory representations may need to be
reconsidered. These tasks might be better suited for exploratory investigations or applied
research contexts where precise measurement of underlying memory strength is less critical
than ecological validity. Meanwhile, our results suggest that forced-choice paradigms,
particularly when combined with critical tests that make parameter-free predictions, offer a
TESTING SDT IN WORKING MEMORY 18
more rigorous approach for testing the theoretical properties of visual working memory. This
opens new avenues for research design â€“ future studies might consider adapting other
established memory paradigms, such as continuous report procedures (Wilken & Ma, 2004),
to incorporate similar critical test logic.
Looking ahead, our findings open several promising avenues for future research. First,
the demonstration that core SDT properties hold in visual working memory using objects
creates opportunities for investigating how these properties might scale or adapt across
different types of visual content and task demands. Second, while our study deliberately
avoided item repetition to maintain stable memory strength distributions, future work should
examine how interference and intrusion effects â€“ hallmark features of working memory
(Oberauer & Lin, 2017) â€“ interact with these core SDT properties. As Kellen et al. (2021)
noted, the BM inequalities framework naturally extends to "enriched scenarios" with multiple
classes of items. This flexibility could allow researchers to incorporate previously-seen items
as a distinct stimulus class alongside novel foils, enabling critical tests of how interference
affects random-scale representations in working memory. Such extensions would help bridge
the gap between controlled experimental tests of SDT properties and the more complex,
context-dependent nature of working memory in ecological settings.
TESTING SDT IN WORKING MEMORY 19