Reduced confidence in situations of increased
observational learning
1,2
David Aguilar-Lleyda
RIKEN Center for Brain Science, Wako, Saitama, Japan
Present address: Vision and Control of Action (VISCA) Group, Department of Cognition,
Development, and Psychology of Education & Institute of Neurosciences, University of
Barcelona, Barcelona, Catalonia, Spain
E-mail: aguilarlleyda@gmail.com
ABSTRACT
Humans can learn about the outcomes of available choice alternatives via their own choices,
but also by observing others choosing. As agents learn, they should become more confident
in knowing the best alternative. However, here we show that such confidence is lower in
situations where observational learning typically happens, compared to contexts of
predominant individual learning. Our first experiment let participants decide between learning
by choosing between reward alternatives and by observing another agent‚Äôs choices.
Introducing contexts with frequent reward loss made participants both observe more and
report lower confidence in knowing which alternative delivered higher reward, despite more
frequent choices of this better alternative. To disentangle whether reduced confidence was
due to frequent losses or to more observation, we conducted two follow-up experiments where
reward and choice agency were manipulated independently. Both factors were found to
independently reduce confidence. Our results illustrate how confidence based on the
alternatives‚Äô value is reduced by the negative outcomes that often accompany observation,
and by an agency component derived from fewer choices being made, thus offering a
multifactorial account of the formation of confidence during observational learning.
INTRODUCTION
When first introduced to different choice alternatives, agents are usually uncertain about which
alternative may deliver better reward outcomes. This uncertainty can be reduced through
individual learning, where agents repeatedly select the alternatives and experience their
outcomes. Alternatively, agents can learn by observing the outcomes of others' choices. A
drawback of observational learning is that it typically prevents agents from the immediate
reward that would follow their own choices. However, observing still offers some advantages
that sometimes make it the preferred way to learn in social animals. First, observation spares
agents the initial trial-and-error process of sampling alternatives. This is particularly beneficial
when some options may result in adverse outcomes, making observation a safer strategy
(Chamley, 2003; Coolen et al., 2003; Dewar, 2004; Kendal et al., 2004; Webster & Laland,
2008; Galef, 2009; Laland, 2004). Second, observing skilled or experienced peers can
accelerate learning, as these individuals are more likely to display choices of the best
alternatives (Rendell et al., 2010).
In humans, uncertainty-driven learning appears to involve metacognitive representations.
Studies using explicit confidence reports have linked exploration via individual choices to low
confidence in the value of available alternatives (Boldt et al., 2019). Confidence reports on
value-based choices reflect the difference in estimated value among alternatives (De Martino
et al., 2013; Lebreton et al., 2015), but are also affected by a series of contextual and
egocentric biases (Lebreton et al., 2019; Chambon et al., 2020; Ting et al., 2020; Salem-
Garcia et al., 2023). However, most research on the factors influencing confidence has
focused on situations where humans learn through their own choices, leaving a gap in
understanding how confidence may be differently shaped when humans can also learn
through observation.
Effects of observational learning on confidence could be situational, a reflection of the contexts
where agents observe more or less. As mentioned earlier, observation is often favored to avoid
negative outcomes, but the presence of such negative outcomes has separately been found
to affect metacognition too. Indeed, in human studies of non-social reinforcement learning,
participants have reported lower confidence in their decisions in contexts involving reward loss,
compared to contexts where reward outcomes are positive, even when the quality of choices
in both situations is similar (Lebreton et al., 2019; Ting et al., 2020; Salem-Garcia et al., 2023).
Thus, we expect that the presence of losses should simultaneously produce more frequent
observational learning and lower confidence in value-based choices.
Beyond loss-related effects, confidence during observational learning may also be influenced
by choice agency, which significantly shapes cognitive computation and subjective experience
(Haggard, 2009; Haggard & Chambon, 2012). Research has shown that individuals exhibit
greater confidence in decisions linked to their own actions, both for perceptual (Charles et al.,
2020) and value-based (Chambon et al., 2020) tasks, possibly through self-reinforcement
mechanisms (Zajkowski & Zhang, 2021; Ptasczynski et al., 2022). Since increased
observation typically implies fewer own choices, we should expect people to be less confident
in the value of the alternatives when obtaining information about them through observed
choices.
While both loss- and agency-related factors may contribute to reduced confidence in contexts
of heightened observational learning, no studies have simultaneously examined their
simultaneous effects. To address this, we designed a series of two-armed bandit experiments.
Participants chose between two alternatives with rewards drawn from independent Gaussian
distributions with different means but identical variance. Learning about the value of these
alternatives occurred either through individual choices or by observing another agent. To
compare the effects of contexts with frequent and rare observation, in our initial experiment
participants freely chose whether to learn by making their own decisions or by observation,
while contextual factors (presence of losses and observee expertise) were manipulated to
encourage varying levels of observation. To dissociate between the origin of differences we
found in confidence, in follow-up experiments the mode of learning (observation or personal
choice) was imposed. Across experiments, participants repeatedly judged which alternative
delivered higher average reward, and rated their confidence in that judgment. Interestingly,
this confidence was lower in situations with losses, as well as when participants made less
choices (observed more), despite their choice and judgement accuracy being as good or better.
Our findings reveal two distinct pathways through which observational learning contexts
reduce confidence in value-based choices: the influence of losses and the absence of agentic
control.
EXPERIMENT 1
Our first experiment served as an initial step in exploring the relationship between learning
mode and confidence. We designed a series of contexts in where individuals would freely
engage in individual and observational learning to a different extent, and examined whether
this impacted confidence in the value of the alternatives. Rather than imposing a specific
learning mode, participants decided whether to learn through their own choices (choice trials)
selected between two color-coded decks of cards and received points drawn from the reward
distribution associated with the chosen deck. In observation trials, participants (observers)
watched another agent (the observee) select a deck and observed the reward derived from
the choice, though this reward did not contribute to their final earnings. Each participant
completed 32 blocks, with each block consisting of 12 trials. To create varying contexts with
differing levels of individual and observational learning, we manipulated two variables across
blocks. First, whether general reward given by the alternatives was high or low, with
alternatives in low reward blocks being more likely to deliver negative reward. Second,
observee experience: at the start of each block, we told participants that the observee had
already completed either 0 (inexperienced) or 10 (experienced) choices between the current
alternatives. Participants were told the observee was always the same individual, whose
choices had been recorded in a previous session. However, the observee was actually a
simulated agent employing a value-learning strategy, progressively favoring the deck with the
highest estimated value (see Methods). After four randomly selected trials per block,
participants were prompted to report their confidence, as a percentage, that a given deck had
0.75
0.5
0.25
HR, E HR, I LR, E LR, I
Condition
sequence of a trial. First, participants decided whether to choose or observe. In observation
trials participants saw another agent‚Äôs choice between two decks, and were given feedback
on the reward delivered by that choice, without that reward affecting their final payoff. In choice
trials participants picked one of the two decks and saw their choice‚Äôs reward, which contributed
towards their final payoff. Four times per block, at the end of a trial participants had to use a
confidence scale to simultaneously judge which of the two decks delivered higher average
reward and give their confidence on that judgment. Boxes on the right summarize the variables
manipulated across blocks. ùúá , ùúá represent the means of high and low value decks,
!" #"
respectively, while ùúé , ùúé represent their standard deviations B. Proportion of trials where
!" #"
participants decided to observe, per condition. C. Same as B, but across trials. D. Proportion
of high value deck choices per condition, only taking into account choice trials. E. Deck
judgment accuracy per condition, defined as the proportion of confidence judgments where
participants gave their rating within the half of the scale corresponding to the high value deck,
thus identifying such deck as that giving higher reward on that block. F. Absolute confidence,
seciohc
noitavresbo
.porP
0.75
0.5
0.25
1 2 3 4 5 6 7 8 9 10 11 12
Trial
seciohc
noitavresbo
.porP
0.75
0.5
0.25
HR, E HR, I LR, E LR, I
Condition
seciohc
kced
eulav
hgih
.porP
0.75
0.5
0.25
HR, E HR, I LR, E LR, I
Condition
kced
eulav
hgih
ni
.fnoc
erom
.porP
HR, E HR, I LR, E LR, I
Condition
ecnedfinoc
etulosbA
REWARD
OBSERVATION TRIAL
High reward Low Reward
Œº Œº Œº Œº
PRESS SPACE hv= 30 lv = 20 hv= 5 lv = -5
OBSERVATION / CHOICE NEXT CONFIDENCE RATING œÉ œÉ
+31 hv= lv = 15
DECISION (4 times per block)
How confident are YOU that,
OBSERVEE EXPERIENCE
on the current block, one
deck gives on average more
Experienced observee Inexperienced observee
OBSERVE CHOOSE
points than the other?
(10 trials of experience) (0 trials of experience)
76%
NEXT
-16 BLOCK TYPES
HR, E: high reward, HR, I: high reward,
PRESS S PRESS D
experienced observee inexperienced observee
LR, E: low reward, LR, I: low reward,
CHOICE TRIAL
experienced observee inexperienced observee
from 50 to 100, per condition. For B, D, E and F, small dots connected with lines depict
individual participants, with the density of their distribution being represented by the violins.
Big dots with error bars depict across-participant averages with their respective standard error
of the mean. For C, error bars depict standard error of the mean, with their point of intersection
with the lines denoting across-participant averages. Note that this summary data is for
visualization purposes only, as our statistical analyses rely on LMMs using trial-to-trial data.
Methods
Participants
not recorded, but we used Prolific‚Äôs feature to ensure a balanced sample with respect to
gender. Remuneration ranged between ¬£10 and ¬£14, depending on the final accumulated
points. 7 participants were excluded after a t-test indicated that their deck choice performance
(choices of the high value deck) was non-significantly greater than chance. All analyses in the
results section are based on the 43 remaining participants.
Apparatus and stimuli
The experiment was coded on JavaScript using jsPsych (De Leeuw, 2015), version 6.1.0. It
was presented online on the participants‚Äô internet browser. Experiment presentation and data
Procedure
Structure of a trial
Participants completed 32 blocks, each consisting of 12 trials. Each trial required drawing a
card from either a blue or pink deck. At the start of the trial, participants chose between making
the decision themselves (choice trial) or observing another agent, referred to as the observee,
making the choice (observation trial). To make this selection, the screen displayed the options
‚ÄúCHOOSE‚Äù and ‚ÄúOBSERVE‚Äù in boxes on opposite sides of the screen, with the sides
counterbalanced across participants. Participants clicked on the box corresponding to their
preferred type of trial using the mouse. Subsequently, a blue and a pink card appeared side
by side, face-down. In choice trials, participants selected the left or right card by pressing the
‚ÄúS‚Äù or ‚ÄúD‚Äù key on their keyboard. In observation trials, participants pressed the spacebar to
see the observee‚Äôs choice. The chosen card was outlined in white for 500 ms and then
revealed a reward number, positive or negative, on a green or red background, respectively.
This reward was either added to or subtracted from the participant's cumulative score. The
unchosen card remained face-down, preventing feedback on foregone choices. Participants
could take as much time as needed to click a "NEXT" button to proceed to the next trial. Within
each block, rewards for the two decks were drawn from Gaussian distributions, with one deck
consistently having a higher mean reward (high value deck) than the other (low value deck).
Reward and observee experience conditions
The experiment implemented a 2x2 factorial design, with each block assigned to a condition
resulting from the crossing of two variables: reward and observee experience. The reward
variable referred to the overall level of reward within a block, which was either high or low,
although the high value deck consistently offered higher average reward than the low value
deck. In high reward blocks, the mean rewards for the high and low value decks were 30 and
20 points, respectively, while in low reward blocks, the mean rewards were 5 and -5 points.
For both decks and across both reward conditions, rewards were sampled from a Gaussian
distribution with a standard deviation of 15 points. To ensure no extreme values appeared,
any reward sampled outside three standard deviations from the mean was resampled. The
reward manipulation was designed to increase the frequency of losses (negative rewards) in
the low reward condition, which was expected to encourage participants to observe more
frequently.
The second variable, observee experience, referred to the number of trials the observee had
completed before participants began a block. In the experienced observee condition, that
number of trials was 10. Consequently, if participants chose to observe on their trial 1, they
would see the observee‚Äôs trial 11. In the inexperienced observee condition, both participant
and observee started the block simultaneously. To prevent participants from gaining access
to their future potential outcomes in experienced observee trials, reward samples within a
block were distinct for the participant and the observee. The observee experience
manipulation was intended to increase observation rates in the experienced observee
condition.
Participants were informed of the reward condition (high or low) and the observee experience
condition (experienced or inexperienced) at the start of each block. Throughout the block, the
reward level and the trial numbers for both the participant and the observee were displayed
on the screen. At the end of each block, participants were shown the total number of points
they had earned.
Two additional elements were counterbalanced across blocks. First, the color of the decks
(blue or pink) associated with the high and low value decks was alternated. Second, the side
of the screen (left or right) on which each deck appeared was varied. The experiment consisted
of 32 blocks, resulting from including two blocks for each combination of color mapping, screen
side mapping, reward condition, and observee experience condition.
Confidence ratings
Confidence ratings were collected four times per block, following either observation or choice
trials. Participants were presented with the prompt: ‚ÄúHow confident are YOU that, on the
current block, one deck gives on average more points than the other?‚Äù A horizontal scale
appeared below the prompt, consisting of a bar divided into two halves, one blue and the other
pink. The colors of the scale corresponded to the block‚Äôs color-side mapping, with the intensity
of the colors decreasing from bright at the extremes to white at the center. When participants
hovering their mouse cursor over the scale, an integer appeared, ranging from 50 at the center,
representing total uncertainty regarding which deck provided a higher average reward, to 100
at either extreme, indicating complete confidence in the corresponding deck. Participants were
required to position the cursor on the half of the scale representing the deck they believed
offered greater average reward and to click at the point that reflected their level of confidence.
To capture confidence ratings at different points within a block, these ratings were distributed
across four trial bins: 1‚Äì3, 4‚Äì6, 7‚Äì9, and 10‚Äì12. Each rating occurred after a trial number
within one of these bins, and across blocks, each trial number was sampled approximately
evenly. This one-click rating, then, gave information on the correctness of the deck judgment
and on absolute confidence in the judgment. Importantly, confidence ratings were designed to
assess participants' belief about which deck provided the higher average reward overall, rather
than their confidence in having chosen the best deck on the preceding trial. This was so
because we expected participants to make some choices to maximize immediate reward
(exploitation), but also some to gather information about the value of an alternative
(exploration), so a deck could be chosen even if not believed to be that with the biggest payoff.
Defining observee choices
Participants were told they would have the opportunity to observe the choices of a human
participant that had previously completed some choice-only blocks. The identity of this
observee was not disclosed, but participants assigned them an avatar and name. This
observee was actually a simulated agent whose choice behavior captured basic traits thought
to be shared by humans. The first of these traits was value learning. The value for the high
value deck h on trial t was simply the averaged reward r experienced after choosing that deck
across the trials so far on that block:
ùë£ = % ùëü (1)
!,# #
#$%
The same was applied to define value for the low value deck l. For simplicity, and to avoid
assumptions, no prior value was assigned to any deck at the start of the block. The second
trait we gave to our simulated agent was early exploration of both decks, transitioning to
exploitation, with more choices of the deck associated with the highest value as trials went by.
This was achieved with a softmax choice function, which determined the probability of
choosing the high value deck on trial t:
!,#
(2)
ùëÉ(ùëê * =
!,# & &
!,# $,#
ùëí + ùëí
‚Äô ‚Äô
The temperature parameter œÑ captures the stochasticity of choices. We made œÑ = 10, which in
simulations of the experiment‚Äôs context led to around 70% choices of the high value deck
around trial 10. This ensured that, in the experienced observee condition, participants could
usually start observing significantly more choices of the high value deck. Since no prior value
was assigned for each deck, in early trials observees chose based on a coin flip (0.5 probability
of choosing either deck) until both decks had been chosen at least once, and choices could
already be made based on experienced reward.
Payoff
Participants were informed that their remuneration for completing the experiment would
consist of a base payment of ¬£8, provided their data demonstrated meaningful engagement
with the task and choices consistent with learning. In addition to the base payment,
participants could earn a variable bonus, bringing the total possible payoff up to ¬£14. The
calculation of such bonus, not disclosed to participants, was based on the number of points
accumulated during the task. Specifically, the bonus was scaled according to a benchmark
derived from the expected performance of a hypothetical high-performer who chose the
higher-value deck on 75% of choice trials, with an overall preference for the optimal strategy
75% of the time. From this benchmark, the performance of a hypothetical participant that
chose randomly both between observation and choice trials and between blue and pink decks.
The resulting value served as the denominator in a formula that scaled the bonus. The
numerator was the difference between the maximum planned payoff (¬£14) and the minimum
(¬£10). This scaling factor was then multiplied by the participant‚Äôs accumulated points, yielding
a final bonus amount between ¬£10 and ¬£14, rounded up to the nearest pound. While
confidence ratings were not directly tied to monetary rewards, participants were explicitly
informed that their data would undergo scrutiny. Specifically, systematic or random use of the
confidence scale‚Äîsuch as repeatedly selecting the same value or side without apparent
consideration‚Äîwould result in forfeiture of payment. This lack of economic incentivization is
unlikely to have influenced our confidence results, as prior research has shown similar
confidence ratings regardless of whether they are monetarily enforced (Lebreton et al., 2019).
Instructions and practice blocks
Before the main part of the experiment participants read the instructions, where they were
familiarized with different aspects: the procedure of a trial, the fact that they would only keep
the reward they earned in choice trials, how to give confidence ratings, the different conditions
a block could belong to, the fact that within a block a deck always gave higher average reward
than the other, and the payoff scheme. Participants were also encouraged to accumulate as
many points as possible.
After the instructions, participants completed four practice blocks of 12 trials each. On the two
first blocks participants simply saw the observee choosing. This helped participants familiarize
themselves with the observee‚Äôs choice dynamics, mainly exploration of both decks leading to
more choices of the high value deck. The last two practice blocks were like those in the main
part of the experiment. Within each pair of practice blocks participants were presented once
each of the two reward conditions, in random order. On the first pair of blocks, participants
always observed from the observee‚Äôs first trial, and on the second pair they observed an
experienced observee and an inexperienced observee once, in random order.
Behavioral Models
The primary aim of our behavioral analyses was to assess the impact of experimental
manipulations on several dependent variables. Due to the hierarchical structure of the data
and unbalanced factor levels (e.g., differing numbers of observation trials across conditions),
we employed Linear Mixed Models (LMMs), building separate models for each dependent
variable. First, to verify whether our design produced conditions with varying levels of
observation, we examined whether participants chose to observe or make their own choices
on each trial. Next, we assessed how these conditions influenced three dependent variables.
First, in trials where participants made their own choice, whether the high value deck was
selected. Second, deck judgment accuracy: that is, whether a confidence rating had been
given within the half of the scale corresponding to the high value deck, meaning the participant
was more confident in that deck giving more reward, and thus correctly identifying it as the
best alternative. When using this variable, we excluded trials with a rating of 50, that
manifested no preference for either deck. Finally, our main variable interest, absolute
confidence, indexed by the 50-to-100 reported integer, irrespective of the half of the scale the
rating had been given within.
For each dependent variable, we aimed at a full model including fixed effects for the factorial
design variables, which in our first experiment were reward level (high vs. low) and observee
experience (experienced vs. inexperienced), along with their interaction. Trial number,
centered around the sample mean, was included as a numeric fixed effect to control for within-
block learning. Random effects included participant ID (random intercept) and the factorial
design variables (random slopes, additive without interactions). If convergence issues arose,
we simplified the models by first removing the interaction between fixed effects, treating them
additively. Persistent issues were addressed by running separate models for each predictor,
excluding the non-tested variable from both fixed and random effects.
The statistics we report are based on running an ANOVA on the LMM. When predicting a
binary dependent variable (observation choices, high value deck choices and deck judgment
accuracy) we fitted a logistic regression by using the mixed function of the afex package
(Singmann et al., 2023). In the main text we report the given œá statistic with its associated p-
values, calculated via Likelihood Ratio Test. The single value between brackets corresponds
to the degrees of freedom of the model. When predicting (continuous) absolute confidence we
used the anova function within the lmer function of the lme4 R package (Bates et al., 2015).
We report the F statistic, degrees of freedom and p-values, calculated through Satterthwaite's
method implemented in the lmerTest package (Kuznetsova et al., 2017). Non-significant
effects are only accompanied by their p-value.
Below are the final specifications of the models referred to in the Results section of Experiment
1. Our first two models try to predict decisions to observe on every trial. Following the approach
described above, and encountering convergence problems with both the full model and the
first simplification, we ran two separate models, where the main predictors were reward
condition (M1.1.1.) and observee experience condition (M1.1.2.):
M1.1.1.: observation_chosen ~ reward_condition + trial_number + (reward_condition |
participant_id)
M1.1.2.: observation_chosen ~ observee_experience_condition + trial_number +
(observee_experience_condition | participant_id)
We then ran three full models predicting choices of the high value deck (M 1.3.), deck
judgment accuracy (M 1.4.) and absolute confidence (M1.5.):
M1.2.: high_value_deck_chosen ~ reward_condition * observee_experience_condition +
trial_number + ((reward_condition + observee_experience_condition) | participant_id)
M1.3.: deck_judgment_accuracy ~ reward_condition * observee_experience_condition +
trial_number + ((reward_condition + observee_experience_condition) | participant_id)
M1.4.: absolute_confidence ~ reward_condition * observee_experience_condition +
trial_number + ((reward_condition + observee_experience_condition) | participant_id)
Results
We started by modelling the frequency of observation as a function of reward magnitude
(Model M1.1, see Methods) and observee experience (Model M1.2), while also controlling for
trial number. In its respective model, we found a significant main effect of reward (œá (6), 35.16,
explained by participants observing to protect themselves from potential losses. While in the
other model there was no significant main effect of observee experience (p = .17), we found
that participants observed significantly more in the experienced observee blocks when reward
was high (œá (6), 10.17, p = .001). We also found effects of trial number, with participants
observing less as trials went by (reward model: œá (6), 1315.91, p < .001; observee experience
model: œá (6), 1055.47, p < .001), showing that, congruent with learning, participants were
Overall, manipulating each of our two variables created conditions with different levels of
observation, although the reward manipulation was much more successful.
Next, we analyzed the effects of the predictors derived from our experimental manipulations
on choice and confidence measures (models M1.2, M1.3, M1.4). Choices of the high value
deck (that is, that with higher generative mean) were significantly more frequent in the low
neither observee experience (p = .28) nor the interaction between the two factors (p = .24).
Importantly, because trial number had been controlled for, the reward effect was not simply
due to higher initial observation making choice trials in low reward blocks typically belong to
later stages within a block, where due to learning more choices of the high value deck should
be expected (see also Supplementary Material 1). Consistently with choices, deck judgment
accuracy (whether confidence for the better deck was over or under 50%) was marginally
observee experience (p = .17) nor their interaction (p = .46). If confidence tracked the better
performance participants had in low reward blocks, such confidence should be higher in that
condition. However, absolute confidence (the absolute value of confidence ratings, ranging
from 50 to 100; Fig 1F) went in the opposite direction, being significantly higher in the high
observee experience (p = .91) or the interaction term (p = .76). All three choice and confidence
measures were also positively associated with trial number (high value deck choices: œá (11),
249.97, p < .001; deck judgment accuracy: œá (11), 83.50, p < .001; absolute confidence: F(1,
5375.44), 622.07, p < .001), indicating that participants performed better and became more
confident as they acquired more information.
Discussion
In Experiment 1 we found that low reward blocks, where participants observed more, were
related to lower confidence in knowing the best alternative, despite choosing such alternative
more often, and identifying it with higher accuracy. Why would such a discrepancy occur? One
possibility is that lower reward and / or frequent losses made participants less confident in
their judgments. This is consistent with studies documenting valence biases in value-based
learning (Lebreton et al., 2019; Ting et al., 2020; Salem-Garcia et al., 2023), so we will call
this the valence hypothesis. Interestingly, valence could also be responsible for the better
choices and deck judgment accuracy in low reward blocks, in line with the loss attention
literature (Yechiam & Hochman, 2013a, 2013b), that identifies more attentiveness, and
consequently better performance, in situations of likely losses. Besides valence, another
explanation for the difference between conditions is that participants felt more confident in
high reward blocks because they made more choices of their own, independently of whether
that led to more accurate beliefs or not (agency hypothesis).
EXPERIMENT 2
Since in our first experiment more observation was always tied to lower reward, the behavioral
results could not disentangle between the effects of reward valence and agency. In order to
arbitrate between these hypotheses, we designed a second experiment where general level
of reward and frequency of observation were dissociated by design. The main innovation of
In what we called observation + choice blocks, we randomly interleaved observation and
choice trials, with roughly half of the trials belonging to each type (see Methods). In only choice
blocks, all trials were choice trials. As in Experiment 1, across blocks we also manipulated the
general level of reward, giving rise to high reward and low reward blocks. However, given the
limited success of the manipulation, we did not vary the experience of the observee: within a
block, participants and observee always had the same trials of experience (akin to the
unexperienced observee condition). With this new task design, finding lower confidence for
low reward than for high reward blocks but no difference in confidence between agency
conditions would lend support for the valence hypothesis. Alternatively, lower confidence for
observation + choice than for only choice blocks but no difference between reward conditions
would offer evidence for the agency hypothesis. Finally, should we find lower confidence for
both low reward and choice only blocks, this would simultaneously support valence and
0.75
0.5
0.25
HR, O+C HR, C LW, O+C LR, C
Condition
sequence of a trial, which was imposed by design to be an observation or a choice trial.
Otherwise, choices and confidence ratings followed the same structure as Experiment 1. The
right boxes summarize the variables manipulated across blocks. First, reward, as in
Experiment 1. Second, choice, which determined whether the block included observation trials
or not. Crossing both two-level variables led to four possible types of blocks. B. Schematics
depicting the predictions the different hypothesis would make regarding absolute confidence
across block types. Confidence is shown in arbitrary units. C. Proportion of high value deck
choices per condition, only taking into account choice trials. D. Deck judgment accuracy per
condition, defined as in Experiment 1. E. Absolute confidence, from 50 to 100, per condition.
For C to E, small dots connected with lines depict individual participants, with the density of
their distribution being represented by the violins. Big dots with error bars depict across-
participant averages with their respective standard error of the mean.
seciohc
kced
eulav
hgih
.porP
0.75
0.5
0.25
HR, O+C HR, C LW, O+C LR, C
Condition
kced
eulav
hgih
ni
.fnoc
erom
.porP
HR, O+C HR, C LW, O+C LR, C
Condition
ecnedfinoc
etulosbA
valence hypothesis agency hypothesis valence + agency hypotheses
HR, O+C HR, C LW, O+C LR, C HR, O+C HR, C LW, O+C LR, C HR, O+C HR, C LW, O+C LR, C
Condition
etulosbA
ecnedfinoc
REWARD
OBSERVATION TRIAL High reward Low Reward
Œº Œº Œº Œº
hv= 30 lv = 20 hv= 5 lv = -5
PRESS SPACE
œÉ œÉ
hv= lv = 15
NEXT
CONFIDENCE RATING
+11
(4 times per block)
How confident are YOU that, CHOICE AGENCY
on the current block, one
Observation + choice Only choice
deck gives on average more
points than the other?
‚àº 6 observation + 6 choice 12 choice trials
trials (randomly interleaved)
79%
NEXT
+17
BLOCK TYPES
PRESS S PRESS D
HR, O+C: high reward, HR, C: high reward,
observation + choice only choice
CHOICE TRIAL LR, O+C: low reward, LR, C: low reward,
observation + choice only choice
Methods
Participants
50 new participants were recruited for this experiment via Prolific. Remuneration range was
as in Experiment 1. After following the same exclusion criteria, the final sample was of 43
participants.
Procedure
Experiment 2 differed from Experiment 1 in some key aspects. Most notably, participants did
not decide between observation and choice on each trial. Instead, observation trials displayed
a screen prompting participants to press the spacebar to reveal the observee‚Äôs choice, while
choice trials required participants to press the S or D keys to make their own selection. The
trial type was indicated by text at the top of the screen (‚ÄòOBSERVATION‚Äô or ‚ÄòCHOICE‚Äô), and
the prompts for key presses were distinct for each trial type. Additionally, observation trials
included an avatar representing the observee. The rest of the trial structure, including
feedback for the chosen option and the frequency and method of confidence ratings, remained
as in Experiment 1. Observee choices were simulated using the same algorithm.
Another difference in Experiment 2 was the across-block 2√ó2 factorial design. As in
Experiment 1, reward (high vs. low reward blocks) was manipulated. However, the observee
experience variable was replaced with a manipulation of choice agency. In only choice blocks,
participants made all their choices. In observation + choice blocks, participants observed the
observee‚Äôs choice in about half of the trials, while choosing themselves in the rest. The exact
number of observation trials within a block was either 5, 6 or 7 (in 25%, 50% and 25% of the
blocks, respectively). This slight variation was implemented so participants could not know for
sure the number of observation trials within a block. This way we prevented that, towards the
end of a block, participants stopped paying attention if no more choice trials were left, which
could affect confidence ratings. The position of observation trials along observation and choice
blocks was randomized, and so was the number of observation trials across blocks.
Participants completed 32 blocks of 12 trials each, with the block structure determined by
variable counterbalancing, similarly as in Experiment 1. To address potential bias caused by
differences in own choices between block types, the payoff calculation was adjusted.
Participants received a fixed ¬£8 plus a bonus of up to ¬£4 (minimum ¬£10 total). Instead of
summing all rewards derived from their own choices, as in Experiment 1, the bonus was based
on reward from three randomly sampled own choices from each block. This ensured
participants were not biased towards paying more attention to only choice blocks.
The instructions and practice blocks followed a similar format to Experiment 1, incorporating
the modifications for Experiment 2. Notably, these adjustments reflected the absence of
observation or choice decisions and the replacement of the observee experience manipulation
with the choice agency manipulation.
Behavioral Models
We used a very similar LMM approach as in our previous experiment. However, due to the
new factorial design, the observee experience condition predictor was here replaced by the
choice agency condition. The variables we tried to predict were the same as those from
Experiment 1‚Äôs last set of analyses: high value deck choices, deck judgment accuracy and
absolute confidence. This gave rise to three main models:
M2.1: high_value_deck_chosen ~ reward_condition * choice_agency_condition +
trial_number + ((reward_condition + choice_agency_condition) | participant_id)
M2.2: deck_judgment_accuracy ~ reward_condition * choice_agency_condition +
trial_number + ((reward_condition + choice_agency_condition) | participant_id)
M2.3: absolute_confidence ~ reward_condition * choice_agency_condition + trial_number +
((reward_condition + choice_agency_condition) | participant_id)
In some follow-up analyses described in the results section, two variations of M2.2 where
reward condition is neither part of the fixed nor of the random effects were also ran. In one,
only trials from the high reward condition were included, and in the other only trials from the
low reward condition.
Results
We fitted three mixed-effects models to predict choice accuracy (M2.1), deck judgment
accuracy (M2.2) and absolute confidence (M2.3). Each dependent variable was predicted by
the level of reward, the level of choice agency (whether that block featured observation and
choice trials or only choice trials), the interaction between the two previous predictors and trial
2C) were marginally, although non-significantly, more frequent in the low reward condition
(œá (11), 3.51, p = .06), while not being affected by agency (p = .382) nor the interaction (p
participants were more likely to identify the high value deck in low reward (œá (11), 13.56, p
< .001) and in choice-only blocks (œá (11), 4.84, p = .03). The interaction between these
variables was also significant (œá (11), 4.04, p = .04). Comparing simple effects of agency at
each level of reward separately indicated the effect remaining significant only in low reward
was significantly predicted by both reward (F(1, 41.95), 56.91, p < .001) and choice agency
(F(1, 42.21), 16.67, p < .001), as well as their interaction (F(1, 5384.03), 4.35, p = .04):
reported confidence was higher in low reward than in high reward blocks, and in only choice
blocks than in observation + choice blocks, but the agency-based difference was more
pronounced for high reward blocks. Finally, similar to Experiment 1, all three measures were
significantly influenced by trial number: participants increasingly chose the high value deck
2 2
(œá (11), 278.44, p < .001), indicated the high value deck gave more reward (œá (11), 83.68, p
< .001) and reported higher confidence in those ratings (F(1, 5376.82), 888.74, p < .001).
Discussion
Our results provide evidence for both tested hypotheses. Reduced absolute confidence in low
reward blocks (where losses were more frequent) despite better, or at least not worse,
performance supports the valence hypothesis. Higher absolute confidence in only choice
blocks supports the agency hypothesis. Thus, Experiment 2 allowed us to identify independent
and coexisting influences of valence and agency on confidence.
It could be argued that the higher absolute confidence observed in only choice blocks is simply
a byproduct of better deck judgment accuracy in these blocks. However, this explanation is
inconsistent with the data. In high reward blocks, the effect of agency on deck judgment
accuracy disappeared, yet the effect on absolute confidence not only persisted but became
more pronounced. This suggests a direct causal influence of agency on confidence.
Consistent with Experiment 1, low reward blocks were associated with more frequent choices
of the high value deck and more accurate deck judgments. Since agency was not confounded
with reward in Experiment 2, these findings strengthen the case for a reward-specific effect on
choices, potentially related to loss attention. Regarding agency, only choice blocks were
associated with more accurate deck judgments, but this effect was limited to low reward blocks.
This could reflect enhanced reward processing, better exploration or just a bigger difference
in sampled value between decks.
The observed agency effects on confidence could be attributed to factors related to making
more choices. For instance, participants may integrate information from their own choices with
greater confidence, or the act of choosing itself may boost confidence. Alternatively, the
difference in confidence between agency conditions might not stem from the choices per se,
but from information accessed via those choices. In observation trials, the observed choice
did not always align with the choice the participant would have made, potentially reducing
confidence‚Äîparticularly when the participant would have chosen the alternative deck.
EXPERIMENT 3
In order to further disambiguate whether higher confidence in the only choice condition was
driven by choice agency or rather by information access, we designed a full information variant
of the task, where both chosen and unchosen reward values were revealed during outcome
variability: standard deviations of both decks were raised from 15 to 20. This change was
introduced in order to counteract the decrease in overall task difficulty derived from receiving
twice as much outcome information per trial. With this new full information design, participants
would not experience the situation of not accessing their desired information. A reward effect
(lower confidence for low reward blocks) being present again may support the information
only choice blocks would support the choice agency hypothesis, suggesting our previous
agency effect had indeed a component related to choices.
0.75
0.5
0.25
HR, O+C HR, C LW, O+C LR, C
Condition
sequence of a trial, which followed the structure of Experiment 2, except for reward feedback
being always shown for the chosen and non-chosen deck, with the chosen deck being outlined.
The right boxes summarize the variables manipulated across blocks, which matched those of
Experiment 2, leading to the same four possible block types. B. Schematics depicting the
predictions the different hypothesis would make regarding absolute confidence across block
types. Confidence is shown in arbitrary units. C. Proportion of choices of the deck that had
given the highest reward so far within that block, per condition, only taking into account choice
trials. D. Deck judgment accuracy per condition, defined as the proportion of confidence
judgments where participants gave their rating within the half of the scale corresponding to
the deck that had given the highest reward so far within that block. E. Absolute confidence,
from 50 to 100, per condition. For C to E, small dots connected with lines depict individual
participants, with the density of their distribution being represented by the violins. Big dots with
error bars depict across-participant averages with their respective standard error of the mean.
raf
os
kced
tseb
seciohc
.porP
0.75
0.5
0.25
HR, O+C HR, C LW, O+C LR, C
Condition
raf
os
kced
tseb
ni
.fnoc
erom
.porP
HR, O+C HR, C LW, O+C LR, C
Condition
ecnedfinoc
etulosbA
information access hypothesis choice agency hypothesis
HR, O+C HR, C LW, O+C LR, C HR, O+C HR, C LW, O+C LR, C
Condition
etulosbA
ecnedfinoc
REWARD
OBSERVATION TRIAL High reward Low Reward
Œº Œº Œº Œº
hv= 30 lv = 20 hv= 5 lv = -5
PRESS SPACE
œÉ œÉ
NEXT hv= lv = 20
CONFIDENCE RATING
+6 -7
(4 times per block)
How confident are YOU that, CHOICE AGENCY
on the current block, one
Observation + choice Only choice
deck gives on average more
points than the other?
‚àº 6 observation + 6 choice 12 choice trials
trials (randomly interleaved)
91%
NEXT
+26 +-1362
BLOCK TYPES
PRESS S PRESS D
HR, O+C: high reward, HR, C: high reward,
observation + choice only choice
CHOICE TRIAL LR, O+C: low reward, LR, C: low reward,
observation + choice only choice
Methods
Participants
A new sample of 50 participants was recruited using Prolific. Exclusion criteria led to a final
sample of 46 participants.
Procedure
Experiment 3 primarily differed from Experiment 2 in that, after both own and observed choices,
reward feedback was provided for both the chosen and non-chosen deck cards. Both cards
were revealed, displaying their numeric reward values (in points) and colored green or red
according to the positive or negative valence of the feedback. To help participants identify their
chosen option more clearly, the corresponding card was outlined in white. As in the previous
experiments, only the reward for the chosen option in choice trials was eligible for contribution
toward the final payoff.
Providing full reward information would presumably facilitate a more accurate and faster
estimation of each deck‚Äôs value, which could lead to more frequent choices of the high value
deck and higher deck judgment accuracy. To mitigate potential ceiling effects in these
variables, the task difficulty was increased by raising the standard deviation of the Gaussian
distribution used to generate rewards for the decks. The standard deviation was increased
from 15 (used previously) to 20.
Minor adjustments were made to the instructions and practice blocks to align them with the
full information manipulation. All other elements of the experiment remained as in Experiment
2, including the basic trial structure, across-block manipulated variables, confidence ratings,
randomization and counterbalancing, the number of blocks and trials, and the payoff scheme.
Behavioral Models
The full feedback design in Experiment 3 led to slight modifications in the dependent and
independent variables used in our LMMs. In Experiments 1 and 2, the high value deck was
used as a reference for analyzing deck choices and deck judgment accuracy, even when this
deck could occasionally have lower experienced payoffs due to sampling variability. This
approach allowed for defining an a priori best deck, even if one of the options had not yet been
sampled. However, the full feedback design alleviates this issue, as both deck values can be
estimated from the first choice onward. This also renders exploration unnecessary, as the
deck with the highest experienced payoff should always be chosen. Consequently, instead of
using choices of the high value deck as a dependent variable, we examined choices of what
we call the ‚Äúbest deck so far‚Äù. To compute this, we excluded the first trial of each block, where
choices could not yet be informed by that block‚Äôs reward history. Similarly, deck judgment
accuracy was calculated by determining whether participants‚Äô judgments aligned with the half
of the scale corresponding to the best deck so far. Our third dependent variable, absolute
confidence, remained unchanged, as it is unsigned. In terms of predictors, in addition to
reward condition, agency condition, and trial number, the fixed effects in our models included
the difference in mean reward between the best deck so far and the other deck. This variable
allowed us to assess whether differences in choices and confidence across conditions
extended beyond variations in reward balance between decks. Like trial number, this predictor
was mean-centered.
The specifications of our models can be found below. Note that when predicting deck judgment
accuracy, convergence issues prevented us from running a full model, and even a first
simplified model without interactions, so we ran two different models, one with reward
condition as predictor (M3.2.1) and the other with choice agency condition (M3.2.2.).
M3.1: best_deck_so_far_chosen ~ reward_condition * choice_agency_condition +
difference_average_experienced_reward_best_deck_minus_other + trial_number +
((reward_condition + choice_agency_condition) | participant_id)
M3.2.1.: deck_judgment_accuracy_relative_to_best_deck_so_far ~ reward_condition +
difference_average_experienced_reward_best_deck_minus_other + trial_number +
(reward_condition | participant_id)
M3.2.2.: deck_judgment_accuracy_relative_to_best_deck_so_far ~ choice_agency_condition
+ difference_average_experienced_reward_best_deck_minus_other + trial_number +
(choice_agency_condition | participant_id)
M3.3: absolute_confidence ~ reward_condition * choice_agency_condition +
difference_average_experienced_reward_best_deck_minus_other + trial_number +
((reward_condition + choice_agency_condition) | participant_id)
Results
Following the previous approach, we built mixed-effects models predicting choices (M3.1),
deck judgment accuracy (M3.2.1 and M3.2.2) and absolute confidence (M3.3). Importantly, as
explained before, the full information design made us redefine the choice and judgment
accuracy measures to be conditioned on the best deck so far, instead of best a priori (high
value) deck.
significant trend towards higher values in the choice-only condition (œá (7), 3.69, p < .06), but
was unaffected by reward (p = .64). Most interestingly for our hypotheses, absolute confidence
agency (F(1, 44.93), 6.72, p = .01), but not their interaction (p = .20). Trial number positively
predicted choice accuracy (œá (12), 4.82, p = .03) and absolute confidence (F(1, 5764.08),
644.95, p < .001), but not deck judgment accuracy (reward model: p = .28; agency model: p
= .27). Finally, our newly incorporated predictor had a significant effect on all three measures:
as the difference in average reward between best and worst decks so far increased, best deck
2 2
choices (œá (12), 821.87, p < .001), deck judgment accuracy (reward model: œá (7), 519.44, p
< .001; agency model: œá (7), 522.31, p < .001) and absolute confidence (F(1, 5828.64),
1315.80, p < .001) increased.
Discussion
Experiment 3 demonstrates that the agency effect observed previously remains significant
even when information access is controlled by providing full reward feedback for both
alternatives on each trial. While we cannot entirely rule out the possibility that the agency effect
in earlier experiments was partly attributable to observation trials preventing participants from
accessing desired information, our findings establish that the agency effect persists in the
absence of this information access limitation.
We also found that full feedback eliminated differences in performance between high and low
reward conditions. This could be attributed to ceiling effects in choices and deck judgment
accuracy, despite our efforts to increase task difficulty. Figures 3C and 3D illustrate that some
participants approached or reached maximum performance under certain conditions, which
may have obscured any previously observed differences in accuracy. Nonetheless, our results
suggest that choice agency independently influences absolute confidence beyond its effect on
choices.
Finally, although non-significant, we observed a trend suggesting that participants identified
the best deck more accurately in only choice blocks. Given the full feedback design, this effect
cannot be attributed to better exploration during choice trials. Instead, it may reflect improved
encoding of reward values in trials where participants made their own choices, again
potentially driven by increased attention during these trials.
GENERAL DISCUSSION
Experiencing the outcomes of chosen alternatives should enhance confidence in knowing
which of these alternatives is associated with better reward. However, here we found such
confidence to be lower in situations where learning occurred primarily through observing
another agent's choices rather than through one's own. In Experiment 1, we showed that
observational learning increased in contexts with frequent losses, but the losses increasing
observation also reduced confidence compared to contexts with no losses and less
observation. To dig deeper into whether reduced confidence had been produced by losses or
by more observation, we ran Experiment 2, where we independently manipulated reward and
choice agency. There, both factors demonstrated to influence confidence. Experiment 3
confirmed these effects even when full feedback was provided for both chosen and non-
chosen alternatives. Together, our findings highlight two factors common in situations with
frequent observational learning that negatively impact confidence: the presence of losses,
which often increase observation, and a reduced number of self-made choices.
The negative effect of losses on confidence aligns with prior research showing that losses
lower confidence while gains increase it, in both perceptual (Giardini et al., 2008; Lebreton et
al., 2018; Hoven et al., 2022) and reinforcement learning (Lebreton et al., 2019; Ting et al.,
2020) decision making. In the latter domain, a recent computational model (Salem-Garcia et
al., 2023) relates such effects to outcome context-dependency during value learning.
According to this account, confidence would be biased by experienced outcomes being
reframed relative to the reward expected in a context, which would be lower in situations where
alternatives deliver negative rather than positive rewards. Compared to these previous studies,
our low reward conditions show that reduced confidence can also appear in contexts where
different alternatives give average rewards of opposite valence (positive vs negative). This
kind of situations, common in real life, capture what could motivate a transition from initial,
loss-avoiding observation into reward-seeking choices.
The second effect we identified was agency-based: even in situations with no losses,
confidence was lower when participants observed more than when they made all their choices.
This difference could be underlied by different factors. Confidence may have tracked the better
attention (Truong et al., 2017), information processing (Falb√©n et al., 2020) or memory retrieval
(Ben Yehuda, 2019) that has been found for self-related stimuli and outcomes obtained by our
own actions. And although our data did not reflect enhanced processing through better choices
in only choice conditions, the analyses reported in Supplementary Material 2 seem to hint at
different processing, with agency determining the weight outcome information had on
confidence. Specifically, in Experiment 3 we saw confidence to be most affected by reward
information coming from chosen decks, as opposed to non-chosen decks in choice trials and
any deck in observation trials. The fact that this was only significant in high reward conditions,
though, suggests an interaction between agency and reward. Agency could also have affected
confidence via enhanced affective states and motivation, as people feel more/less confident
when these states are positive/negative (J√∂nsson et al., 2005; Ifcher & Zarghamee, 2014;
Koellinger & Treffers, 2015; Culot et al., 2021). Moreover, affect (Kaiser et al., 2021; Leotti et
al., 2010) and motivation (Eitam et al., 2013; Karsh & Eitam, 2015) grow positively with the
feeling of agency, with motivation in particular increasing when agency gives the possibility to
influence the environment. In our study, agency could also be linked to motivation through
more opportunities to win reward in only choice conditions, as the rewards picked for final
payoff came only from choice trials. Another possible affective driver is the need to feel good
about one‚Äôs own choices. Accordingly, increased confidence after making a choice could be
a way to reinforce self-consistency, similarly as it happens with post-choice valuation (Brehm,
1956; Sharot et al., 2010; Egan et al., 2010; Fujiwara et al., 2013). A related choice-induced
factor could be confirmation bias, believed to sometimes be behind overconfidence (Salem-
Garcia et al., 2023), and which is only present for information derived from one‚Äôs own choices
(Chambon et al., 2020). However, note that confirmation bias has also been shown to be
caused by high confidence (Rollwage et al., 2020) rather than to cause it, providing evidence
for reversed causality. Whatever the origin of our agency effect is, there are some accounts
that cannot fully explain it. First, some could attribute lower confidence to participants, while
observing, not always accessing the outcome information corresponding to the choice they
would have made. However, the agency effect surviving in Experiment 3, where outcome
feedback was given for both alternatives, rules that out as the sole explanation. Second, since
increased confidence has been found for voluntary motor actions as opposed to passive motor
actions (Charles et al., 2020), or for motor actions as opposed to no actions (Filevich et al.,
2020), one could think the agency effect can be reduced to a motor effect. Unlike in those
studies, though, our tasks required participants to still make an action, in form of a key press,
to reveal the observee‚Äôs choice. The fact that despite matched actions between observation
and choice trials we still found more own choices being followed by greater confidence
suggests that our agency effect is not simply of motor origin.
When attempting to foster observation in Experiment 1, featuring experienced observees was
far less successful than introducing the presence of losses. Participants likely prioritized
obtaining immediate rewards over the potential benefits of learning from a more experienced
agent. Including more trials per block or featuring more than two choice options may have
made initial observation of experienced observees look like a better investment. Leveraging
observee experience could have involved straightforward choice imitation, or more
sophisticated processes that involve inferring the observee‚Äôs goals and mental states, what
may end up shaping the observer‚Äôs values (Burke et al., 2010; Najar et al., 2020; Charpentier
et al., 2020). However, that would probably require understanding the observee‚Äôs strategy
and/or choice quality. Participants may not have had enough exposure to the observee‚Äôs
choices to do that, despite the initial training session featuring two full blocks of observation.
Our experimental manipulations influenced not only absolute confidence but also deck choices
and judgment accuracy. Compared to high reward blocks, low reward blocks led to more
frequent choices of the high value deck (Experiments 1 and 2) and greater deck judgment
accuracy (Experiment 1), while ceiling effects may have masked similar outcomes in
Experiment 3. Previous studies suggest that enhanced on-task attention in the presence of
losses might drive better decision-making in such contexts (Yechiam & Hochman, 2013a,
2013b). Whatever the cause may be, it is remarkable that, despite improved performance in
loss-heavy conditions, participants still reported lower confidence. Beyond reward effects,
manipulating the presence of observation trials also impacted deck judgment accuracy, though
not deck choices. In Experiments 2 and 3, deck judgment accuracy tended to be higher for
only choice blocks. While these effects were modest, they align with studies finding enhanced
attention (Truong et al., 2017) and information processing (Falb√©n et al., 2020) for self-related
stimuli, and where obtaining an outcome by performing an action helps remembering that
outcome (Ben Yehuda, 2019).
In Experiment 1, we showed that observation increased in the presence of losses and
decreased as participants learned which alternatives yielded better outcomes. However, loss-
avoidance and learning are likely not the only factors influencing the balance between
observing and choosing. Section 3 of the supplementary material reveals that, within low
reward blocks, decisions to observe (compared to choosing) were associated with smaller
differences in experienced rewards between decks and lower confidence in the preceding trial.
Value difference between alternatives (De Martino et al., 2013; Lebreton et al., 2015) and
confidence (Boldt et al., 2019) have been previously identified as determinants of value-based
decisions. However, since value-based confidence seems to be estimated from value
differences (De Martino et al., 2013), their effects are likely interdependent, making it unclear
if confidence separately drives observation decisions. In any case, both variables being
predictors only in low reward blocks suggests that participants used observation mainly as a
strategy when they were uncertain of which deck could penalize them if chosen.
Confidence was often dissociated from deck choices and deck choice accuracy within
participants across conditions, but our results section did not relate these three variables
across participants. Our analyses in section 4 of the supplementary material show that
participants making more high-value deck choices also tended to have better deck judgment
accuracy. However, neither better choices nor greater judgment accuracy correlated positively
with absolute confidence; in fact, there was sometimes a negative trend. This suggests that
the typical positive relationship between confidence and performance was disrupted here by
biases. Since losses had the largest impact on confidence in our within-participant analyses,
we computed a measure of loss-derived confidence bias, defined as a greater positive
difference in confidence between high and low reward blocks. Across participants, those with
stronger loss-derived confidence bias tended to report higher overall confidence but showed
lower deck judgment accuracy. This implies that while loss-driven bias determined overall
confidence ratings, participants with better insight into the best deck experienced less bias.
Although the findings summarized in the previous paragraph highlight biases in confidence,
they do not speak of overconfidence as traditionally defined‚Äîconfidence exceeding objective
performance. Prior evidence (Lebreton et al., 2019; Ting et al., 2020; Salem-Garcia et al.,
2023) suggests that individuals in contexts involving personal choices and positive rewards
often display overconfidence. Losses and non-owned actions would then reduce this
overconfidence, thus ameliorating the bias. Another possibility is that losses and less choices
do not reduce but exacerbate bias, yet in the opposite direction: making people underconfident.
Surprisingly, the analyses reported in Supplementary Material 5 seem to support this last
hypothesis. Moreover, in Experiment 3 underconfidence was the norm across all conditions.
The reason why our data departs from the often-found baseline overconfidence, though, is still
to be determined.
While our results contributed to identifying different factors that may lead to reduced
confidence while learning through observation, they also formulate some questions that
warrant further investigation. A natural extension of this research would be to develop a
computational model that explains the mechanisms by which reward valence and agency
influence confidence. This could build on existing frameworks, such as the reinforcement
learning model developed by Salem-Garcia et al. (2023). Another promising avenue would be
to revisit our unsuccessful attempt to manipulate observation by varying observee experience.
We could examine how providing more explicit information on observee characteristics, such
as skill level or strategy, affects observers‚Äînot only in terms of engaging in observation, but
also in changing their own confidence in the alternatives‚Äô value. As a final idea, the study of
metacognitive representations could further advanced by incorporating tasks where observers
assess both their own confidence and that of the observees. This would allow us to examine
whether different information or biases shape confidence estimates about oneself and others.