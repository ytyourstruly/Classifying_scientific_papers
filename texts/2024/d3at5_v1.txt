Expert or Novice? Visual Working Memory Reveals the Difference Under Load
Bahareh Jozranjbar1*, & Mohsen Rafiei1
Department of Psychology
Providence College
Author Note
Correspondence should be directed to Bahareh Jozranjbar, Faculty of Psychology,
Providence College, Providence, Rhode Island, USA.
Email: b.j.ranjbar@gmail.com
Abstract
This study examines the relationship between visual working memory (VWM) and object
recognition, focusing on category expertise (faces vs. houses) and processing strategies
(featural vs. configural) under varying cognitive loads. Participants performed a VWM task
with numerical sequences and an object recognition task manipulating featural and
configural attributes. Results indicated a strong relationship between VWM performance
and configural processing of houses, a non-expert category, in high-load conditions,
suggesting greater demands of this task on general VWM resources. Conversely, faces-
an expert category-appeared to rely less on VWM because of specialized holistic
processing mechanisms. Featural processing of non-expert categories was also found to
require fewer VWM resources. These findings highlight how expertise and processing
strategies contribute to VWM, where non-expert categories rely more on the general
mechanisms and the expert categories exploit domain-specific efficiencies to alleviate
cognitive load.
Keywords: Visual working memory; simple objects; real-world objects; featural vs
configural processing; visual expertise
Introduction
Visual working memory (VWM) refers to the ability to temporarily retain and retrieve visual
information (Luck & Vogel, 1997). While essential for maintaining perceptual continuity,
VWM has a limited capacity (Alvarez & Cavanagh, 2004; Awh et al., 2007; Kristjánsson,
2006; Luck & Vogel, 1997; Vogel et al., 2001). Whereas these limitations have been well
studied using simple stimuli, such as colors and shapes, the mechanisms supporting
VWM for complex stimuli are still poorly understood.
Research shows that VWM capacity depends on the type of stimuli. Some studies show
that real-world objects, which are visually complex, often require more VWM resources
than simpler stimuli (Alvarez & Cavanagh, 2004; Luria et al., 2010). However, real-world
objects also benefit from long-term memory since meaningfulness and familiarity enhance
performance, for example, Jackson & Raymond (2008) demonstrated that VWM capacity
increases when long-term memory representations are available. Similarly, Xie & Zhang
(2017) reported that familiarity enhances VWM capacity: participants recalled more first-
generation Pokémon than less familiar characters. Further studies showed that
meaningful stimuli enhance VWM performance and may involve separate memory
processes (Ngiam et al., 2019; Thibeault et al., 2024). The so-called object benefit
phenomenon shows that concrete objects are maintained in visual working memory
(VWM) more effectively than simple features (Brady & Störmer, 2024; Sahar et al., 2020;
Shoval & Makovski, 2022). The benefits that come with objects are supported by the
presence of semantic information (Brady & Störmer, 2022, 2024; Thibeault et al., 2024),
along with a higher degree of familiarity and knowledge about the stimuli (see Chung et
al., 2024, for a review). Torres et al., (2024) further found that tangible objects elicited
higher recollection rates, a greater number of high-confidence responses, and better
memory performance compared to their scrambled counterparts, which again underlines
the importance of semantic information over visual complexity. This advantage is
supported by increased electrophysiological indices of WM storage (Asp et al., 2021;
Brady et al., 2016; Thibeault et al., 2024), suggesting that enhanced memory
performance is supported by additional neural resources, possibly through the
recruitment of ventral stream regions responsible for object representation (Clarke &
Tyler, 2015; Stojanoski et al., 2019).
Some research studies challenge the assumed benefits of familiarity and meaningfulness
in VWM. For instance, Chen et al., (2006) and Pashler, (1988) failed to find any significant
advantages for familiar objects in visual working memory (VWM) tasks, suggesting that
the effects might not be generalizable. Furthermore, Brady & Störmer, (2024) emphasized
the crucial point of thoroughly examining stimulus dissimilarity when estimating memory
capacity across different stimuli, as the nature of the stimuli dramatically impacts VWM
performance. These mixed results point out the complexity of VWM processes. While the
object benefit demonstrates that meaningful stimuli can recruit additional cognitive
resources, possibly by activating semantic features to foster recollection, the mechanisms
driving these effects are still uncertain. One plausible explanation is that VWM processes
differ between real-world and simple objects because of the different processing
mechanism: featural processing, encoding each visual attribute, and configural
processing, encoding spatial relations between features (Maurer et al., 2002).
Elementary visual features, such as color and orientation, are typically processed
separately by specialized neural networks, thus encouraging feature-based processing
(Conway, 2009; Markov et al., 2019; Paik & Ringach, 2011; Wang et al., 2017). On the
other hand, complex objects in the real world are often holistic representations, as they
cannot be easily decomposed into unique components. Such a holistic encoding likely
engages higher-level brain regions, such as the medial temporal lobe and the ventral
visual stream, reflecting their integrated nature (Erez et al., 2016; van den Honert et al.,
2017). It is important to note that that processing strategies may vary across object
categories. In other words, strategies effective for one category may not apply to another
(Jozranjbar et al., 2021, 2023).
Experts holistically process objects in their area of expertise, which allows for fast
identification and quick processing (Bukach et al., 2006; Gauthier & Bukach, 2007). This
expertise expands VWM capacity via chunking and holistic binding. Faces, for instance,
are stored more efficiently in VWM compared to other complex objects, probably because
of holistic processing (Curby & Gauthier, 2007). Car experts also show a VWM advantage
for cars, illustrating how expertise leads to a domain-specific enhancement of VWM
capacity (Curby et al., 2009). These chunks may serve as either compressed codes
(Brady et al., 2009) or cues for long-term memory (Huang, 2011, 2015a, 2015b; Hulme
et al., 1991, 1997; Jones & Farrell, 2018; Kahneman et al., 1992).
Increased ability in specific categories enables specialized processing, which reduces
reliance on generalized VWM. Jozranjbar et al., (2024) found a significant relation
between VWM precision for basic stimuli and configural memory accuracy for non-expert
categories, such as houses. This suggests that configural processing for non-expert
categories places significantly greater demands on VWM than featural processing or the
processing related to expert categories. Interestingly, memory accuracy for configural
houses was more strongly related to VWM precision than was memory accuracy for
expert categories, such as faces and pseudowords, whether in featural or configural
conditions. This is consistent with previous findings that expertise improves VWM
performance by perceptual experience (Curby et al., 2009; Curby & Gauthier, 2007).
However, whereas houses are a non-expert category, they found no significant
relationship between memory for featural information within houses and VWM precision,
suggesting that featural processing in non-expert categories places less demand on
VWM. The study, however, used a spatial VWM task in which participants adjusted the
orientation of a bar to match a previously seen sample. This task inherently places strong
emphasis on spatial properties, such as angles and distances, aligning closely with
configural tasks like house recognition, where spatial arrangements are critical. This
alignment likely explains the strong association between VWM precision and configural
processing for houses. In contrast, VWM tasks that emphasize featural properties, such
as specific colors or numbers, may better align with object recognition tasks focused on
encoding discrete, independent features, such as the featural condition for houses. This
would suggest that the mechanisms of WM might vary depending on task characteristics,
specifically, spatial VWM would seem more relevant for configural recognition of non-
expert categories, whereas featural VWM would apply more for featural recognition of
those same categories, for instance, Huang, (2015b) demonstrated how the efficiency of
VWM processing is dependent on task type, showing that there are particular features
that could be processed in a more fitting way for certain tasks relative to others.
Building on prior research (Jozranjbar et al., 2024), this study shifts from oriented lines to
numerical sequences, a paradigm that focuses on featural processing. As discrete and
independent elements, numerical sequences offer a complementary perspective to
previous study focused on spatially dependent configurations. Using an individual
differences approach, the study examines how VWM retention of numerical sequences
under low and high WM load conditions relates to object recognition performance in
featural and configural conditions for unfamiliar faces and houses. Specifically, it
measures how memory accuracy for these stimuli is related to and possibly supported by
VWM accuracy measured using simple numerical sequences, thus giving new insights
into the interaction between VWM and object recognition mechanisms under various
cognitive loads.
Method
Participants
The participants were 38 undergraduate students from Providence College who
participated in the study in exchange for research credits. The sample included 17 males
and 21 females, with a mean age of 19 years (range: 18–21). All participants were 18
years or older, with normal or corrected-to-normal vision and normal hearing.
Procedure
The study was approved by the institutional review board (IRB-FY25-14), and informed
consent was obtained from all participants prior to the study. The experiment was
conducted on individual computers using PsychoPy version 2024.2.4. Participants
provided responses using a standard keyboard. All participants were tested in a quiet
room, seated approximately 50 cm from a 1920 × 1080 resolution monitor.
The experiment consisted of 60 rounds. Each round began with a VWM sequence of six
digits, followed by five object recognition trials, and concluded with a WM probe. This
structure resulted in a total of 300 object recognition trials and 60 VWM sequences.
Tasks
The experiment included two interleaved tasks: a visual working memory task and an
object recognition task. Participants completed practice trials before beginning the main
task. During the VWM practice, sequences of three digits were presented, followed by
three object recognition trials using geometrical shapes (e.g., circles, squares). Each trial
included a sample shape, a match, and a foil. After the object recognition trials, a VWM
probe was presented, requiring participants to determine whether the probe was part of
the initial sequence. Feedback was provided during practice to facilitate understanding of
the tasks. Participants were required to complete three consecutive rounds correctly
before proceeding to the main experiment.
Working Memory Task
In the main experiment, participants were presented with sequences of six digits, either
in ascending sequential order (low VWM load) or in random order (high VWM load). The
digits were displayed in black Arial font (size: 0.07 in height PsychoPy units) on a white
background for 2000 ms, followed by a blank screen for 1500 ms. After completing five
object recognition trials in each round, participants were shown a single probe digit and
recorded using the “Y” key for “present” and the “N” key for “not present.” Feedback was
not provided during the main experiment. Overall, there were 60 WM sequences, of which
30 were presented in ascending sequential order (low VWM load) and 30 in random order
(high VWM load). The VWM sequence types (sequential or random) were randomized
across rounds.
load trials with digits in ascending order and high-WM-load trials with digits in random order. Each trial
begins with a WM sequence followed by five repetitions of object recognition tasks. Object recognition trials
include a sample image (faces or houses), a mask, and a side-by-side presentation of a match and foil
image until a response is made. The round concludes with a WM probe asking participants to identify if a
single digit was part of the initial sequence. WM = working memory.
Object Recognition Task
The object recognition task assessed participants' ability to differentiate between a
sample image and a foil. Stimuli consisted of faces and houses, adapted from Collins et
al., (2012). Each trial began with a 500 ms presentation of a sample image at the center
of the screen, followed by a 200 ms mask. Subsequently, a match image (identical to the
sample) and a foil image (differing featurally or configurally) were displayed side-by-side
until participants made a selection. The left arrow key (←) was used to select the left
image, and the right arrow key (→) for the right image.
Featural changes involved variations in specific features, such as the shape of the nose
in faces or the style of windows in houses. Configural changes altered the spatial
relationships between features, such as the distance between the eyes in faces or the
using PsychoPy's height units, where the values represent proportions of the screen’s
height. Sample images were displayed at 0.25 × 0.25 of the screen’s height, while match
and foil images were scaled to 0.15 × 0.15 of the screen’s height to minimize reliance on
low-level template matching. Object recognition trials included four conditions based on
combinations of processing type (featural vs. configural) and stimulus type (faces vs.
houses). Each condition comprised 75 trials, presented in a randomized order.
visual recognition task.
Measures and Data Preprocessing
The primary dependent variable for both tasks was accuracy. For the object recognition
task, accuracy was calculated as the proportion of correct responses in identifying the
match image. Only trials within rounds where participants responded correctly to the
VWM probe were included in the analysis, ensuring that object recognition accuracy
reflected processing under conditions where VWM sequences were successfully
retained.
Reaction times (RTs) were recorded in milliseconds as a secondary measure to explore
potential interactions between WM load and visual recognition performance. Extreme RT
values, defined as those exceeding ±3 standard deviations (±3·SD) from the mean, were
excluded to prevent skewed results. This approach ensured that the analysis focused on
meaningful data while maintaining the integrity of the findings.
Results
We aimed to investigate the relationship between featural and configural conditions of
faces and houses and visual working memory (VWM) performance under low-load and
high-load VWM conditions. Specifically, we sought to explore how varying VWM demands
influence the interaction between object categories and processing strategies, such as
featural and configural processing. Detailed accuracy distributions across these
VWM load and object recognition tasks.
memory (WM) conditions. Each plot represents accuracy (%) across five categories: Configural Face,
Configural House, Featural Face, Featural House, and Working Memory. The violin plots visualize the
distribution, median, and variance of accuracy for each condition, highlighting differences in performance
under varying WM demands.
Rather than focusing solely on absolute accuracy, which could be influenced by task
difficulty, we aimed to understand how VWM performance aligns with specific object
recognition tasks. This method enabled us to estimate the degree of association between
VWM and the object recognition variables, without making assumptions about causality.
VWM accuracy served as the dependent variable in Bayesian multiple regression
analyses, with participants’ accuracy in the four object recognition conditions
(featural/configural processing for faces/houses) as predictors. Separate Bayesian
regression analyses were conducted for the low-load and high-load VWM conditions to
estimate the degree of association between WM and object recognition variables.
High-Load Working Memory
A Bayesian linear regression was conducted to predict high-load VWM accuracy using
Configural Face, Configural House, Featural Face, Featural House, and Working Memory
accuracy as predictors. The analysis identified the 10 best models, as summarized in
predictor, with the highest posterior probability (P(M|data) = 0.404), a Bayes factor of
BF10 = 1.000, and explained 27.1% of the variance in WM accuracy (R² = 0.271). This
result highlights that Configural House accuracy was the strongest predictor of VWM
performance. Other models, including combinations of additional predictors such as
Featural Face and Configural Face, demonstrated substantially lower posterior
probabilities and Bayes factors, suggesting these variables contributed minimally to
explaining WM performance.
object recognition tasks under high-load working memory condition. P(M) represents prior
probabilities, P(M|data) shows posterior probabilities, BFM indicates the change in odds from
prior to posterior, BF10 provides Bayes factors relative to the best model (always 1 for the top
model), and R² reflects variance explained.
Model Comparison – High-Load Working Memory
Models P(M) P(M|data) BF BF R²
M 10
Configural House 0.050 0.404 12.906 1.000 0.271
Featural Face + Featural House + Configural Face +
0.200 0.092 0.404 0.057 0.278
Configural House
Configural Face + Configural House 0.033 0.088 2.784 0.325 0.275
Featural House + Configural House 0.033 0.084 2.652 0.311 0.272
Model Comparison – High-Load Working Memory
Models P(M) P(M|data) BF BF R²
M 10
Featural Face + Configural House 0.033 0.083 2.624 0.308 0.272
Featural House + Configural Face + Configural House 0.050 0.053 1.058 0.130 0.278
Featural Face + Configural Face + Configural House 0.050 0.050 0.995 0.123 0.275
Featural Face + Featural House + Configural House 0.050 0.049 0.972 0.120 0.274
Null model 0.200 0.043 0.181 0.027 0.000
Featural House 0.050 0.025 0.488 0.062 0.127
The results of all model results are available in the supplementary section (supplementary
configural house recognition accuracy.
configural house recognition accuracy.
accuracy had the highest posterior inclusion probability (P(incl|data) = 0.902), with a
mean coefficient of 0.502 (95% CI [0.000, 0.876]). This finding underscores the strong
and significant contribution of Configural House accuracy to VWM performance. In
contrast, other predictors, such as Featural Face and Configural Face, showed much
lower inclusion probabilities (P(incl|data) < 0.3), indicating weaker associations with VWM
accuracy. The shift from prior to posterior inclusion probabilities is illustrated in the bar
emphasizing the dominance of Configural House accuracy. This method, which weights
models by their posterior probabilities, demonstrated that Configural House consistently
contributed the most to predicting VWM performance under high-load conditions. These
results suggest that configural processing, particularly for non-expert object categories
like houses, places the greatest cognitive demand on VWM resources.
memory (WM) and object recognition tasks under high-load working memory condition. The
leftmost column lists the predictors. P(incl|data) represents the posterior inclusion probability,
showing the likelihood that a predictor is part of the best model given the data. BFinclusion
indicates the Bayes factor for inclusion, reflecting the change in odds from prior to posterior
inclusion. The Mean and SD columns present the posterior mean and standard deviation of each
predictor's coefficient after model averaging. The lower and upper columns display the 95%
central credible intervals, offering a range of likely values for each coefficient based on the data.
Posterior Summaries of Coefficients
95% Credible
Interval
Coefficient P(incl) P(excl) P(incl|data) P(excl|data) BF M ean SD Lower Upper
inclusion
Intercept 1.000 0.000 1.000 0.000 1.000 83.662 2.084 79.944 88.028
Featural 4.556×10
0.500 0.500 0.292 0.708 0.412 0.144 -0.283 0.405
Face
Featural
0.500 0.500 0.319 0.681 0.469 0.036 0.155 -0.231 0.475
House
Configural
0.500 0.500 0.299 0.701 0.427 -0.024 0.129 -0.351 0.220
Face
Configural
0.500 0.500 0.902 0.098 9.168 0.502 0.247 0.000 0.876
House
working memory conditions.
memory for configural and featural information of faces and houses. Configural house
recognition demonstrates the strongest positive correlation with VWM accuracy, whereas
featural house recognition shows a weaker correlation. In contrast, no significant
relationships are observed for featural or configural face recognition. The separation
between house and face conditions underscores distinct processing mechanisms, with
house-related tasks clustering more closely to VWM performance.
recognition tasks (featural and configural processing for faces and houses) under high WM load conditions.
The color intensity represents the strength of Pearson’s correlations, with red indicating positive correlations
and blue indicating negative correlations. Configural house recognition shows the strongest positive
correlation with WM accuracy, depicted by the darkest red arc, while featural house recognition shows a
weaker positive correlation. No significant correlations are observed for either featural or configural face
recognition. Thicker arcs signify stronger relationships.
Low-Load Working Memory
analysis identified the null model as the best-fitting model, with the highest posterior
probability (P(M|data) = 0.155). This suggests that none of the tested predictors, including
featural and configural conditions for faces and houses, significantly explained working
memory accuracy. The Featural Face model (P(M|data) = 0.129, R² = 0.148) was the
second-best model, demonstrating moderate predictive power. This was followed by the
Configural Face model (P(M|data) = 0.107, R² = 0.137) and the Configural House model
(P(M|data) = 0.079, R² = 0.120). These results highlight a slightly greater relevance of
featural strategies, particularly for faces, under low-load conditions. Detailed results for
object recognition tasks under low-load working memory condition. P(M) represents prior
probabilities, P(M|data) shows posterior probabilities, BFM indicates the change in odds from
prior to posterior, BF10 provides Bayes factors relative to the best model (always 1 for the top
model), and R² reflects variance explained.
Model Comparison – Low-Load Working Memory
Models P(M) P(M|data) BF BF R²
M 10
Null model 0.200 0.155 0.735 1.000 0.000
Featural Face 0.050 0.129 2.805 3.317 0.148
Model Comparison – Low-Load Working Memory
Models P(M) P(M|data) BF BF R²
M 10
Configural Face 0.050 0.107 2.281 2.763 0.137
Featural Face + Featural House + Configural Face +
0.200 0.105 0.469 0.677 0.210
Configural House
Configural House 0.050 0.079 1.625 2.031 0.120
Featural Face + Configural House 0.033 0.075 2.368 2.919 0.199
Featural Face + Configural Face + Configural House 0.050 0.051 1.012 1.304 0.204
Featural Face + Featural House + Configural House 0.050 0.049 0.989 1.275 0.202
Featural Face + Configural Face 0.033 0.047 1.428 1.814 0.172
Configural Face + Configural House 0.033 0.044 1.343 1.711 0.169
predictor demonstrated a moderate posterior inclusion probability (P(incl|data) = 0.519,
BF (inclusion) = 1.078), emphasizing its relative importance under low-load conditions. In
contrast, the Featural House (P(incl|data) = 0.313) and Configural Face (P(incl|data) =
0.445) predictors exhibited lower inclusion probabilities, indicating weaker associations
with working memory accuracy. The Configural House predictor showed a slightly higher
inclusion probability (P(incl|data) = 0.456, BF (inclusion) = 0.837), suggesting a moderate
contribution to performance. The shift from prior to posterior inclusion probabilities is
memory (WM) and object recognition tasks under low-load working memory condition. The
leftmost column lists the predictors. P(incl|data) represents the posterior inclusion probability,
showing the likelihood that a predictor is part of the best model given the data. BFinclusion
indicates the Bayes factor for inclusion, reflecting the change in odds from prior to posterior
inclusion. The Mean and SD columns present the posterior mean and standard deviation of each
predictor's coefficient after model averaging. The lower and upper columns display the 95%
central credible intervals, offering a range of likely values for each coefficient based on the data.
Posterior Summaries of Coefficients
95% Credible
Interval
Coefficient P(incl) P(excl) P(incl|data) P(excl|data) BF M ean SD Lower Upper
inclusion
Intercept 1.000 0.000 1.000 0.000 1.000 90.209 1.839 86.741 94.127
Featural Face 0.500 0.500 0.519 0.481 1.078 0.188 0.259 -0.062 0.842
Featural
0.500 0.500 0.313 0.687 0.456 -0.014 0.112 -0.315 0.258
House
Configural
0.500 0.500 0.445 0.555 0.800 0.110 0.211 -0.110 0.735
Face
Configural
0.500 0.500 0.456 0.544 0.837 0.085 0.138 -0.096 0.408
House
working memory conditions.
highlighting weak correlations between working memory accuracy and object recognition
predictors under low-load of VWM. Among these, the Featural Face condition exhibited
the strongest positive correlation, albeit still weak, with working memory accuracy, while
other conditions, such as Configural House and Featural House, showed even weaker
associations.
recognition predictors under low-load conditions. The Featural Face predictor exhibits the strongest positive
correlation with WM accuracy, shown by the relatively darker red arc, while weaker connections are
observed for Configural Face, Featural House, and Configural House predictors. The color intensity of the
arcs represents the strength of Pearson's correlations, with red shades indicating positive relationships.
Thicker arcs correspond to stronger associations.
Discussion
This study investigated the relationship between visual working memory (VWM) and
object recognition with respect to the interaction of category expertise, faces as expert
categories versus houses as non-expert categories, and processing mechanisms,
featural versus configural, under different levels of cognitive load. Using a VWM paradigm
based on sequences of numbers and object recognition, this study investigates how these
factors contribute together to VWM performance.
Under high-load conditions, configural House accuracy strongly predicted VWM accuracy
and constituted a significant contributor to the best-fitting Bayesian regression models.
This is in line with previous findings suggesting that the configural processing of non-
expert categories, such as houses, heavily loads VWM (Jozranjbar et al., 2024). By the
same token, our results provide evidence that for non-expert categories, VWM demands
vary as a function of the type of processing. Featural processing involves encoding and
remembering individual features independently, while configural processing requires
integration of multiple features and their spatial relationships. This integration likely
imposes greater cognitive demands on VWM for non-expert categories, as both the
individual features and their relations need to be encoded efficiently.
For expert categories, unitizing or chunking strategies might minimize these demands,
because experts typically use holistic processing to rapidly integrate features into
coherent wholes (Bukach et al., 2006; Curby et al., 2009; Curby & Gauthier, 2007;
Gauthier & Bukach, 2007; Gauthier & Tarr, 2002; but see McKone & Robbins, 2007).
Extensive knowledge about an object or category will enable experts to encode the
learned associations so that the VWM chunks can be filled with closely integrated
features. These integrated chunks maximize limited capacity and reduce dependence on
generalized VWM resources. In non-expert categories, the lack of such established
associations places an increasingly heavy demand on VWM in more challenging
conditions. Consequently, the configural processing advantage may be restricted to
expert categories for which pre-existing associations between features facilitate efficient
integration and retrieval.
The findings also build on previous work by demonstrating that the relationship between
configural processing of non-expert categories and VWM is not task-specific. Previously,
Jozranjbar et al., (2024), found a strong relationship between VWM precision for simple
stimuli and configural memory accuracy for houses, using a spatially oriented VWM task,
wherein participants had to adjust the orientation of a bar to. The present study replicated
this relationship using a numerically based VWM task prototypical of featural processing.
This implies that the observed association is not contingent on the particular nature of the
VWM task but, rather, reflects a more generic mechanism. Both spatial and featural VWM
tasks showed significant associations with configural house processing under high-load
conditions, emphasizing the dependence of such tasks on common VWM resources.
In this latter respect, under conditions of low load, the null model was the best predictor,
indicating that none of the tested predictors, including Configural House accuracy,
correlated significantly with VWM performance. The lack of significant predictors under
low load points out that the relationship between configural house accuracy and VWM
emerges mainly under high-load conditions. Here, cognitive demands stretch available
resources, making apparent the dependency of configural tasks on shared general VWM
mechanisms.
Our findings are unlikely to be explained by a lower complexity in featural houses
compared to configural houses, given that on average, recognition accuracy was actually
lower for featural houses. An alternative potential explanation could be that in the VWM
task participants were able to rely heavily on verbal cues rather than visual processing.
However, in the case of a purely visual task, Jozranjbar et al., 2024, observed similar
results, suggesting that reliance on verbal cues most likely did not affect our findings.
However, the use of an alternative task that heavily relies on featural processing and
reduces verbal cues would be a good way forward for future research. Future research
should also investigate a broader range of stimuli and tasks to further determine the
relationship between VWM and object recognition.
Conclusion
Our results highlight a robust association between VWM performance and memory
accuracy for non-expert categories, specifically houses, at high loads. Configural
processing demands strongly affect VWM capacity when multiple features and their
spatial arrangements need to be integrated. This effect contrasts with expert categories,
where holistic processing strategies enable more efficient use of memory. Notably, the
observed relationships between VWM and configural processing generalize across
distinct task paradigms, emphasizing their generalizability. Under low-load conditions,
general VWM resources are adequate to handle both featural and configural tasks;
however, under high-load conditions, there is an apparent critical dependence on the
general cognitive mechanisms for configural conditions of non-expert categories. The
findings demonstrate the role of expertise and task demands in shaping memory
performance.
Open Practices Statement
available to other researchers upon request, contingent on approval from the relevant
institutional review board (IRB) and adherence to all applicable U.S. laws and regulations
regarding data privacy and protection.