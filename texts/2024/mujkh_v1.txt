Future Proofing Schools: Bringing School Policies into the AI Era
Ann Marcus-Quinn* and Selina McCoy (ESRI, Dublin)
*University of Limerick, Ann.Marcus.Quinn@ul.ie
Abstract
The digital landscape in education has evolved rapidly in recent years, necessitating
updates to Acceptable Use Policies (AUPs) that reflect current technologies, including
Artificial Intelligence (AI). This study analysed the AUPs of 51 large second-level
schools, each with a student population exceeding 1,000, uncovering a concerning
trend: very few AUPs are current for the academic year 2024/25, with many still dating
from before 2020. These outdated policies largely lack guidelines on recent
technological advancements, particularly AI, which was absent in all AUPs reviewed. A
survey of school leaders was then rolled out, providing valuable insights from one-in-
seven leaders regarding the challenges schools face in updating AUPs to keep pace
with rapid digital and AI developments. Given the limited guidance available from the
Department of Education, school leaders emphasised the urgent need for relevant,
updated policies. For most schools, it may be practical to begin by incorporating basic
AI guidelines into existing AUPs, covering general expectations around ethical AI use,
privacy, and appropriate applications. Schools more deeply integrating AI into learning,
assessment, or administration may benefit from a standalone AI policy to address
these complex issues comprehensively. As AI technology continues to advance,
separate AI policies could gradually become the norm, enabling schools to respond
more dynamically to technological changes. The findings from this study provide key
insights for school managers and the Department of Education, informing future policy
and support structures to better address the evolving needs of the digital educational
landscape.
Introduction
AUPs in schools traditionally govern internet and device use, aiming to provide a safe
and controlled learning environment. However, as technology has advanced, so too
have the expectations and demands on these documents. This paper assesses the
readiness of current AUPs to address AI and outlines potential risks and benefits for
second-level schools. The Department of Education has acknowledged the use of AI
tools in completing Additional Assessment Components for senior cycle, with students
now being advised on how to appropriately reference AI usage, including details such
as the name of the AI tool, the date the content was generated, and a brief explanation
of its use (DE, 2024). Where generative AI tools produce shareable URLs containing
session content, students are expected to include these in their research sources. In
cases where no shareable URL is available, students must still cite the AI tool and
provide details of the prompts used. However, in the absence of clear guidelines from
the Department on how teachers and schools should navigate the complexities of AI
integration, they are left to independently determine the extent to which AI tools can be
used in teaching and learning. This lack of guidance risks significant variation in AI
implementation across institutions until standardised policies are introduced.
Addressing the gap in AUPs is critical as AI becomes increasingly integrated into
educational tools, with impacts on privacy, student behaviour, and educational equity
(Ali et al., 2024; Luckin, 2016).
Background and Literature Review
Acceptable Use Policies provide the rules for technology use within schools and aim to
create boundaries for online engagement. Emerging technologies, especially generative
AI are transforming how information is accessed and managed in classrooms, raising
new ethical concerns and demands for policy adaptation. For over 40 years, AI has
played a role in education and generative AI (GenAI) is the latest innovation with
transformative potential for educational systems (Cox, 2017). While some view AI as a
catalyst for accelerating educational change, others urge a more cautious approach,
emphasising both the benefits and drawbacks of its application in learning
environments. Recently some have cautioned about possible adverse effects of AI on
individual subjective well-being (Zhao et al., 2024). While AI in education holds the
potential to provide personalised, scalable solutions and bridge gaps, it also comes
with significant risks, particularly if not implemented thoughtfully, as it can exacerbate
existing inequalities. Although AI tools are not new, their current applications, such as
ChatGPT, launched in 2022, have been among the most disruptive technologies in
education. By June 2024, ChatGPT has become one of the most advanced publicly
available chatbots, capable of generating text within seconds and presenting itself as a
major disruptor to traditional teaching, learning, and student assessment (Cotton et al.,
2023). As a state-of-the-art language model based on OpenAI’s Generative Pretrained
Transformer (GPT), ChatGPT can generate text that often appears indistinguishable
from human writing, and its conversational abilities suggest potential uses in
education. However, it's essential to recognise that ChatGPT and similar AI tools are
not without their limitations and may not fully live up to the expectations of
revolutionising education. While students are increasingly using ChatGPT as a starting
point for drafting work and speeding up assessment completion, this reliance
underscores the need for a nuanced understanding of AI's capabilities and boundaries
(Kasneci et al., 2023; Rudolph et al., 2023). AI can assist students in achieving their full
potential but it is not a substitute for the deep understanding and nuance developed
through traditional learning approaches (Ducar & Schocket, 2018; Pham et al., 2022;
Urlaub & Dessein, 2022).
The promise of AI in education is significant, but it is equally important to manage
expectations and focus on thoughtful, equitable implementation to truly realise its
potential. Policy makers and school leaders must prioritise and acknowledge the voice
of educators, rather than yielding to the interests of large corporations, when
embedding digital technology in education to ensure that moral and ethical
considerations are appropriately addressed.
AI in Education
Studies on AI in education suggest that while AI tools can support learning, they also
introduce risks around data privacy, equity, and potential over-reliance on automated
assessments (Farooqi et al., 2024). At an OpenAI education forum, it was revealed that
a majority of ChatGPT users are students, illustrating AI's influence on education
globally (Watkins, 2024). This intersection of opportunities and challenges presented by
AI in education underscores the need for comprehensive frameworks and teacher
competences, as detailed in the report published by the European Digital Education
Hub’s Squad on Artificial Intelligence in Education. The report published by the
European Digital Education Hub’s Squad on artificial intelligence in education, focuses
on the integration of AI into education. The report outlines the necessary competences
for teachers, emphasising three areas: teaching for AI (developing critical engagement),
teaching with AI (using AI as educational tools), and teaching about AI (explaining its
technical fundamentals). It highlights the need for AI literacy, ethical considerations,
and data privacy. The report also provides practical examples and scenarios for
incorporating AI in classrooms and underscores the importance of supporting teachers
through training and institutional frameworks to maximise AI's potential while
addressing challenges (European Commission, 2023).
Some countries are actively integrating AI into their education systems (Sansusi et al,
2024). In Estonia, AI is being used to promote personalised learning (Kasneci, 2024).
The Ministry of Education and Research has established an AI council comprising
educational scientists, teachers, and entrepreneurs to guide this initiative (Education
Estonia, 2024). The council has developed general principles to ensure consistent and
stable AI integration in schools. Recognising the societal demand for AI proficiency, the
ministry plans to offer comprehensive courses for teachers, students, and civil
servants, focusing on practical applications of AI in education. To maintain cognitive
engagement, the council emphasises the importance of keeping learning processes
mentally stimulating, even with AI assistance. AI-based educational tools are being
introduced to provide adaptive learning experiences tailored to individual student
needs, aiming to free up teachers' time for more personalised student interactions.
Norway has also taken steps to integrate AI into education. In 2023, Oslo Municipality
launched a local chatbot to explore AI's role in education; an investigation involving 246
teachers revealed that instructional self-efficacy significantly influenced the perceived
utility of AI, while management and colleague discussion showed lower impacts. These
findings highlight the untapped potential of management and peer collaboration in
maximising AI's benefits, especially in the absence of established national guidelines
during the study (Elstad and Eriksen, 2024). In September 2024, Italy also initiated an AI
pilot as part of the national strategy for AI 2024-2026 to integrate AI into 15 classrooms
across four regions, aiming to enhance digital competencies among students (Agenzia
per l’Italia Digitale, 2024). The initiative employs AI tools on tablets and computers to
serve as virtual assistants, facilitating personalised learning experiences and aiding
teachers in developing tailored educational methods. This effort addresses Italy's
position among the EU countries with the lowest basic digital skills, with plans to
expand the programme if successful (Reuters, 2024).
AI as a Learning Aid
AI-powered apps like Duolingo are being used as learning aids for second level
students, enhancing traditional education with engaging, personalised experiences. By
using AI, these apps adapt to each student's proficiency level, ensuring that content is
challenging enough to promote growth but not too difficult to be discouraging. For
language learning, apps like Duolingo employ game-like elements, encouraging regular
practice through rewards and levels that make learning both fun and effective. This
tailored approach can improve retention and foster a positive attitude towards learning
outside the classroom. Additionally, AI apps often include immediate feedback, which
helps students quickly correct mistakes and build confidence. By making lessons
accessible anytime, anywhere, AI learning tools help students take charge of their
education, support skill development at their own pace, and expand learning beyond
school hours, making them valuable tools for second-level learners. When employing
ChatGPT as a learning aid, it may be beneficial to provide multiple-choice options
within the prompt. This approach enables the model to identify the most accurate
response, thereby reducing the risk of generating incorrect or misleading information
("hallucinations").
In 2023 a study which looked at the capabilities of ChatGPT (GPT-4) on second level
(high-school) computer science examinations: the UK A-Level (CS) and Irish Leaving
Certificate (LCCS). This research found that ChatGPT was capable of answering many
exam questions but that this should not undermine the integrity of the LCCS and A-
Level CS exams, as they are still conducted under invigilation (Mahon et al., 2023). In
the future, computer science assessments might be redesigned to incorporate
interactive elements where students engage with ChatGPT during exams. Through this
interaction, students could obtain information, explore problem-solving strategies, or
request clarification on complex topics. With the capability to log these interactions,
assessment could increasingly focus on students’ analytical processes rather than on
memorisation alone (Mahon et al., 2023) This research provides a compelling argument
for integrating instruction on AI, specifically on using tools like ChatGPT, as part of
computer science education. By familiarising students with AI-assisted learning,
educators can equip them with skills to effectively leverage AI as a supportive tool
rather than a substitute for their knowledge. Teaching students how to engage with AI
for problem-solving, information retrieval, and conceptual clarification can enhance
their analytical capabilities and deepen their understanding of complex topics. This
approach encourages students to see AI as a collaborative learning aid, promoting
critical thinking and informed decision-making. Embedding such instructional
components into the curriculum would prepare students not only to navigate
assessments that may incorporate interactive AI elements but also to apply these skills
beyond the classroom in real-world problem-solving contexts.
Policy Context
Ireland’s inaugural national AI strategy, AI Here for Good (Department of Enterprise,
2021), outlines a comprehensive plan to equip Ireland’s workforce and population with
future-oriented skills essential for driving AI development, deployment, and utilisation,
aimed at enhancing productivity and societal well-being. The integration of digital and
technical competencies into school curricula is anticipated to contribute significantly
to achieving this goal. However, as emphasised in the AI Strategy, it is crucial for
educators and school leaders to understand both the potential and limitations of AI
within teaching practices; leveraging AI to enhance learning experiences while also
addressing the ethical considerations and risks associated with its use. AI-based
educational tools offer numerous benefits, including the ability to deliver tailored
learning experiences and personalised feedback, as well as specialised support for
non-traditional learners and children with diverse needs. The outcomes of various EU
initiatives and the engagement of teacher support services in European AI pilot
projects, such as the AI4T (Artificial Intelligence for Teachers Erasmus+ Project), will
provide valuable insights into the application of AI and big data in education. These
projects are expected to yield high-quality resources developed collaboratively with
European partners, which can be adapted appropriately within the Irish educational
framework (Department of Education, 2022). As policies surrounding AI use in
education continue to evolve, it is essential to provide children with opportunities to
become familiar with and comfortable using AI tools from an early age, fostering a
foundation for future interactions with AI technologies. Studies indicate that AI-driven
educational technology should be guided by pedagogical principles and prioritise user-
centered design to ensure that both teachers and students are empowered, not
marginalised, by the integration of technology (European Commission, 2020; Selwyn,
2019). Many researchers have published extensively on the disconnect between
educational policy and practice (Bartell, 2001; Selwyn, 2023). In his 2010 article Selwyn
examined how information and communication technologies (ICT) are often promoted
in educational policies as solutions to educational inequalities. He argued that there is
a significant gap between these policy intentions and the realities of classroom
practice, highlighting the challenges in effectively implementing ICT to address
educational disadvantage. More recently, this work underscores the broader issue of
misalignment between educational policy directives and actual teaching practices.
In the context of AI use in Irish schools, policy is critical to success as it provides a
structured framework that ensures consistency, fairness, and accountability in the
implementation and operation of AI tools. Policies establish clear guidelines and
expectations around the ethical use of AI, data privacy, and the equitable deployment
of technology, helping educators, students, and parents understand how these tools
should be used and what safeguards are in place (Murphy et al, 2021). This foundation
promotes a stable, organised environment where AI can enhance educational goals
effectively, supporting learning and development while protecting the rights and
wellbeing of all school community members. Research undertaken in 2022 looked at
over 30 countries which had published national strategies for AI, detailing anticipated
impacts across various policy sectors, including education (Schiff, 2022). Findings from
this analysis indicate that AI’s application in education is largely overlooked in these
policies, with greater emphasis placed on education's role in cultivating an AI-ready
workforce and training AI professionals. Despite frequent mentions of AI ethics, the
ethical considerations specific to education receive minimal attention, suggesting that
the broader policy and ethical ramifications of the use of AI in education remain outside
mainstream policy agendas and key decision-making processes. In Ireland, the
Department of Education has acknowledged that there is a need for guidelines for the
use of AI in education. However, despite the press releases of 2024 which commit to
providing AI guidelines, there remains a lack of clear direction for schools, despite
growing concerns around the responsible use of AI in education (Schiff, 2022). The
department may be choosing to observe and assess what has proven effective in other
countries before designing its own AI for education policy. This approach enables
experts to monitor the outcomes of various approaches internationally and identify
best practices and potential pitfalls allowing for a more informed policy development
process. This strategy enables a careful analysis of how certain policies perform in
practice, especially regarding adaptability to specific educational and cultural
contexts. By learning from the successes and challenges faced by others, a policy can
be crafted that is both evidence-based and tailored to the unique needs of its own
educational landscape, ultimately increasing the likelihood of successful
implementation. However, while policy borrowing can offer valuable insights and tested
frameworks, it is not without its pitfalls. Policies effective in one context may not
translate seamlessly into another due to differing educational environments, cultural
norms, and resource availability (Burdett & O’Donnell, 2016).
Methodology
This study reviewed AUPs from the largest second-level schools in Ireland; some 51
schools with over 1,000 students as of July 2024. Schools with large student
populations were chosen to reflect settings where digital tools are more likely to be
heavily used, potentially increasing the relevance of comprehensive AUPs. The AUPs
were collected and analysed for references to AI and other recent technological
advancements, with particular attention to guidelines around ethical AI use, privacy,
and application in educational contexts. Additionally, a survey was conducted among
87 school leaders to capture their perspectives on updating AUPs to meet the demands
of today’s digital environment. The survey was sent to all second level principals via the
National Association of Principals and Deputy Principals, the Joint Managerial Body of
Secondary Schools and one Education and Training Board in the last week of November
and first week of December. Given the short survey window, a response rate of 10% of
schools was highly positive and the participating schools are broadly representative of
the national population. It gathered qualitative data on the challenges faced by schools
in maintaining relevant and up-to-date policies, as well as the types of support that
would be most beneficial. This mixed-methods approach enabled a robust analysis of
both existing policy documents and the insights of school leadership, providing a
comprehensive understanding of the current state of AUPs in large second-level
schools and the evolving needs around digital and AI policy in Irish education.
Findings
The number of large second-level schools has grown significantly, which may signal
increasing complexity in managing and updating digital policies for larger student
bodies. Only six schools, all ETB schools, had AUPs that were current for AY24/25,
revealing a general lag in policy updates that address rapid digital advancements in
schools. The dataset includes publication years spanning from 2000 to 2024, with data
available for 11 distinct years: 2000, 2003, 2011, 2016, 2017, 2018, 2020, 2021, 2022,
2023, and 2024. This range highlights a gradual increase in policy updates over time,
with a notable clustering of documents in the 2020s, suggesting a more recent focus on
modernising school policies. This cluster is possibly associated with the necessity for a
revised AUP document during the physical closure of schools during the Covid
pandemic and the pivot to online teaching and learning.
Some schools, particularly fee-charging institutions, restricted public access to their
AUPs post-2020, indicating a shift towards guarded policy distribution. Of the 51
schools a total of 11 did not have an AUP on the school website; eight religious schools
and three community colleges. Two of the three community colleges without an AUP
had evidence of having had an AUP. One had a policy relating to Chromebook usage
and mobile phone usage. In this case the school AUP document was incorrectly linked
to Chromebook policy. Another community college provided a link to a generic
Education and Training Board Mobile Phone Policy that was not school specific.
A total of five of the AUP documents were scanned pdfs (two catholic schools, two inter
denominational schools and one multi denominational school).
Across all 51 AUP documents AI-related guidelines were notably absent, with most
AUPs lacking comprehensive instructions on emerging digital tools, underscoring the
disconnect between policy and practice.
Findings from Survey of School Principals
A short online survey was issued to school principals at the end of November 2024, to
assess their experiences and views in relation to AUPs. A total of 87 school leaders
responded, just under one-in-seven school leaders, representative of all school types.
The results highlight current challenges and provide some implications for policy.
Each school leader was asked how well their school AUP addresses the challenges and
were confident their AUP addresses needs, with the vast majority highlighting shortfalls
(67% indicating their AUP doesn’t cover newer technologies and 23% indicating their
AUP is outdated). School leaders in voluntary secondary school were more likely to feel
their AUP is outdated, reflecting the different supports and resources for this sector
compared to ETB schools (see Carroll et al., 2024).
Very well, AUP Somewhat, covers Not well, AUP
comprehensive basics but not outdated
newer tech
environment
Almost three-quarters of school leaders report that their AUP does not address the use
of AI by staff and students, while one quarter indicate their AUP partially address AI
usage but there are no specific guidelines. In terms of familiarity with AI tools, just 13
per cent of school leaders indicate they are familiar with AI tools and actively using
36 per cent are not yet using AI tools. Overall, school leaders are open to students using
cent are in support of students using such tools with guidelines in place, while one third
caution against such use unless strict guidelines are in place. Over half of school
leaders identify ‘strong ethical or privacy concerns’ regarding the use of AI tools, and 44
per cent identify ‘some concerns’, which need to be addressed by policies. School
leaders in voluntary secondary schools are more likely to raise strong concerns. All
school leaders indicate a need for training and resources to help staff and students
understand the appropriate use of AI. In terms of the most useful support, school
leaders were most likely to highlight the need for training for teachers/staff (39 per
cent), clear guidelines on acceptable AI use for students and staff (38%) and resources
voluntary secondary sector were particularly likely to highlight the need for
templates/resources.
Overall, school leaders are more likely to identify risks rather than benefits in adopting
AI tools within their school setting. In total 58 per cent identify some risks but equal
benefits and the need to proceed with caution. Conversely, 38 per cent identify
significant benefits and the potential to enhance education. Over 62 per cent feel AI
tools used within the school (for learning, administration, or security) should be
monitored differently than traditional digital tools, with 23 per cent undecided on this
issue and just 14 per cent disagreeing.
make it relevant for the next 5 years. Just under half indicated they would like guidelines
specifically addressing AI and emerging technologies, while 30 per cent would like to
see flexible language to accommodate future technology changes and 16 per cent
would like clear guidance for both in-school and remote learning environments.
Finally, and as noted earlier, some schools have made their AUPs private in recent
years; we asked school leaders their preferences on this. In total, 53 per cent feel that
these policies should be publicly available, 16 per cent feel they should include both
public and private sections and 12 per cent feel access should be restricted for
privacy/security reasons.
Very familiar, actively
using AI tools
Somewhat familiar,
considering AI tools
Slightly familiar, not
using yet
Not familiar, no AI
tools
0 10 20 30 40 50
AI-driven tutoring, assessment tools or plagiarism detection)
Strongly Support Open to Caution Oppose
support use but use, against use use by
use with guidelines undecided without students
guidelines not needed on strict
guidelines guidelines
assignments or learning support?
Resources or templates to
incorporate AI into AUPs
Training for
teachers/administrators
Clear guidelines on acceptable
AI use (student & staff)
0 10 20 30 40 50
Guidelines Flexible Clear guidance Enhanced
specifically language to for both in- privacy and
addressing AI & accommodate school and security
emerging tech future tech remote learning protocols
changes environments
the next five years?
Discussion
As stated earlier only six schools, all ETB schools, had AUPs that were current for
AY24/25. It is possible that voluntary secondary schools might be more likely not to
have an AUP or an up-to-date AUP due to differences in resources, governance
structures, and support systems compared to ETB schools (see Carroll et al., 2024).
The fact that only the ETB schools have up-to-date policies highlights the advantages of
centralised resources, standardised templates, and administrative support provided by
the state. Non-ETB schools may lack equivalent funding, expertise, or oversight, placing
them at a disadvantage in maintaining compliance and modern policy management.
AI brings unique challenges, such as bias, privacy issues, and the risk of academic
misconduct, which demand clear guidelines in school policies. The choice between
integrating AI guidelines into the Acceptable Use Policy (AUP) versus creating a
separate AI policy document depends on the depth and complexity of the AI issues the
school aims to address, as well as its resources and policy-making priorities. There are
advantages and limitations to each of these approaches.
Schools often lack the resources or centralised guidance to frequently update AUPs,
leading to outdated policies that no longer reflect digital realities (Marcus-Quinn, 2024).
While the Department of Education has acknowledged the need for AI guidelines, the
absence of concrete direction leaves schools without a standardised framework for
responsible AI use. Open AI, in a move to support educators in incorporating AI into
their teaching practices, provide resources including introductory materials from
leading educational organisations on teaching with and about AI (Open AI, 2024). The
company has also published useful responses to frequently asked questions from
educators on effectively utilising ChatGPT for educational purposes. Similar but more
objective resources are required from the Department of Education.
If schools in Ireland aren't formalising AI use policies in writing, they may instead be
addressing AI awareness informally through classroom discussions, workshops, or by
integrating digital literacy topics into the curriculum. Over the last two years AI
translation tools have played a critical role in fostering inclusivity within educational
settings, particularly for students from diverse linguistic backgrounds. These tools
facilitate real-time translation, enabling students to comprehend instructional
materials and participate actively in classroom discussions. The Department of
Education has supported the integration of over 18,000 children from Ukraine into Irish
schools and for many the integration of Google Translate has been instrumental in
assisting Ukrainian students to navigate the curriculum and engage with peers, thereby
enhancing their overall educational experience (Shiel, 2022). New arrivals from Ukraine
are also advised to use Google Translate to access information from the Citizens
Information service (Citizens Information, 2024).
At a local level teachers might also be highlighting the ethical and practical aspects of
AI during relevant lessons, to help students understand both the potential and the
limitations of AI. Additionally, schools may rely on broader internet safety and critical
thinking lessons to indirectly address issues related to AI use, encouraging students to
think critically about digital tools, data privacy, and the reliability of AI-generated
content. However, without a clear, written policy, these efforts could vary significantly
from school to school, potentially leaving gaps in consistent understanding and
responsible AI use among students.
Many teachers in Ireland are interested in the use of ICT in their own teaching practice
(Carroll et al., 2024). Where appropriate many may be proactively addressing the
integration of AI in education, rather than passively awaiting official guidelines.
Recognising their influential role in shaping students' responsible and effective use of
AI, educators are voicing their perspectives and concerns through op-eds, letters to
newspapers, and interviews with national media outlets. Beyond public discourse,
teachers are also actively supporting one another through peer-led professional
development resources, sharing valuable insights and strategies at no cost. Often,
these contributions are offered voluntarily, during their own time and at their own
expense, underscoring the commitment teachers have toward navigating the ethical
and practical challenges posed by AI in the classroom. This collective initiative reflects
a strong sense of responsibility among educators to guide students thoughtfully in an
evolving digital landscape.
Ireland’s education system is implementing “additional assessment components”
(AACs) for the Leaving Certificate, aiming to reduce exam-related stress by assessing
“key competencies” outside traditional exams. Starting in 2025, 40% of each subject’s
grade will stem from assessments outside exam halls. Some teachers are currently
raising concerns over AI's potential to compromise assessment. Studies reveal that
current AI detection technologies are unreliable, leading to false accusations or
undetected misuse. Education experts, including Prof. Áine Hyland, suggest delaying
AACs, given the challenges in verifying student-authored work. Some teachers query
whether self-declaration of AI use could fairly prevent cheating. In subjects like English,
assessing students in controlled conditions remains infeasible due to logistical
limitations, leaving AACs vulnerable to manipulation. Many teachers agree that while
AACs aim to reduce pressure, high-stakes assessments are increasingly at risk in the AI
era, threatening the integrity of Ireland’s examination system (Girdham, n.d.).
In addition to the promises and limitations of using AI, such as ChatGPT, in education,
Irish-language schools present a unique set of challenges. Although AI is marketed as a
solution for personalised learning and reducing teacher workload, its effectiveness in
non-English contexts, like Irish-language education, is questionable due to significant
data limitations. AI models require vast amounts of data for reliable functionality, but
the Irish language lacks sufficient resources to train these tools effectively.
Additionally, the small number of students in Irish-language schools makes it unlikely
that private companies will invest in developing sophisticated Irish-language AI
systems, as the limited user base would not guarantee a profitable return on
investment. Without targeted government support, Irish-language schools may be
forced to choose between substandard AI tools or missing out on AI’s potential benefits
altogether. In October 2024 the Irish Government launched a tender process to develop
an innovative Irish language-based AI tool, spearheaded by the Gaeltacht development
agency, Údarás na Gaeltachta, under the project ArdIntleacht na Gaeilge. This AI
initiative aims to enhance Irish language capabilities in real-time speech processing,
query responses, translation, and the use of cultural context within AI-generated
content. Scheduled for completion by 2026, the tool is intended to improve public
service delivery by offering responses in various Irish dialects and reflecting Ireland’s
cultural context in its interactions. The tool is also anticipated to serve as a model for
other lesser-used languages worldwide, promoting AI development that respects
linguistic diversity. Additionally, it is expected to create research and innovation
opportunities for other countries with minority languages, positioning Irish as a
pioneering force in AI for linguistic preservation and digital inclusivity.
The ArdIntleacht na Gaeilge project could significantly enhance AI resources for Irish-
language second-level schools by providing tailored, culturally relevant tools that
support Irish-language learning and communication. By focusing on real-time speech
processing, intelligent responses, and translation in Irish, the project offers schools a
powerful resource for engaging students in immersive, practical language experiences
within the digital sphere. This AI tool could help schools address the gap in educational
resources specific to Irish, aiding students in understanding and using the language in a
variety of contexts, from academic subjects to everyday interactions.
Recommendations
Schools should explicitly address AI’s role, covering data privacy, ethical usage, and
limitations to prevent misuse. Regular updates, as recommended by digital education
experts, are necessary to keep AUPs relevant and effective. The Department of
Education could provide a model AUP or guidelines, giving schools a basis for
developing AI-inclusive policies. Transparent, accessible AUPs foster trust and provide
clear expectations for students, parents, and educators alike.
Integrating AI guidelines directly into the AUP can simplify policy management by
consolidating all digital use expectations into a single document, making it easier for
students, parents, and staff to understand and follow without having to refer to multiple
sources. Including AI guidelines within the AUP provides immediate context, aligning AI
use with other responsible and acceptable technology practices, which may reinforce
its relevance as part of daily digital engagement in schools. For schools with limited
resources or personnel to maintain policy updates, embedding AI guidelines in the AUP
offers a streamlined approach to keeping digital policies current as technology evolves.
However, this approach comes with limitations. AUPs are generally designed to cover a
wide range of digital behaviours, so adding AI guidelines may result in limited scope,
possibly omitting critical details specific to AI. The addition of comprehensive AI
guidelines could also make the document long and complex, which might impact
readability and compliance, especially for students. This integrated approach is best
suited for schools aiming to introduce basic AI guidelines related to privacy, ethical
use, and usage boundaries within their existing tech policy framework.
While creating a separate AI policy document may allow for a more comprehensive
approach, offering detailed coverage of specific issues such as privacy, data security,
ethical concerns, and AI-driven learning tools. A standalone policy could provide
flexibility, enabling schools to address nuanced aspects of AI, such as data
governance, transparency in AI-based grading, and limitations on AI tools, without
diluting or overcomplicating the broader AUP. This structure could also support policy
evolution, allowing schools to update their AI guidelines more frequently to keep pace
with rapid technological developments, without revising the entire AUP. However,
having multiple policy documents could create a challenge for users who must navigate
and adhere to different policies, potentially affecting compliance. Additionally,
developing and maintaining an extra document requires time and expertise, which may
strain the resources of smaller schools. This standalone approach is more suitable for
schools with significant AI integration, like those using AI-driven learning tools or
planning to expand their AI use, as it provides the specificity and depth necessary to
address complex AI-related issues effectively.
Integrating AI use guidelines directly into the AUP would streamline policy
management, making it easier for students, parents, and staff to access and
understand all digital use expectations in one place. This approach also ensures that AI
is positioned within the broader context of responsible technology use, reinforcing its
role as part of everyday digital engagement in schools. In Ireland, Webwise, an initiative
supported by the Department of Education and the European Union, focuses on
promoting internet safety in Ireland by offering educational resources, guidance, and
support to teachers, parents, and young people. The service assists Irish schools in
revising their AUPs to enhance online safety. A free AUP Generator tool is available,
allowing schools to create customised policies, alongside comprehensive templates
and guidelines addressing rights, responsibilities, and consequences related to internet
use (Webwise, 2022). Additionally, Webwise provides training sessions, workshops,
and continuous support for educators and school leaders to ensure successful
implementation. These efforts equip schools with the tools to support a secure and
responsible approach to internet use within their communities. If the Webwise AUP
generator tool were to incorporate AI guidelines, it would provide an exceptionally
efficient mechanism for embedding this crucial content into school Acceptable Use
Policies (AUPs), ensuring that schools are equipped to address emerging challenges
and opportunities related to AI technology.
Conclusion
The review of current AUPs for the Academic Year 2024/25 reveals an urgent need for
updates, specifically with AI guidelines that keep pace with the current technological
landscape in education. This analysis underscores the importance of proactive policy
adjustments and calls for more research on how AUPs can support safe and effective AI
use in schools (Holmes, 2019).