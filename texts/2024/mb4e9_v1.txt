Robots vs. AI – How Attitudes, Familiarity, Anthropomorphism,
Knowledge, and Risk-Opportunity Perception Influence Users’
Preference for Robots and Artificial Intelligence*
1 2 3
Nadia Said , Julia Wagner , and Andreea E. Potinteu
Abstract— In recent years the fast development of artificial empathize with embodied vs. non-embodied robots. Other
intelligence (AI) and robotic technology has led to tremendous
research focuses on how people perceive social interactions
growth in various industries, especially in the medical and
with embodied vs. non-embodied robots [4], [1]. Generally,
transportation sectors. While AI and (humanoid) robots are
embodiment leads to higher empathy, more positive impres-
often viewed as promising technology for the future, there is also
sions of a robot’s social abilities, and more positive attitudes
an increase in concern about the negative impact of those devel-
opments on society. Even though AI and robots could be used towards robots.
interchangeably in many application areas, they fundamentally
While research shows a tendency for people to favor em-
differ in that robots have a physical presence as opposed to
bodied robots, especially in social interactions, our approach
AI being more abstract algorithms running in the background
differs in two ways: First, we want to investigate whether
of an application. That poses the question of whether people
people’s preference for AI as an abstract algorithm vs. a
differ in their preferences regarding robots or AI and what
cognitive factors influence people’s preferences. Our study physical instance (like a robot) differ, rather than comparing
investigated the preference for robots or AI in 15 different
embodied vs. non-embodied robots, and second, we want to
interaction contexts for a sample of N = 526 of the German
investigate the main drivers of people’s preferences for one
population (representative for age and gender). To identify
or the other. More specifically, we investigate the influence
the most important factors influencing participants’ prefer-
of attitudes, familiarity, anthropomorphism, knowledge, and
ences for robots or AI, attitudes, perceived anthropomorphism,
knowledge, familiarity, and risk-opportunity perception were risk-opportunity perception on people’s preference for robots
measured. Results show that attitudes and risk-opportunity
vs. AI.
perception are the most important predictors for participants’
A. Attitudes
preferences. Furthermore, differences in perception of robots
and AI are discussed.
Given the substantial body of research on the connection
between attitudes and behavior [5], [6], participants’ attitudes
I. INTRODUCTION
towards robots and AI are measured as one potential driving
Today, people already interact with AI, for example,
factor for participants’ preference.
through voice assistants like Siri and Alexa. These tech-
B. Familiarity
nologies have become ubiquitous in daily life, allowing
people to access, e.g., information conveniently and quickly. There is some research showing a positive relationship
In comparison, the use of robots in everyday life is still between technology usage (and few research on AI usage
relatively limited. So far, robots have mainly been used in specifically) and familiarity [7]. Other research however,
production, manufacturing, and logistics, where they help to shows that familiarity seems to be playing a minor role when
automate and optimize work processes. Recently, however, other factors are taken into account [8].
there have been more and more innovative developments
C. Anthropomorphism
aimed at developing robots for everyday use, especially in
Anthropomorphism refers to the attribution of human-like
areas such as nursing, elderly care, service, and security.
characteristics or behaviors to non-human entities like robots
Given these developments, it is essential to understand how
and AI systems. Anthropomorphism can influence people’s
individuals perceive and interact with these technologies.
perceptions, attitudes, and behaviors toward technology, their
A substantial body of research compares embodied vs.
expectations, and trust in its performance and reliability.
non-embodied robots [1], [2]. For example, Kwak et al. [3]
Additionally, studies show that anthropomorphism directly
investigated whether there is a difference in how much people
affects the intention to use robots and AI [9].
*This work was not supported by any organization
D. Knowledge
Nadia Said is with the Department of Psychology, Uni-
versity of Tu¨bingen; Schleichstr. 4, 72076 Tu¨bingen, Germany
While there is a large body of research showing a positive
nadia.said@uni-tuebingen.de
relationship between knowledge and product usage [10],
Julia Wagner with the Department of Computer Science,
there is lesser research on this relationship for AI specifi-
Reutlingen University; Alteburgstrae 150, 72762 Reutlingen, Germany
Julia1.Wagner@Student.Reutlingen-University.DE
cally [8]. Generally, however, one would expect that more
Andreea E. Potinteu is with the Department of Psychology, University
knowledge about robots and AI will be related to higher
of Tu¨bingen and the Leibniz-Institut fu¨r Wissensmedien; Schleichstr. 4/6,
a.potinteu@iwm-tuebingen.de preference for robots and AI.
72076 Tu¨bingen, Germany
E. Risk-Opportunity Perception 1) Scenarios: To measure participants’ preference for
either AI or robots, they received 15 scenarios addressing
Research shows that there is a relationship between per-
three application areas: service, security, and medical. Each
ceived risks and opportunities and participants’ usage inten-
scenario described a certain situation in which AI or robots
tion [11], as well as actual behavior [12]. For example, the
were used (see Fig. 1 for an example).
study by Schwesig et al. [12] showed that participants who
perceived AI as riskier were less willing to use it. Addi-
tionally, the context of AI usage (medicine, transportation,
I A C V
NDEPENDENT ND ONTROL ARIABLES
media, psychology) influenced the likelihood of participants’
willingness to use the AI application. Regarding robots, the
Attitudes Familiarity
study of Seo and Lee (2021), for example, showed that
5 items for each category (robot 3 items for each category (robot
participants’ revisit intention of a robot restaurant decreases
and AI) adapted from [14] and AI)
with higher risk perception [13].
11-point scale ranging from 7-point scale ranging from
”strongly disagree“ to ”strongly ”strongly disagree“ to ”strongly
F. The Current Research
agree“ agree“
The aim of this study is to measure and investigate
E.g.:”I have had experience with
people’s preference for AI or robots and the factors that E.g.: ”I am afraid of robots.“ robots in
my work / education / studies.“
influence those preferences. Therefore, we have developed
Anthropomorphism
15 scenarios from different domains in which robots and AI Knowledge
are compared as two possible options to use. 27 statements (14 true & 13
false) about AI adapted from
8 items for each category (robot
[17]
II. METHODS and AI) taken from [15] and
[16]
20 statements (9 true & 11
false) about robots
aspredicted.org/7M8_H3W. All participants provided
5-point scale ranging from ”not choice between two options:
informed consent. Methods were approved by the ethical
at all“ to ”very much“ ”true“ or ”false“
review board of the Leibniz-Institut fu¨r Wissensmedien in
E.g.: ”To what extend is the
E.g.: ”A strong AI can make
Tu¨bingen, Germany. AI/robot able to speak like a
decisions on its own.“
human? “
A. Participants
Risk-Opportunity Perception
Demographic Variables
15 items for each category
For the study, we recruited a representative (age and
Gender: female, male, binary
(robot and AI)
gender) sample of N = 542 from the German population
7-point scale
via the panel provider Bilendi&respondi. Six out of those
ranging from “risk“ to Age: min. 18 years
participants did not provide their consent for data processing.
”opportunity“
Moreover, only one participant was in the “diverse” cate-
Education: 4 levels (”no
gory of the gender variable. In order to prevent potential E.g.: ”Do you believe this [...] education“, ”lower secondary
AI application is more of a risk school“, ”intermediate secondary
distortion in the statistical models, we randomly assigned
or more of an opportunity? “ school“, ”college-level
the participant from the “diverse” category to “male” or
diploma“)
“female”. Furthermore, five participants participated twice
and were thus completely removed from the data set to
ensure data quality. Thus, the final sample consisted of N =
526 participants (M = 45.97 years, SD = 13.90, Range Airport – Passport Control
age age
= 18 − 69 years, n = 246, n = 280). Regarding the
female male You are at the airport and are standing at passport control.
school education level, 0.57% stated to have not finished
A photo of your face is taken and your fingerprints are
any education, 7.60% of participants attended a lower sec-
scanned.
ondary school (Volks-, Hauptschulabschluss), 33.84% had
completed intermediate secondary school (Mittlere Reife,
Option 1 (AI): An AI-controlled computer instructs you
Realschul- oder gleichwertiger Abschluss), and 57.98% had
and performs the check with you.
obtained a college-level diploma (Abitur, Hochschulreife).
Option 2 (Robot): A robot instructs you and performs the
check with you.
B. Design and Material
The study employed a questionnaire-based survey to col-
Fig. 1. Example of one of the security scenarios.
lect data on participants’ preferences for using robots or AI in
different contexts. The dependent variable is the preference Participants were then asked ”Which option would you
for either robots or AI, which was measured for 15 different prefer?“. Answers were given on a 5-point scale with the fol-
scenarios. The independent variables were attitudes, famil- lowing options: ”definitely the AI“, ”rather the AI“, ”equiv-
iarity, anthropomorphism, knowledge, and risk-opportunity alent“, ”rather the robot“, ”definitely the robot“. Participants
perception. Measures and examples for the independent were randomly assigned to one of four different versions
is, either AI or robots as options were presented first, and age, and education). Note that negative values indicate a
labeling of the rating scale was either with ”definitely the preference for AI, and positive values indicate a preference
robot“ on the left and ”definitely the AI“ on the right or for robots. The independent variables were successively
vice versa. added to a baseline model (see Fig. 2, light blue). The entire
model is displayed in Fig. 2 (yellow). Results show that risk-
III. R
ESULTS
opportunity perception and attitudes are the most important
In the following section the results of the study are
predictors when it comes to participants’ preference for either
presented. If not stated otherwise, a significance level of
AI or robots, followed by knowledge for AI.
α = .05 was defined for all statistical analyses.
A. Robots vs. AI: Differences in Perception
risk_opportunity_AI
risk_opportunity_R
knowledge_AI
on different scales and if there was a significant difference
knowledge_R
between the AI vs. robot ratings (for this analysis, the signif-
anthropomorphism_AI
icance level was adjusted to α = .008). Overall, participants
anthropomorphism_R
had a preference for AI applications over robots. Participants’ familiarity_AI
familiarity_R
attitudes towards robots were more positive than towards
attitude_AI
AI, however this result was not longer significant with
attitude_R
the adjusted alpha-level. Concerning familiarity, participants
Education
reported being more familiar with AI than with robots. In- Gender
Age
terestingly, perceived anthropomorphism was greater for AI
−0.4 −0.2 0.0 0.2 0.4
Estimate
than for robots. Regarding knowledge, participants had more
Baseline + Familiarity + Knowledge
accurate knowledge about AI than about robots. Participants’
Model
+ Attitude + Anthropomorphism + Risk−Opportunity Perception
risk-opportunity ratings were above the middle of the scale
for AI and robots, indicating that people perceived more Fig. 2. Results of multiple regression models predicting the preference
score (negative regression coefficients: preference for AI, positive regression
opportunities than risks concerning AI as well as robots
coefficients: preference for robots) with age, gender, and education as
(M = 4.60, SD = 1.34; t(525) = 10.25, p < .001;
control variables. The size of the distribution indicates 95% CI.
AI AI
M = 4.54, SD = 1.31, t(525) = 9.49, p < .001).
Robot Robot
There was no significant difference between AI and robots
for participants’ risk-opportunity perception. C. Robots vs. AI: Influence of Context
B. Robots vs. AI: Most Important Predictors for Preference Furthermore, we explored whether the scenarios’ different
contexts impacted participants’ preferences for robots or AI.
Multiple linear regressions were used to investigate
To investigate which scenarios significantly differed from
whether the main variables influenced the strength and di-
the overall mean, we conducted t-tests comparing each
rection of the preference score (while controlling for gender,
scenario to the mean of the remaining scenarios (for this
analysis, the significance level was adjusted to α = .003).
Results show that four scenarios significantly differed from
R . AI: C D M
OBOTS VS OMPARISON OF THE IFFERENT EASURES
More specifically, in scenarios 4 and 10, the robot is
Preference
preferred over the AI. On the other hand, for scenarios 14
M = 2.80, SD = 0.70;
preference preference
t(525) = −6.43, p < .001
M = 6.30, SD = 2.32;M = 6.58, SD = R . AI: C P
OBOTS VS ONTEXT AND REFERENCE
AI AI Robot Robot
2.17; t(1045.1) = −2.06, p = .039
Familiarity
Scenario 4: Assistance while shopping
M = 2.72, SD = 1.80;M = 2.29, SD =
AI AI Robot Robot
M = 2.79, SD = 0.70;M =
overall overall SC04
1.74; t(1048.7) = 3.94, p < .001
3.02, SD = 1.11; t(595.9) = −4.74, p < .001
SC04
Anthropomorphism
Scenario 10: Rehabilitation clinic
M = 2.17, SD = 0.90;M = 1.95, SD =
AI AI Robot Robot M = 2.79, SD = 0.71;M =
overall overall SC10
0.89; t(1049.8) = 4.01, p < .001
3.04, SD = 1.06; t(603.84) = −5.34, p < .001
SC10
Knowledge
Scenario 14: Smart Home
M = 0.68, SD = 0.16;M = 0.59, SD =
M = 2.82, SD = 0.70;M =
AI AI Robot Robot
overall overall SC14
0.19; t(1017.1) = 8.04, p < .001
2.50, SD = 1.09; t(599.38) = 6.73, p < .001
SC14
Risk-Opportunity Perception
Scenario 15: Fall detection at home
M = 4.60, SD = 1.34;M = 4.54, SD = M = 2.81, SD = 0.70;M =
AI AI Robot Robot overall overall SC15
1.31; t(1049.3) = 0.72, p = .47 2.66, SD = 1.06; t(603.3) = 3.21, p = .0014
SC15
and 15, participants showed a stronger preference for the AI However, participants did not receive any description of AI
over the robot compared to the mean preference score. and robots, even though one could derive this difference
(abstract algorithm vs. embodied robot) from some of the
IV. D
ISCUSSION
scenarios. Thus, in future studies, participants could receive
A. Robots vs. AI: Differences in Perception
additional information, or their mental representation could
be assessed via self-reports.
The results from our study show that people’s perceptions
and assessments of robots and AI differ: First, participants
EFERENCES
were less familiar with robots than with AI. This can be
[1] K. M. Lee, Y. Jung, J. Kim, and S. R. Kim, “Are physically embodied
explained by the fact that AI is more commonly used in
social agents better than disembodied social agents?: The effects of
daily life (e.g., voice assistants like Siri and Alexa) than
physical embodiment, tactile interaction, and people’s loneliness in
robots (note, that robots are more frequently encountered in human–robot interaction,” International Journal of Human-Computer
Studies, vol. 64, no. 10, pp. 962–973, 2006.
other countries like e.g. South Korea). Furthermore, there
[2] A. Tapus, C. Tapus, and M. Mataric, “The role of physical embodiment
has been a rapid increase in media coverage of AI in recent
of a therapist robot for individuals with cognitive impairments,” in RO-
years, while (humanoid) robots, even though being covered, MAN 2009-The 18th IEEE International Symposium on Robot and
Human Interactive Communication. IEEE, 2009, pp. 103–107.
received lesser attention. Second, participants perceived AI
[3] S. S. Kwak, Y. Kim, E. Kim, C. Shin, and K. Cho, “What makes
as more anthropomorphic than robots. However, the anthro-
people empathize with an emotional robot?: The impact of agency
pomorphism items were mainly tailored to assess whether and physical embodiment on human empathy for a robot,” in 2013
IEEE Ro-man. IEEE, 2013, pp. 180–185.
people think that robots or AI have, for example, their own
[4] J. Wainer, D. J. Feil-Seifer, D. A. Shell, and M. J. Mataric, “Em-
thoughts and feelings. Given the recent developments in AI,
bodiment and human-robot interaction: A task-based perspective,” in
one could imagine that participants associate such abilities RO-MAN 2007-The 16th IEEE International Symposium on Robot and
Human Interactive Communication. IEEE, 2007, pp. 872–877.
more with AI than with robots. Third, participants had lesser
[5] L. R. Glasman and D. Albarrac´ın, “Forming attitudes that predict
knowledge about robots than about AI. This result is not
future behavior: a meta-analysis of the attitude-behavior relation.”
surprising as robots are less frequently encountered in daily Psychological Bulletin, vol. 132, no. 5, p. 778, 2006.
[6] R. H. Fazio et al., “How do attitudes guide behavior,” Handbook of
life in Germany and receive lesser media attention. Last,
Motivation and Cognition: Foundations of Social Behavior, vol. 1, pp.
participants did not differ in their risk-opportunity perception
204–243, 1986.
for robots and AI and generally viewed both more as an [7] E. C. Idemudia and M. S. Raisinghani, “The influence of cognitive
trust and familiarity on adoption and continued use of smartphones:
opportunity than a risk.
An empirical analysis,” Journal of International Technology and
Information Management, vol. 23, no. 2, p. 6, 2014.
B. Robots vs. AI: Most Important Predictors for Preference
[8] A.-E. Potinteu, D. Renftle, and N. Said, “What Predicts AI Usage?
Investigating the Main Drivers of AI Use Intention over Different
When investigating the different potential predictors for
Contexts,” PsyArXiv, 2023.
people’s preferences, results show that education, age, gen-
[9] M. Blut, C. Wang, N. V. Wu¨nderlich, and C. Brock, “Understanding
der, and familiarity had no significant influence. The two
anthropomorphism in service provision: a meta-analysis of physical
robots, chatbots, and other AI,” Journal of the Academy of Marketing
most important predictors for robots and AI were attitudes
Science, vol. 49, pp. 632–658, 2021.
and risk-opportunity perception. Additionally, knowledge
[10] S. H. Lim, D. J. Kim, Y. Hur, and K. Park, “An empirical study of the
about AI was positively related to participants’ preference
impacts of perceived security and knowledge on continuous intention
to use mobile fintech payment services,” International Journal of
for AI. Furthermore, in the partial models, perceived an-
Human–Computer Interaction, vol. 35, no. 10, pp. 886–898, 2019.
thropomorphism of robots and knowledge about robots were
[11] P. Esmaeilzadeh, “Use of AI-based tools for healthcare purposes: a
both positively related to participants’ preference for robots. survey study from consumers’ perspectives,” BMC Medical Informat-
ics and Decision Making, vol. 20, no. 1, pp. 1–19, 2020.
However, anthropomorphism and knowledge were not sig-
[12] R. Schwesig, I. Brich, J. Buder, M. Huff, and N. Said, “Using Artificial
nificant anymore when adding risk-opportunity perception
Intelligence (AI)? Risk and Opportunity Perception of AI Predict
to the model. Concerning knowledge about robots, one People’s Willingness to Use AI,” PsyArXiv, 2022.
[13] K. H. Seo and J. H. Lee, “The emergence of service robots at restau-
explanation could be that participants generally had not much
rants: Integrating trust, perceived risk, and satisfaction,” Sustainability,
knowledge about robots (59% correct). Thus, the impact
vol. 13, no. 8, p. 4431, 2021.
of knowledge was only small in the partial model and not
[14] C. Sindermann, P. Sha, M. Zhou, J. Wernicke, H. S. Schmitt, M. Li,
R. Sariyska, M. Stavrou, B. Becker, and C. Montag, “Assessing the
significant anymore in the full model. Interestingly, although
attitude towards artificial intelligence: Introduction of a short measure
participants perceived AI as more anthropomorphic, per-
in german, chinese, and english language,” KI-Ku¨nstliche Intelligenz,
ceived anthropomorphism only played a role in participants’
vol. 35, no. 1, pp. 109–118, 2021.
[15] P. A. Ruijten, A. Haans, J. Ham, and C. J. Midden, “Perceived
preference for robots (if only in the partial model).
human-likeness of social robots: testing the Rasch model as a method
for measuring anthropomorphism,” International Journal of Social
C. Limitations
Robotics, vol. 11, pp. 477–494, 2019.
The scenarios covered a range of robot and AI use cases, [16] S. Moussawi and M. Koufaris, “Perceived Intelligence and Perceived
Anthropomorphism of Personal Intelligent Agents: Scale Development
of which some are theoretically possible but not implemented
and Validation,” in Hawaii International Conference on System Sci-
yet, and others are already put into practice. Therefore, future
ences, 2019.
studies should adapt the scenarios to ensure comparability. [17] N. Said, A.-E. Potinteu, I. Brich, J. Buder, H. Schumm, and M. Huff,
“An Artificial Intelligence Perspective: How Knowledge and Confi-
Furthermore, the study is based on the assumption that
dence Shape Risk and Opportunity Perception,” PsyArXiv, 2022.
people’s mental models of robots and AI differ in that AI is
perceived as a more abstract concept than embodied robots.